{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_4:0\", shape=(), dtype=float32) Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "[4.0, 3.0]\n",
      "12.0\n",
      "12.0\n",
      "[3. 7.]\n",
      "[0.         0.3        0.6        0.90000004 1.2        1.5\n",
      " 1.8000002  2.1000001  2.4       ]\n",
      "8\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "node1=tf.constant(4.0,tf.float32)\n",
    "node2=tf.constant(3.0)\n",
    "print(node1,node2)\n",
    "node3=node1*node2\n",
    "\n",
    "# launch the graph in session\n",
    "sess=tf.Session()\n",
    "print(sess.run([node1,node2]))\n",
    "print(sess.run(node3))\n",
    "print(sess.run(node3))\n",
    "\n",
    "a=tf.placeholder(tf.float32) #placeholder\n",
    "b=tf.placeholder(tf.float32) #placeholder\n",
    "adder_node=a+b\n",
    "print(sess.run(adder_node,{a:[1,3],b:[2,4]}))\n",
    "\n",
    "W=tf.Variable([.3],tf.float32)\n",
    "b=tf.Variable([-.3],tf.float32)\n",
    "x=tf.placeholder(tf.float32)\n",
    "linear_model=W*x+b\n",
    "init=tf.global_variables_initializer()\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(linear_model,{x:[1,2,3,4,5,6,7,8,9]}))\n",
    "\n",
    "x=tf.add(5,3) # can use subtract, multiply as well\n",
    "print(sess.run(x))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.cast(tf.constant(2.0),tf.int32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01798620996209156\n",
      "0.11920292202211755\n",
      "0.5\n",
      "0.8807970779778823\n",
      "0.9820137900379085\n"
     ]
    }
   ],
   "source": [
    "# 1/(1+exp(-x))\n",
    "import numpy as np\n",
    "def sigmoid_(a):\n",
    "    return 1/(1+np.exp(-a))\n",
    "a=[-4,-2,0,2,4]\n",
    "for i in a:\n",
    "    print(sigmoid_(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2913126124515909\n",
      "-0.999329299739067\n",
      "-0.9640275800758169\n",
      "0.0\n",
      "0.9640275800758169\n",
      "0.999329299739067\n"
     ]
    }
   ],
   "source": [
    "# tanh(a)=(e^a-e^-a)/e^a+e^-a\n",
    "#import numpy as np\n",
    "#def tanh_(a):\n",
    "#    return (pow(2.75,a)-pow(2.75,-a))/pow(2.75,a)+pow(2.75,-a)\n",
    "#for i in a:\n",
    "#    print(tanh_(i))\n",
    "\n",
    "def tanh_(a):\n",
    "    return np.tanh(a)\n",
    "print(tanh_(.3))\n",
    "for i in a:\n",
    "    print(tanh_(i))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.82005792e-01 1.79860635e-02 8.14457845e-06]\n",
      "1.0\n",
      "sigmoid_Activation :  [0.54983395 0.7310586  0.5        0.95257413 0.11920292]\n",
      "tanh_Activation :  [ 0.19737528  0.7615942   0.          0.9950547  -0.9640276 ]\n",
      "relu_Activation :  [0.2 1.  0.  3.  0. ]\n"
     ]
    }
   ],
   "source": [
    "round(1.2334,2)\n",
    "\n",
    "# softmax\n",
    "Scores=[12,8,.3]\n",
    "import numpy as np\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x), axis=0)\n",
    "print(softmax(Scores))\n",
    "print(sum(softmax(Scores)))\n",
    "\n",
    "# Sigmoid\n",
    "import numpy as np\n",
    "a=[.2,1,0,3,-2]\n",
    "sigmoid_Activation=tf.sigmoid(a)\n",
    "tanh_Activation=tf.tanh(a)\n",
    "relu_Activation=tf.nn.relu(a)\n",
    "with tf.Session() as sess:\n",
    "    output1=sess.run(sigmoid_Activation)\n",
    "    output2=sess.run(tanh_Activation)\n",
    "    output3=sess.run(relu_Activation)\n",
    "    print(\"sigmoid_Activation : \",output1)\n",
    "    print(\"tanh_Activation : \",output2)\n",
    "    print(\"relu_Activation : \",output3)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aparajita\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[array([-0.54620796], dtype=float32), array([-0.20577921], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Optimizers modifies each variable according to the derivative of loss w.r.t to that variable.\n",
    "\n",
    "# LOSS FUNCTION\n",
    "W=tf.Variable([.5],tf.float32)\n",
    "b=tf.Variable([.1],tf.float32)\n",
    "x=tf.placeholder(tf.float32)\n",
    "y=tf.placeholder(tf.float32)\n",
    "linear_model=W*x+b\n",
    "squared_delta=tf.square(linear_model-y)\n",
    "loss=tf.reduce_sum(squared_delta)\n",
    "\n",
    "optimizer=tf.train.GradientDescentOptimizer(0.01)\n",
    "train=optimizer.minimize(loss)\n",
    "init=tf.global_variables_initializer()\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(3):\n",
    "    sess.run(train,{x:[1,2,3,4],y:[0,-1,-2,-3]})\n",
    "print(sess.run([W,b]))\n",
    "#print(sess.run(loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# Simplest TensorFlow Neuron\n",
    "import tensorflow as tf\n",
    "weight=tf.Variable(0.8)\n",
    "input_value=tf.constant(1.0)\n",
    "output_value=weight*input_value\n",
    "init=tf.global_variables_initializer()\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(output_value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-e119c58f3907>:22: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[[ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-2.]\n",
      " [ 0.]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# AND GATE\n",
    "T,F =1., -1.   # o doesn't give correct o/p for false hence we take -1  \n",
    "bias=1\n",
    "train_in=[\n",
    "    [T,T,bias],\n",
    "    [T,F,bias],\n",
    "    [F,T,bias],\n",
    "    [F,F,bias]\n",
    "]\n",
    "train_out=[\n",
    "    [T],\n",
    "    [F],\n",
    "    [F],\n",
    "    [F]\n",
    "]\n",
    "\n",
    "w=tf.Variable(tf.random_normal([3,1]))\n",
    "\n",
    "# step(x)={1 IF X>0; -1 otherwise}\n",
    "def step(x):\n",
    "    is_greater=tf.greater(x,0)\n",
    "    as_float=tf.to_float(is_greater)\n",
    "    doubled=tf.multiply(as_float,2)\n",
    "    return tf.subtract(doubled,1)\n",
    "\n",
    "output = step(tf.matmul(train_in,w))\n",
    "error=tf.subtract(train_out,output)\n",
    "mse=tf.reduce_mean(tf.square(error))\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(output))\n",
    "print(sess.run(error))\n",
    "print(sess.run(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# OR GATE\n",
    "T,F =1., -1.   # o doesn't give correct o/p for false hence we take -1  \n",
    "bias=1\n",
    "train_in=[\n",
    "    [T,T,bias],\n",
    "    [T,F,bias],\n",
    "    [F,T,bias],\n",
    "    [F,F,bias]\n",
    "]\n",
    "train_out=[\n",
    "    [T],\n",
    "    [T],\n",
    "    [T],\n",
    "    [F]\n",
    "]\n",
    "\n",
    "w=tf.Variable(tf.random_normal([3,1]))\n",
    "\n",
    "# step(x)={1 IF X>0; -1 otherwise}\n",
    "def step(x):\n",
    "    is_greater=tf.greater(x,0)\n",
    "    as_float=tf.to_float(is_greater)\n",
    "    doubled=tf.multiply(as_float,2)\n",
    "    return tf.subtract(doubled,1)\n",
    "\n",
    "output = step(tf.matmul(train_in,w))\n",
    "error=tf.subtract(train_out,output)\n",
    "mse=tf.reduce_mean(tf.square(error))\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(output))\n",
    "print(sess.run(error))\n",
    "print(sess.run(mse))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
