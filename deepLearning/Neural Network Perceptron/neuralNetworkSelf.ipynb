{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "epoch :  0  -  cost:  0.68764603\n",
      "epoch :  1  -  cost:  0.6843908\n",
      "epoch :  2  -  cost:  0.6818702\n",
      "epoch :  3  -  cost:  0.67961293\n",
      "epoch :  4  -  cost:  0.67747086\n",
      "epoch :  5  -  cost:  0.67539614\n",
      "epoch :  6  -  cost:  0.67337245\n",
      "epoch :  7  -  cost:  0.67139345\n",
      "epoch :  8  -  cost:  0.669456\n",
      "epoch :  9  -  cost:  0.6675579\n",
      "epoch :  10  -  cost:  0.6656975\n",
      "epoch :  11  -  cost:  0.66387314\n",
      "epoch :  12  -  cost:  0.66208357\n",
      "epoch :  13  -  cost:  0.6603273\n",
      "epoch :  14  -  cost:  0.6586031\n",
      "epoch :  15  -  cost:  0.65690964\n",
      "epoch :  16  -  cost:  0.65524596\n",
      "epoch :  17  -  cost:  0.65361094\n",
      "epoch :  18  -  cost:  0.6520033\n",
      "epoch :  19  -  cost:  0.6504222\n",
      "epoch :  20  -  cost:  0.6488668\n",
      "epoch :  21  -  cost:  0.647336\n",
      "epoch :  22  -  cost:  0.64582914\n",
      "epoch :  23  -  cost:  0.64434534\n",
      "epoch :  24  -  cost:  0.64288366\n",
      "epoch :  25  -  cost:  0.64144367\n",
      "epoch :  26  -  cost:  0.6400244\n",
      "epoch :  27  -  cost:  0.6386254\n",
      "epoch :  28  -  cost:  0.6372459\n",
      "epoch :  29  -  cost:  0.6358853\n",
      "epoch :  30  -  cost:  0.63454306\n",
      "epoch :  31  -  cost:  0.6332187\n",
      "epoch :  32  -  cost:  0.6319116\n",
      "epoch :  33  -  cost:  0.6306214\n",
      "epoch :  34  -  cost:  0.62934744\n",
      "epoch :  35  -  cost:  0.6280893\n",
      "epoch :  36  -  cost:  0.6268467\n",
      "epoch :  37  -  cost:  0.62561905\n",
      "epoch :  38  -  cost:  0.62440604\n",
      "epoch :  39  -  cost:  0.6232073\n",
      "epoch :  40  -  cost:  0.62202245\n",
      "epoch :  41  -  cost:  0.6208511\n",
      "epoch :  42  -  cost:  0.61969304\n",
      "epoch :  43  -  cost:  0.6185479\n",
      "epoch :  44  -  cost:  0.6174153\n",
      "epoch :  45  -  cost:  0.61629504\n",
      "epoch :  46  -  cost:  0.61518675\n",
      "epoch :  47  -  cost:  0.6140903\n",
      "epoch :  48  -  cost:  0.6130053\n",
      "epoch :  49  -  cost:  0.61193156\n",
      "epoch :  50  -  cost:  0.6108689\n",
      "epoch :  51  -  cost:  0.6098169\n",
      "epoch :  52  -  cost:  0.6087755\n",
      "epoch :  53  -  cost:  0.6077444\n",
      "epoch :  54  -  cost:  0.6067236\n",
      "epoch :  55  -  cost:  0.60571265\n",
      "epoch :  56  -  cost:  0.60471153\n",
      "epoch :  57  -  cost:  0.6037199\n",
      "epoch :  58  -  cost:  0.6027377\n",
      "epoch :  59  -  cost:  0.6017648\n",
      "epoch :  60  -  cost:  0.6008009\n",
      "epoch :  61  -  cost:  0.5998458\n",
      "epoch :  62  -  cost:  0.59889966\n",
      "epoch :  63  -  cost:  0.5979619\n",
      "epoch :  64  -  cost:  0.5970327\n",
      "epoch :  65  -  cost:  0.5961119\n",
      "epoch :  66  -  cost:  0.59519917\n",
      "epoch :  67  -  cost:  0.59429455\n",
      "epoch :  68  -  cost:  0.59339786\n",
      "epoch :  69  -  cost:  0.5925089\n",
      "epoch :  70  -  cost:  0.5916276\n",
      "epoch :  71  -  cost:  0.5907539\n",
      "epoch :  72  -  cost:  0.5898876\n",
      "epoch :  73  -  cost:  0.5890287\n",
      "epoch :  74  -  cost:  0.588177\n",
      "epoch :  75  -  cost:  0.58733237\n",
      "epoch :  76  -  cost:  0.58649474\n",
      "epoch :  77  -  cost:  0.58566415\n",
      "epoch :  78  -  cost:  0.58484024\n",
      "epoch :  79  -  cost:  0.5840232\n",
      "epoch :  80  -  cost:  0.5832126\n",
      "epoch :  81  -  cost:  0.5824086\n",
      "epoch :  82  -  cost:  0.58161116\n",
      "epoch :  83  -  cost:  0.58081996\n",
      "epoch :  84  -  cost:  0.5800352\n",
      "epoch :  85  -  cost:  0.5792565\n",
      "epoch :  86  -  cost:  0.5784839\n",
      "epoch :  87  -  cost:  0.5777174\n",
      "epoch :  88  -  cost:  0.57695687\n",
      "epoch :  89  -  cost:  0.57620215\n",
      "epoch :  90  -  cost:  0.5754533\n",
      "epoch :  91  -  cost:  0.57471025\n",
      "epoch :  92  -  cost:  0.5739728\n",
      "epoch :  93  -  cost:  0.57324094\n",
      "epoch :  94  -  cost:  0.57251465\n",
      "epoch :  95  -  cost:  0.5717938\n",
      "epoch :  96  -  cost:  0.57107836\n",
      "epoch :  97  -  cost:  0.57036823\n",
      "epoch :  98  -  cost:  0.56966335\n",
      "epoch :  99  -  cost:  0.56896377\n",
      "epoch :  100  -  cost:  0.56826925\n",
      "epoch :  101  -  cost:  0.5675799\n",
      "epoch :  102  -  cost:  0.5668955\n",
      "epoch :  103  -  cost:  0.5662161\n",
      "epoch :  104  -  cost:  0.5655416\n",
      "epoch :  105  -  cost:  0.564872\n",
      "epoch :  106  -  cost:  0.5642073\n",
      "epoch :  107  -  cost:  0.56354725\n",
      "epoch :  108  -  cost:  0.5628919\n",
      "epoch :  109  -  cost:  0.56224114\n",
      "epoch :  110  -  cost:  0.56159514\n",
      "epoch :  111  -  cost:  0.56095356\n",
      "epoch :  112  -  cost:  0.56031644\n",
      "epoch :  113  -  cost:  0.55968386\n",
      "epoch :  114  -  cost:  0.5590556\n",
      "epoch :  115  -  cost:  0.5584318\n",
      "epoch :  116  -  cost:  0.5578123\n",
      "epoch :  117  -  cost:  0.55719703\n",
      "epoch :  118  -  cost:  0.5565859\n",
      "epoch :  119  -  cost:  0.555979\n",
      "epoch :  120  -  cost:  0.55537623\n",
      "epoch :  121  -  cost:  0.55477756\n",
      "epoch :  122  -  cost:  0.55418295\n",
      "epoch :  123  -  cost:  0.55359226\n",
      "epoch :  124  -  cost:  0.55300564\n",
      "epoch :  125  -  cost:  0.5524229\n",
      "epoch :  126  -  cost:  0.55184394\n",
      "epoch :  127  -  cost:  0.551269\n",
      "epoch :  128  -  cost:  0.5506976\n",
      "epoch :  129  -  cost:  0.5501302\n",
      "epoch :  130  -  cost:  0.54956645\n",
      "epoch :  131  -  cost:  0.54900634\n",
      "epoch :  132  -  cost:  0.54844993\n",
      "epoch :  133  -  cost:  0.54789716\n",
      "epoch :  134  -  cost:  0.5473479\n",
      "epoch :  135  -  cost:  0.5468022\n",
      "epoch :  136  -  cost:  0.54626\n",
      "epoch :  137  -  cost:  0.54572123\n",
      "epoch :  138  -  cost:  0.545186\n",
      "epoch :  139  -  cost:  0.5446542\n",
      "epoch :  140  -  cost:  0.5441256\n",
      "epoch :  141  -  cost:  0.5436005\n",
      "epoch :  142  -  cost:  0.54307866\n",
      "epoch :  143  -  cost:  0.5425601\n",
      "epoch :  144  -  cost:  0.5420447\n",
      "epoch :  145  -  cost:  0.5415326\n",
      "epoch :  146  -  cost:  0.5410237\n",
      "epoch :  147  -  cost:  0.5405178\n",
      "epoch :  148  -  cost:  0.54001516\n",
      "epoch :  149  -  cost:  0.53951555\n",
      "epoch :  150  -  cost:  0.53901905\n",
      "epoch :  151  -  cost:  0.5385255\n",
      "epoch :  152  -  cost:  0.5380351\n",
      "epoch :  153  -  cost:  0.5375476\n",
      "epoch :  154  -  cost:  0.53706306\n",
      "epoch :  155  -  cost:  0.5365814\n",
      "epoch :  156  -  cost:  0.5361026\n",
      "epoch :  157  -  cost:  0.53562677\n",
      "epoch :  158  -  cost:  0.53515375\n",
      "epoch :  159  -  cost:  0.5346835\n",
      "epoch :  160  -  cost:  0.53421605\n",
      "epoch :  161  -  cost:  0.53375137\n",
      "epoch :  162  -  cost:  0.5332895\n",
      "epoch :  163  -  cost:  0.53283024\n",
      "epoch :  164  -  cost:  0.5323737\n",
      "epoch :  165  -  cost:  0.5319199\n",
      "epoch :  166  -  cost:  0.53146863\n",
      "epoch :  167  -  cost:  0.5310201\n",
      "epoch :  168  -  cost:  0.530574\n",
      "epoch :  169  -  cost:  0.53013057\n",
      "epoch :  170  -  cost:  0.52968967\n",
      "epoch :  171  -  cost:  0.52925134\n",
      "epoch :  172  -  cost:  0.52881545\n",
      "epoch :  173  -  cost:  0.52838206\n",
      "epoch :  174  -  cost:  0.5279511\n",
      "epoch :  175  -  cost:  0.5275226\n",
      "epoch :  176  -  cost:  0.52709657\n",
      "epoch :  177  -  cost:  0.52667284\n",
      "epoch :  178  -  cost:  0.5262515\n",
      "epoch :  179  -  cost:  0.52583265\n",
      "epoch :  180  -  cost:  0.52541596\n",
      "epoch :  181  -  cost:  0.52500165\n",
      "epoch :  182  -  cost:  0.5245896\n",
      "epoch :  183  -  cost:  0.5241799\n",
      "epoch :  184  -  cost:  0.5237723\n",
      "epoch :  185  -  cost:  0.52336705\n",
      "epoch :  186  -  cost:  0.522964\n",
      "epoch :  187  -  cost:  0.52256316\n",
      "epoch :  188  -  cost:  0.5221644\n",
      "epoch :  189  -  cost:  0.52176785\n",
      "epoch :  190  -  cost:  0.5213735\n",
      "epoch :  191  -  cost:  0.52098125\n",
      "epoch :  192  -  cost:  0.520591\n",
      "epoch :  193  -  cost:  0.52020293\n",
      "epoch :  194  -  cost:  0.51981694\n",
      "epoch :  195  -  cost:  0.51943296\n",
      "epoch :  196  -  cost:  0.5190511\n",
      "epoch :  197  -  cost:  0.51867115\n",
      "epoch :  198  -  cost:  0.51829326\n",
      "epoch :  199  -  cost:  0.5179172\n",
      "epoch :  200  -  cost:  0.5175433\n",
      "epoch :  201  -  cost:  0.51717126\n",
      "epoch :  202  -  cost:  0.51680124\n",
      "epoch :  203  -  cost:  0.51643306\n",
      "epoch :  204  -  cost:  0.5160668\n",
      "epoch :  205  -  cost:  0.5157024\n",
      "epoch :  206  -  cost:  0.5153399\n",
      "epoch :  207  -  cost:  0.51497924\n",
      "epoch :  208  -  cost:  0.5146204\n",
      "epoch :  209  -  cost:  0.51426345\n",
      "epoch :  210  -  cost:  0.51390827\n",
      "epoch :  211  -  cost:  0.51355493\n",
      "epoch :  212  -  cost:  0.5132033\n",
      "epoch :  213  -  cost:  0.5128535\n",
      "epoch :  214  -  cost:  0.5125054\n",
      "epoch :  215  -  cost:  0.5121591\n",
      "epoch :  216  -  cost:  0.5118145\n",
      "epoch :  217  -  cost:  0.5114716\n",
      "epoch :  218  -  cost:  0.5111304\n",
      "epoch :  219  -  cost:  0.5107909\n",
      "epoch :  220  -  cost:  0.5104531\n",
      "epoch :  221  -  cost:  0.5101169\n",
      "epoch :  222  -  cost:  0.5097824\n",
      "epoch :  223  -  cost:  0.5094495\n",
      "epoch :  224  -  cost:  0.50911826\n",
      "epoch :  225  -  cost:  0.5087885\n",
      "epoch :  226  -  cost:  0.5084605\n",
      "epoch :  227  -  cost:  0.50813395\n",
      "epoch :  228  -  cost:  0.5078091\n",
      "epoch :  229  -  cost:  0.5074857\n",
      "epoch :  230  -  cost:  0.5071639\n",
      "epoch :  231  -  cost:  0.50684357\n",
      "epoch :  232  -  cost:  0.50652486\n",
      "epoch :  233  -  cost:  0.50620764\n",
      "epoch :  234  -  cost:  0.5058918\n",
      "epoch :  235  -  cost:  0.5055776\n",
      "epoch :  236  -  cost:  0.50526476\n",
      "epoch :  237  -  cost:  0.5049535\n",
      "epoch :  238  -  cost:  0.5046437\n",
      "epoch :  239  -  cost:  0.5043352\n",
      "epoch :  240  -  cost:  0.50402826\n",
      "epoch :  241  -  cost:  0.50372267\n",
      "epoch :  242  -  cost:  0.5034185\n",
      "epoch :  243  -  cost:  0.5031157\n",
      "epoch :  244  -  cost:  0.5028144\n",
      "epoch :  245  -  cost:  0.50251436\n",
      "epoch :  246  -  cost:  0.50221586\n",
      "epoch :  247  -  cost:  0.50191855\n",
      "epoch :  248  -  cost:  0.5016226\n",
      "epoch :  249  -  cost:  0.5013282\n",
      "epoch :  250  -  cost:  0.5010349\n",
      "epoch :  251  -  cost:  0.50074303\n",
      "epoch :  252  -  cost:  0.5004524\n",
      "epoch :  253  -  cost:  0.5001631\n",
      "epoch :  254  -  cost:  0.49987507\n",
      "epoch :  255  -  cost:  0.49958837\n",
      "epoch :  256  -  cost:  0.49930292\n",
      "epoch :  257  -  cost:  0.49901876\n",
      "epoch :  258  -  cost:  0.4987358\n",
      "epoch :  259  -  cost:  0.4984541\n",
      "epoch :  260  -  cost:  0.49817362\n",
      "epoch :  261  -  cost:  0.49789447\n",
      "epoch :  262  -  cost:  0.49761638\n",
      "epoch :  263  -  cost:  0.4973396\n",
      "epoch :  264  -  cost:  0.49706396\n",
      "epoch :  265  -  cost:  0.49678957\n",
      "epoch :  266  -  cost:  0.49651635\n",
      "epoch :  267  -  cost:  0.4962443\n",
      "epoch :  268  -  cost:  0.49597344\n",
      "epoch :  269  -  cost:  0.4957038\n",
      "epoch :  270  -  cost:  0.49543518\n",
      "epoch :  271  -  cost:  0.49516773\n",
      "epoch :  272  -  cost:  0.49490145\n",
      "epoch :  273  -  cost:  0.4946363\n",
      "epoch :  274  -  cost:  0.49437222\n",
      "epoch :  275  -  cost:  0.49410927\n",
      "epoch :  276  -  cost:  0.4938475\n",
      "epoch :  277  -  cost:  0.49358672\n",
      "epoch :  278  -  cost:  0.49332714\n",
      "epoch :  279  -  cost:  0.49306852\n",
      "epoch :  280  -  cost:  0.49281105\n",
      "epoch :  281  -  cost:  0.49255463\n",
      "epoch :  282  -  cost:  0.49229923\n",
      "epoch :  283  -  cost:  0.49204493\n",
      "epoch :  284  -  cost:  0.4917917\n",
      "epoch :  285  -  cost:  0.49153945\n",
      "epoch :  286  -  cost:  0.49128824\n",
      "epoch :  287  -  cost:  0.49103802\n",
      "epoch :  288  -  cost:  0.49078894\n",
      "epoch :  289  -  cost:  0.49054074\n",
      "epoch :  290  -  cost:  0.49029362\n",
      "epoch :  291  -  cost:  0.49004745\n",
      "epoch :  292  -  cost:  0.4898023\n",
      "epoch :  293  -  cost:  0.48955816\n",
      "epoch :  294  -  cost:  0.48931488\n",
      "epoch :  295  -  cost:  0.48907265\n",
      "epoch :  296  -  cost:  0.48883134\n",
      "epoch :  297  -  cost:  0.4885911\n",
      "epoch :  298  -  cost:  0.4883517\n",
      "epoch :  299  -  cost:  0.48811334\n",
      "epoch :  300  -  cost:  0.48787585\n",
      "epoch :  301  -  cost:  0.48763928\n",
      "epoch :  302  -  cost:  0.4874036\n",
      "epoch :  303  -  cost:  0.48716897\n",
      "epoch :  304  -  cost:  0.48693517\n",
      "epoch :  305  -  cost:  0.4867023\n",
      "epoch :  306  -  cost:  0.48647028\n",
      "epoch :  307  -  cost:  0.4862392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  308  -  cost:  0.48600906\n",
      "epoch :  309  -  cost:  0.48577973\n",
      "epoch :  310  -  cost:  0.4855513\n",
      "epoch :  311  -  cost:  0.4853237\n",
      "epoch :  312  -  cost:  0.48509708\n",
      "epoch :  313  -  cost:  0.48487124\n",
      "epoch :  314  -  cost:  0.4846462\n",
      "epoch :  315  -  cost:  0.48442212\n",
      "epoch :  316  -  cost:  0.48419887\n",
      "epoch :  317  -  cost:  0.4839764\n",
      "epoch :  318  -  cost:  0.4837548\n",
      "epoch :  319  -  cost:  0.48353398\n",
      "epoch :  320  -  cost:  0.4833141\n",
      "epoch :  321  -  cost:  0.48309493\n",
      "epoch :  322  -  cost:  0.48287666\n",
      "epoch :  323  -  cost:  0.48265907\n",
      "epoch :  324  -  cost:  0.48244238\n",
      "epoch :  325  -  cost:  0.4822265\n",
      "epoch :  326  -  cost:  0.4820114\n",
      "epoch :  327  -  cost:  0.4817971\n",
      "epoch :  328  -  cost:  0.48158357\n",
      "epoch :  329  -  cost:  0.48137078\n",
      "epoch :  330  -  cost:  0.48115876\n",
      "epoch :  331  -  cost:  0.4809476\n",
      "epoch :  332  -  cost:  0.48073712\n",
      "epoch :  333  -  cost:  0.48052743\n",
      "epoch :  334  -  cost:  0.48031852\n",
      "epoch :  335  -  cost:  0.48011035\n",
      "epoch :  336  -  cost:  0.4799029\n",
      "epoch :  337  -  cost:  0.4796962\n",
      "epoch :  338  -  cost:  0.47949025\n",
      "epoch :  339  -  cost:  0.479285\n",
      "epoch :  340  -  cost:  0.47908056\n",
      "epoch :  341  -  cost:  0.47887674\n",
      "epoch :  342  -  cost:  0.4786737\n",
      "epoch :  343  -  cost:  0.4784713\n",
      "epoch :  344  -  cost:  0.47826973\n",
      "epoch :  345  -  cost:  0.4780688\n",
      "epoch :  346  -  cost:  0.4778686\n",
      "epoch :  347  -  cost:  0.477669\n",
      "epoch :  348  -  cost:  0.47747022\n",
      "epoch :  349  -  cost:  0.4772721\n",
      "epoch :  350  -  cost:  0.47707462\n",
      "epoch :  351  -  cost:  0.47687787\n",
      "epoch :  352  -  cost:  0.4766817\n",
      "epoch :  353  -  cost:  0.47648636\n",
      "epoch :  354  -  cost:  0.4762916\n",
      "epoch :  355  -  cost:  0.47609752\n",
      "epoch :  356  -  cost:  0.4759041\n",
      "epoch :  357  -  cost:  0.4757114\n",
      "epoch :  358  -  cost:  0.4755193\n",
      "epoch :  359  -  cost:  0.4753278\n",
      "epoch :  360  -  cost:  0.47513697\n",
      "epoch :  361  -  cost:  0.47494683\n",
      "epoch :  362  -  cost:  0.47475728\n",
      "epoch :  363  -  cost:  0.47456837\n",
      "epoch :  364  -  cost:  0.47438014\n",
      "epoch :  365  -  cost:  0.47419247\n",
      "epoch :  366  -  cost:  0.4740055\n",
      "epoch :  367  -  cost:  0.47381905\n",
      "epoch :  368  -  cost:  0.47363332\n",
      "epoch :  369  -  cost:  0.4734481\n",
      "epoch :  370  -  cost:  0.47326362\n",
      "epoch :  371  -  cost:  0.47307968\n",
      "epoch :  372  -  cost:  0.47289634\n",
      "epoch :  373  -  cost:  0.47271356\n",
      "epoch :  374  -  cost:  0.47253147\n",
      "epoch :  375  -  cost:  0.47234988\n",
      "epoch :  376  -  cost:  0.47216892\n",
      "epoch :  377  -  cost:  0.47198853\n",
      "epoch :  378  -  cost:  0.4718088\n",
      "epoch :  379  -  cost:  0.4716296\n",
      "epoch :  380  -  cost:  0.47145095\n",
      "epoch :  381  -  cost:  0.4712729\n",
      "epoch :  382  -  cost:  0.47109538\n",
      "epoch :  383  -  cost:  0.47091845\n",
      "epoch :  384  -  cost:  0.47074214\n",
      "epoch :  385  -  cost:  0.4705664\n",
      "epoch :  386  -  cost:  0.4703911\n",
      "epoch :  387  -  cost:  0.47021636\n",
      "epoch :  388  -  cost:  0.47004232\n",
      "epoch :  389  -  cost:  0.46986872\n",
      "epoch :  390  -  cost:  0.4696957\n",
      "epoch :  391  -  cost:  0.4695232\n",
      "epoch :  392  -  cost:  0.46935126\n",
      "epoch :  393  -  cost:  0.46917978\n",
      "epoch :  394  -  cost:  0.46900883\n",
      "epoch :  395  -  cost:  0.46883857\n",
      "epoch :  396  -  cost:  0.46866873\n",
      "epoch :  397  -  cost:  0.46849948\n",
      "epoch :  398  -  cost:  0.46833065\n",
      "epoch :  399  -  cost:  0.4681624\n",
      "epoch :  400  -  cost:  0.46799463\n",
      "epoch :  401  -  cost:  0.4678274\n",
      "epoch :  402  -  cost:  0.46766075\n",
      "epoch :  403  -  cost:  0.46749455\n",
      "epoch :  404  -  cost:  0.46732873\n",
      "epoch :  405  -  cost:  0.4671636\n",
      "epoch :  406  -  cost:  0.46699888\n",
      "epoch :  407  -  cost:  0.4668347\n",
      "epoch :  408  -  cost:  0.466671\n",
      "epoch :  409  -  cost:  0.46650773\n",
      "epoch :  410  -  cost:  0.46634507\n",
      "epoch :  411  -  cost:  0.46618286\n",
      "epoch :  412  -  cost:  0.46602106\n",
      "epoch :  413  -  cost:  0.4658598\n",
      "epoch :  414  -  cost:  0.465699\n",
      "epoch :  415  -  cost:  0.4655387\n",
      "epoch :  416  -  cost:  0.46537885\n",
      "epoch :  417  -  cost:  0.46521953\n",
      "epoch :  418  -  cost:  0.46506053\n",
      "epoch :  419  -  cost:  0.46490222\n",
      "epoch :  420  -  cost:  0.4647442\n",
      "epoch :  421  -  cost:  0.4645867\n",
      "epoch :  422  -  cost:  0.46442965\n",
      "epoch :  423  -  cost:  0.46427307\n",
      "epoch :  424  -  cost:  0.464117\n",
      "epoch :  425  -  cost:  0.46396127\n",
      "epoch :  426  -  cost:  0.46380606\n",
      "epoch :  427  -  cost:  0.4636512\n",
      "epoch :  428  -  cost:  0.46349692\n",
      "epoch :  429  -  cost:  0.4633431\n",
      "epoch :  430  -  cost:  0.4631896\n",
      "epoch :  431  -  cost:  0.46303663\n",
      "epoch :  432  -  cost:  0.46288404\n",
      "epoch :  433  -  cost:  0.46273193\n",
      "epoch :  434  -  cost:  0.4625802\n",
      "epoch :  435  -  cost:  0.4624289\n",
      "epoch :  436  -  cost:  0.46227813\n",
      "epoch :  437  -  cost:  0.46212763\n",
      "epoch :  438  -  cost:  0.46197766\n",
      "epoch :  439  -  cost:  0.4618281\n",
      "epoch :  440  -  cost:  0.46167892\n",
      "epoch :  441  -  cost:  0.4615302\n",
      "epoch :  442  -  cost:  0.46138188\n",
      "epoch :  443  -  cost:  0.46123403\n",
      "epoch :  444  -  cost:  0.46108654\n",
      "epoch :  445  -  cost:  0.46093944\n",
      "epoch :  446  -  cost:  0.46079278\n",
      "epoch :  447  -  cost:  0.46064654\n",
      "epoch :  448  -  cost:  0.4605006\n",
      "epoch :  449  -  cost:  0.4603552\n",
      "epoch :  450  -  cost:  0.46021008\n",
      "epoch :  451  -  cost:  0.46006545\n",
      "epoch :  452  -  cost:  0.45992118\n",
      "epoch :  453  -  cost:  0.45977727\n",
      "epoch :  454  -  cost:  0.45963374\n",
      "epoch :  455  -  cost:  0.45949072\n",
      "epoch :  456  -  cost:  0.45934802\n",
      "epoch :  457  -  cost:  0.4592057\n",
      "epoch :  458  -  cost:  0.4590637\n",
      "epoch :  459  -  cost:  0.45892218\n",
      "epoch :  460  -  cost:  0.458781\n",
      "epoch :  461  -  cost:  0.4586402\n",
      "epoch :  462  -  cost:  0.45849976\n",
      "epoch :  463  -  cost:  0.45835978\n",
      "epoch :  464  -  cost:  0.4582201\n",
      "epoch :  465  -  cost:  0.4580808\n",
      "epoch :  466  -  cost:  0.45794186\n",
      "epoch :  467  -  cost:  0.45780328\n",
      "epoch :  468  -  cost:  0.45766515\n",
      "epoch :  469  -  cost:  0.4575273\n",
      "epoch :  470  -  cost:  0.45738983\n",
      "epoch :  471  -  cost:  0.45725268\n",
      "epoch :  472  -  cost:  0.457116\n",
      "epoch :  473  -  cost:  0.4569796\n",
      "epoch :  474  -  cost:  0.45684355\n",
      "epoch :  475  -  cost:  0.45670786\n",
      "epoch :  476  -  cost:  0.45657253\n",
      "epoch :  477  -  cost:  0.4564376\n",
      "epoch :  478  -  cost:  0.4563029\n",
      "epoch :  479  -  cost:  0.45616868\n",
      "epoch :  480  -  cost:  0.45603475\n",
      "epoch :  481  -  cost:  0.45590118\n",
      "epoch :  482  -  cost:  0.4557679\n",
      "epoch :  483  -  cost:  0.455635\n",
      "epoch :  484  -  cost:  0.45550242\n",
      "epoch :  485  -  cost:  0.4553702\n",
      "epoch :  486  -  cost:  0.45523834\n",
      "epoch :  487  -  cost:  0.4551068\n",
      "epoch :  488  -  cost:  0.45497558\n",
      "epoch :  489  -  cost:  0.45484468\n",
      "epoch :  490  -  cost:  0.45471412\n",
      "epoch :  491  -  cost:  0.45458397\n",
      "epoch :  492  -  cost:  0.45445397\n",
      "epoch :  493  -  cost:  0.45432448\n",
      "epoch :  494  -  cost:  0.45419523\n",
      "epoch :  495  -  cost:  0.45406628\n",
      "epoch :  496  -  cost:  0.45393768\n",
      "epoch :  497  -  cost:  0.45380935\n",
      "epoch :  498  -  cost:  0.45368144\n",
      "epoch :  499  -  cost:  0.45355377\n",
      "epoch :  500  -  cost:  0.45342645\n",
      "epoch :  501  -  cost:  0.45329943\n",
      "epoch :  502  -  cost:  0.45317274\n",
      "epoch :  503  -  cost:  0.45304635\n",
      "epoch :  504  -  cost:  0.4529202\n",
      "epoch :  505  -  cost:  0.45279446\n",
      "epoch :  506  -  cost:  0.45266902\n",
      "epoch :  507  -  cost:  0.45254382\n",
      "epoch :  508  -  cost:  0.452419\n",
      "epoch :  509  -  cost:  0.45229444\n",
      "epoch :  510  -  cost:  0.45217016\n",
      "epoch :  511  -  cost:  0.45204622\n",
      "epoch :  512  -  cost:  0.45192263\n",
      "epoch :  513  -  cost:  0.45179924\n",
      "epoch :  514  -  cost:  0.45167616\n",
      "epoch :  515  -  cost:  0.45155343\n",
      "epoch :  516  -  cost:  0.451431\n",
      "epoch :  517  -  cost:  0.4513088\n",
      "epoch :  518  -  cost:  0.4511869\n",
      "epoch :  519  -  cost:  0.4510654\n",
      "epoch :  520  -  cost:  0.450944\n",
      "epoch :  521  -  cost:  0.45082298\n",
      "epoch :  522  -  cost:  0.45070225\n",
      "epoch :  523  -  cost:  0.45058188\n",
      "epoch :  524  -  cost:  0.45046175\n",
      "epoch :  525  -  cost:  0.45034182\n",
      "epoch :  526  -  cost:  0.4502222\n",
      "epoch :  527  -  cost:  0.4501029\n",
      "epoch :  528  -  cost:  0.4499839\n",
      "epoch :  529  -  cost:  0.44986513\n",
      "epoch :  530  -  cost:  0.4497467\n",
      "epoch :  531  -  cost:  0.44962847\n",
      "epoch :  532  -  cost:  0.44951054\n",
      "epoch :  533  -  cost:  0.44939288\n",
      "epoch :  534  -  cost:  0.44927555\n",
      "epoch :  535  -  cost:  0.44915846\n",
      "epoch :  536  -  cost:  0.44904158\n",
      "epoch :  537  -  cost:  0.44892496\n",
      "epoch :  538  -  cost:  0.44880873\n",
      "epoch :  539  -  cost:  0.44869268\n",
      "epoch :  540  -  cost:  0.44857693\n",
      "epoch :  541  -  cost:  0.44846147\n",
      "epoch :  542  -  cost:  0.44834614\n",
      "epoch :  543  -  cost:  0.44823125\n",
      "epoch :  544  -  cost:  0.44811648\n",
      "epoch :  545  -  cost:  0.44800204\n",
      "epoch :  546  -  cost:  0.44788784\n",
      "epoch :  547  -  cost:  0.44777384\n",
      "epoch :  548  -  cost:  0.44766024\n",
      "epoch :  549  -  cost:  0.44754675\n",
      "epoch :  550  -  cost:  0.44743362\n",
      "epoch :  551  -  cost:  0.44732064\n",
      "epoch :  552  -  cost:  0.44720805\n",
      "epoch :  553  -  cost:  0.44709563\n",
      "epoch :  554  -  cost:  0.44698343\n",
      "epoch :  555  -  cost:  0.44687152\n",
      "epoch :  556  -  cost:  0.44675982\n",
      "epoch :  557  -  cost:  0.44664842\n",
      "epoch :  558  -  cost:  0.44653726\n",
      "epoch :  559  -  cost:  0.44642633\n",
      "epoch :  560  -  cost:  0.44631562\n",
      "epoch :  561  -  cost:  0.4462052\n",
      "epoch :  562  -  cost:  0.44609496\n",
      "epoch :  563  -  cost:  0.44598508\n",
      "epoch :  564  -  cost:  0.44587532\n",
      "epoch :  565  -  cost:  0.4457658\n",
      "epoch :  566  -  cost:  0.44565666\n",
      "epoch :  567  -  cost:  0.44554764\n",
      "epoch :  568  -  cost:  0.4454389\n",
      "epoch :  569  -  cost:  0.44533038\n",
      "epoch :  570  -  cost:  0.445222\n",
      "epoch :  571  -  cost:  0.44511396\n",
      "epoch :  572  -  cost:  0.44500613\n",
      "epoch :  573  -  cost:  0.44489855\n",
      "epoch :  574  -  cost:  0.44479123\n",
      "epoch :  575  -  cost:  0.4446841\n",
      "epoch :  576  -  cost:  0.44457713\n",
      "epoch :  577  -  cost:  0.4444705\n",
      "epoch :  578  -  cost:  0.444364\n",
      "epoch :  579  -  cost:  0.44425786\n",
      "epoch :  580  -  cost:  0.4441518\n",
      "epoch :  581  -  cost:  0.4440461\n",
      "epoch :  582  -  cost:  0.44394046\n",
      "epoch :  583  -  cost:  0.4438352\n",
      "epoch :  584  -  cost:  0.4437301\n",
      "epoch :  585  -  cost:  0.4436252\n",
      "epoch :  586  -  cost:  0.44352052\n",
      "epoch :  587  -  cost:  0.4434161\n",
      "epoch :  588  -  cost:  0.44331184\n",
      "epoch :  589  -  cost:  0.44320783\n",
      "epoch :  590  -  cost:  0.44310406\n",
      "epoch :  591  -  cost:  0.44300047\n",
      "epoch :  592  -  cost:  0.4428971\n",
      "epoch :  593  -  cost:  0.44279402\n",
      "epoch :  594  -  cost:  0.44269106\n",
      "epoch :  595  -  cost:  0.44258836\n",
      "epoch :  596  -  cost:  0.44248587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  597  -  cost:  0.44238356\n",
      "epoch :  598  -  cost:  0.44228148\n",
      "epoch :  599  -  cost:  0.4421796\n",
      "epoch :  600  -  cost:  0.4420779\n",
      "epoch :  601  -  cost:  0.44197643\n",
      "epoch :  602  -  cost:  0.44187522\n",
      "epoch :  603  -  cost:  0.44177416\n",
      "epoch :  604  -  cost:  0.44167337\n",
      "epoch :  605  -  cost:  0.44157267\n",
      "epoch :  606  -  cost:  0.4414723\n",
      "epoch :  607  -  cost:  0.4413721\n",
      "epoch :  608  -  cost:  0.44127205\n",
      "epoch :  609  -  cost:  0.4411722\n",
      "epoch :  610  -  cost:  0.4410726\n",
      "epoch :  611  -  cost:  0.44097316\n",
      "epoch :  612  -  cost:  0.44087395\n",
      "epoch :  613  -  cost:  0.4407749\n",
      "epoch :  614  -  cost:  0.44067612\n",
      "epoch :  615  -  cost:  0.4405775\n",
      "epoch :  616  -  cost:  0.4404791\n",
      "epoch :  617  -  cost:  0.44038078\n",
      "epoch :  618  -  cost:  0.4402828\n",
      "epoch :  619  -  cost:  0.44018495\n",
      "epoch :  620  -  cost:  0.44008732\n",
      "epoch :  621  -  cost:  0.43998984\n",
      "epoch :  622  -  cost:  0.4398926\n",
      "epoch :  623  -  cost:  0.43979552\n",
      "epoch :  624  -  cost:  0.4396986\n",
      "epoch :  625  -  cost:  0.43960196\n",
      "epoch :  626  -  cost:  0.4395055\n",
      "epoch :  627  -  cost:  0.43940914\n",
      "epoch :  628  -  cost:  0.439313\n",
      "epoch :  629  -  cost:  0.43921703\n",
      "epoch :  630  -  cost:  0.43912125\n",
      "epoch :  631  -  cost:  0.43902573\n",
      "epoch :  632  -  cost:  0.43893036\n",
      "epoch :  633  -  cost:  0.4388352\n",
      "epoch :  634  -  cost:  0.43874013\n",
      "epoch :  635  -  cost:  0.43864527\n",
      "epoch :  636  -  cost:  0.4385506\n",
      "epoch :  637  -  cost:  0.4384562\n",
      "epoch :  638  -  cost:  0.43836194\n",
      "epoch :  639  -  cost:  0.4382678\n",
      "epoch :  640  -  cost:  0.43817392\n",
      "epoch :  641  -  cost:  0.4380801\n",
      "epoch :  642  -  cost:  0.43798658\n",
      "epoch :  643  -  cost:  0.43789315\n",
      "epoch :  644  -  cost:  0.4378\n",
      "epoch :  645  -  cost:  0.43770695\n",
      "epoch :  646  -  cost:  0.43761408\n",
      "epoch :  647  -  cost:  0.43752143\n",
      "epoch :  648  -  cost:  0.4374289\n",
      "epoch :  649  -  cost:  0.43733662\n",
      "epoch :  650  -  cost:  0.43724447\n",
      "epoch :  651  -  cost:  0.43715245\n",
      "epoch :  652  -  cost:  0.43706062\n",
      "epoch :  653  -  cost:  0.43696898\n",
      "epoch :  654  -  cost:  0.43687752\n",
      "epoch :  655  -  cost:  0.43678623\n",
      "epoch :  656  -  cost:  0.4366951\n",
      "epoch :  657  -  cost:  0.43660414\n",
      "epoch :  658  -  cost:  0.43651333\n",
      "epoch :  659  -  cost:  0.43642265\n",
      "epoch :  660  -  cost:  0.4363323\n",
      "epoch :  661  -  cost:  0.43624198\n",
      "epoch :  662  -  cost:  0.43615186\n",
      "epoch :  663  -  cost:  0.43606192\n",
      "epoch :  664  -  cost:  0.4359721\n",
      "epoch :  665  -  cost:  0.43588248\n",
      "epoch :  666  -  cost:  0.43579304\n",
      "epoch :  667  -  cost:  0.43570372\n",
      "epoch :  668  -  cost:  0.43561462\n",
      "epoch :  669  -  cost:  0.43552566\n",
      "epoch :  670  -  cost:  0.43543684\n",
      "epoch :  671  -  cost:  0.43534815\n",
      "epoch :  672  -  cost:  0.43525967\n",
      "epoch :  673  -  cost:  0.43517137\n",
      "epoch :  674  -  cost:  0.43508327\n",
      "epoch :  675  -  cost:  0.4349952\n",
      "epoch :  676  -  cost:  0.43490735\n",
      "epoch :  677  -  cost:  0.4348197\n",
      "epoch :  678  -  cost:  0.43473214\n",
      "epoch :  679  -  cost:  0.43464482\n",
      "epoch :  680  -  cost:  0.4345576\n",
      "epoch :  681  -  cost:  0.43447047\n",
      "epoch :  682  -  cost:  0.43438357\n",
      "epoch :  683  -  cost:  0.43429682\n",
      "epoch :  684  -  cost:  0.43421027\n",
      "epoch :  685  -  cost:  0.4341238\n",
      "epoch :  686  -  cost:  0.4340375\n",
      "epoch :  687  -  cost:  0.43395132\n",
      "epoch :  688  -  cost:  0.43386537\n",
      "epoch :  689  -  cost:  0.43377957\n",
      "epoch :  690  -  cost:  0.43369386\n",
      "epoch :  691  -  cost:  0.43360826\n",
      "epoch :  692  -  cost:  0.43352294\n",
      "epoch :  693  -  cost:  0.43343768\n",
      "epoch :  694  -  cost:  0.43335265\n",
      "epoch :  695  -  cost:  0.4332677\n",
      "epoch :  696  -  cost:  0.43318295\n",
      "epoch :  697  -  cost:  0.4330983\n",
      "epoch :  698  -  cost:  0.43301383\n",
      "epoch :  699  -  cost:  0.43292943\n",
      "epoch :  700  -  cost:  0.4328453\n",
      "epoch :  701  -  cost:  0.43276122\n",
      "epoch :  702  -  cost:  0.4326773\n",
      "epoch :  703  -  cost:  0.43259352\n",
      "epoch :  704  -  cost:  0.43250993\n",
      "epoch :  705  -  cost:  0.43242645\n",
      "epoch :  706  -  cost:  0.43234318\n",
      "epoch :  707  -  cost:  0.43225998\n",
      "epoch :  708  -  cost:  0.43217695\n",
      "epoch :  709  -  cost:  0.43209407\n",
      "epoch :  710  -  cost:  0.43201125\n",
      "epoch :  711  -  cost:  0.43192866\n",
      "epoch :  712  -  cost:  0.43184617\n",
      "epoch :  713  -  cost:  0.43176386\n",
      "epoch :  714  -  cost:  0.43168166\n",
      "epoch :  715  -  cost:  0.43159962\n",
      "epoch :  716  -  cost:  0.4315177\n",
      "epoch :  717  -  cost:  0.43143588\n",
      "epoch :  718  -  cost:  0.43135425\n",
      "epoch :  719  -  cost:  0.43127275\n",
      "epoch :  720  -  cost:  0.4311914\n",
      "epoch :  721  -  cost:  0.4311102\n",
      "epoch :  722  -  cost:  0.4310291\n",
      "epoch :  723  -  cost:  0.43094814\n",
      "epoch :  724  -  cost:  0.43086728\n",
      "epoch :  725  -  cost:  0.43078664\n",
      "epoch :  726  -  cost:  0.4307061\n",
      "epoch :  727  -  cost:  0.43062574\n",
      "epoch :  728  -  cost:  0.4305454\n",
      "epoch :  729  -  cost:  0.4304652\n",
      "epoch :  730  -  cost:  0.43038523\n",
      "epoch :  731  -  cost:  0.43030533\n",
      "epoch :  732  -  cost:  0.43022555\n",
      "epoch :  733  -  cost:  0.43014595\n",
      "epoch :  734  -  cost:  0.4300665\n",
      "epoch :  735  -  cost:  0.42998716\n",
      "epoch :  736  -  cost:  0.42990792\n",
      "epoch :  737  -  cost:  0.4298288\n",
      "epoch :  738  -  cost:  0.42974982\n",
      "epoch :  739  -  cost:  0.42967096\n",
      "epoch :  740  -  cost:  0.4295923\n",
      "epoch :  741  -  cost:  0.42951372\n",
      "epoch :  742  -  cost:  0.42943522\n",
      "epoch :  743  -  cost:  0.42935696\n",
      "epoch :  744  -  cost:  0.42927873\n",
      "epoch :  745  -  cost:  0.42920068\n",
      "epoch :  746  -  cost:  0.42912275\n",
      "epoch :  747  -  cost:  0.42904487\n",
      "epoch :  748  -  cost:  0.4289672\n",
      "epoch :  749  -  cost:  0.42888963\n",
      "epoch :  750  -  cost:  0.42881224\n",
      "epoch :  751  -  cost:  0.42873493\n",
      "epoch :  752  -  cost:  0.4286577\n",
      "epoch :  753  -  cost:  0.42858067\n",
      "epoch :  754  -  cost:  0.42850366\n",
      "epoch :  755  -  cost:  0.42842686\n",
      "epoch :  756  -  cost:  0.42835015\n",
      "epoch :  757  -  cost:  0.4282736\n",
      "epoch :  758  -  cost:  0.42819712\n",
      "epoch :  759  -  cost:  0.42812085\n",
      "epoch :  760  -  cost:  0.42804462\n",
      "epoch :  761  -  cost:  0.42796853\n",
      "epoch :  762  -  cost:  0.42789257\n",
      "epoch :  763  -  cost:  0.4278167\n",
      "epoch :  764  -  cost:  0.427741\n",
      "epoch :  765  -  cost:  0.4276653\n",
      "epoch :  766  -  cost:  0.42758983\n",
      "epoch :  767  -  cost:  0.42751446\n",
      "epoch :  768  -  cost:  0.4274392\n",
      "epoch :  769  -  cost:  0.42736408\n",
      "epoch :  770  -  cost:  0.427289\n",
      "epoch :  771  -  cost:  0.42721412\n",
      "epoch :  772  -  cost:  0.42713937\n",
      "epoch :  773  -  cost:  0.4270647\n",
      "epoch :  774  -  cost:  0.42699015\n",
      "epoch :  775  -  cost:  0.42691568\n",
      "epoch :  776  -  cost:  0.42684138\n",
      "epoch :  777  -  cost:  0.42676714\n",
      "epoch :  778  -  cost:  0.42669305\n",
      "epoch :  779  -  cost:  0.4266191\n",
      "epoch :  780  -  cost:  0.4265452\n",
      "epoch :  781  -  cost:  0.42647144\n",
      "epoch :  782  -  cost:  0.42639786\n",
      "epoch :  783  -  cost:  0.42632428\n",
      "epoch :  784  -  cost:  0.42625087\n",
      "epoch :  785  -  cost:  0.42617756\n",
      "epoch :  786  -  cost:  0.42610434\n",
      "epoch :  787  -  cost:  0.42603135\n",
      "epoch :  788  -  cost:  0.4259584\n",
      "epoch :  789  -  cost:  0.42588553\n",
      "epoch :  790  -  cost:  0.42581278\n",
      "epoch :  791  -  cost:  0.42574015\n",
      "epoch :  792  -  cost:  0.42566764\n",
      "epoch :  793  -  cost:  0.4255952\n",
      "epoch :  794  -  cost:  0.42552295\n",
      "epoch :  795  -  cost:  0.4254507\n",
      "epoch :  796  -  cost:  0.42537865\n",
      "epoch :  797  -  cost:  0.42530668\n",
      "epoch :  798  -  cost:  0.4252348\n",
      "epoch :  799  -  cost:  0.42516303\n",
      "epoch :  800  -  cost:  0.4250914\n",
      "epoch :  801  -  cost:  0.42501983\n",
      "epoch :  802  -  cost:  0.4249484\n",
      "epoch :  803  -  cost:  0.42487708\n",
      "epoch :  804  -  cost:  0.42480588\n",
      "epoch :  805  -  cost:  0.42473474\n",
      "epoch :  806  -  cost:  0.42466372\n",
      "epoch :  807  -  cost:  0.42459282\n",
      "epoch :  808  -  cost:  0.42452204\n",
      "epoch :  809  -  cost:  0.4244513\n",
      "epoch :  810  -  cost:  0.4243807\n",
      "epoch :  811  -  cost:  0.42431024\n",
      "epoch :  812  -  cost:  0.42423984\n",
      "epoch :  813  -  cost:  0.4241695\n",
      "epoch :  814  -  cost:  0.42409942\n",
      "epoch :  815  -  cost:  0.42402935\n",
      "epoch :  816  -  cost:  0.42395929\n",
      "epoch :  817  -  cost:  0.4238895\n",
      "epoch :  818  -  cost:  0.42381972\n",
      "epoch :  819  -  cost:  0.42375004\n",
      "epoch :  820  -  cost:  0.4236805\n",
      "epoch :  821  -  cost:  0.42361102\n",
      "epoch :  822  -  cost:  0.42354167\n",
      "epoch :  823  -  cost:  0.4234724\n",
      "epoch :  824  -  cost:  0.42340323\n",
      "epoch :  825  -  cost:  0.42333418\n",
      "epoch :  826  -  cost:  0.42326525\n",
      "epoch :  827  -  cost:  0.42319635\n",
      "epoch :  828  -  cost:  0.4231276\n",
      "epoch :  829  -  cost:  0.42305902\n",
      "epoch :  830  -  cost:  0.42299044\n",
      "epoch :  831  -  cost:  0.422922\n",
      "epoch :  832  -  cost:  0.4228536\n",
      "epoch :  833  -  cost:  0.42278528\n",
      "epoch :  834  -  cost:  0.42271718\n",
      "epoch :  835  -  cost:  0.42264915\n",
      "epoch :  836  -  cost:  0.42258108\n",
      "epoch :  837  -  cost:  0.42251325\n",
      "epoch :  838  -  cost:  0.4224455\n",
      "epoch :  839  -  cost:  0.42237777\n",
      "epoch :  840  -  cost:  0.4223102\n",
      "epoch :  841  -  cost:  0.42224267\n",
      "epoch :  842  -  cost:  0.42217535\n",
      "epoch :  843  -  cost:  0.42210802\n",
      "epoch :  844  -  cost:  0.42204082\n",
      "epoch :  845  -  cost:  0.42197374\n",
      "epoch :  846  -  cost:  0.4219067\n",
      "epoch :  847  -  cost:  0.4218398\n",
      "epoch :  848  -  cost:  0.42177293\n",
      "epoch :  849  -  cost:  0.4217063\n",
      "epoch :  850  -  cost:  0.42163965\n",
      "epoch :  851  -  cost:  0.42157304\n",
      "epoch :  852  -  cost:  0.42150658\n",
      "epoch :  853  -  cost:  0.4214402\n",
      "epoch :  854  -  cost:  0.421374\n",
      "epoch :  855  -  cost:  0.42130777\n",
      "epoch :  856  -  cost:  0.4212417\n",
      "epoch :  857  -  cost:  0.42117572\n",
      "epoch :  858  -  cost:  0.4211098\n",
      "epoch :  859  -  cost:  0.42104405\n",
      "epoch :  860  -  cost:  0.4209783\n",
      "epoch :  861  -  cost:  0.42091268\n",
      "epoch :  862  -  cost:  0.42084715\n",
      "epoch :  863  -  cost:  0.4207817\n",
      "epoch :  864  -  cost:  0.42071635\n",
      "epoch :  865  -  cost:  0.42065114\n",
      "epoch :  866  -  cost:  0.4205859\n",
      "epoch :  867  -  cost:  0.42052084\n",
      "epoch :  868  -  cost:  0.42045584\n",
      "epoch :  869  -  cost:  0.42039093\n",
      "epoch :  870  -  cost:  0.42032614\n",
      "epoch :  871  -  cost:  0.42026138\n",
      "epoch :  872  -  cost:  0.42019677\n",
      "epoch :  873  -  cost:  0.4201322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  874  -  cost:  0.42006776\n",
      "epoch :  875  -  cost:  0.42000335\n",
      "epoch :  876  -  cost:  0.4199391\n",
      "epoch :  877  -  cost:  0.4198749\n",
      "epoch :  878  -  cost:  0.41981074\n",
      "epoch :  879  -  cost:  0.41974676\n",
      "epoch :  880  -  cost:  0.4196828\n",
      "epoch :  881  -  cost:  0.419619\n",
      "epoch :  882  -  cost:  0.41955516\n",
      "epoch :  883  -  cost:  0.41949156\n",
      "epoch :  884  -  cost:  0.4194279\n",
      "epoch :  885  -  cost:  0.41936436\n",
      "epoch :  886  -  cost:  0.419301\n",
      "epoch :  887  -  cost:  0.4192376\n",
      "epoch :  888  -  cost:  0.41917437\n",
      "epoch :  889  -  cost:  0.4191112\n",
      "epoch :  890  -  cost:  0.41904813\n",
      "epoch :  891  -  cost:  0.41898513\n",
      "epoch :  892  -  cost:  0.41892225\n",
      "epoch :  893  -  cost:  0.41885936\n",
      "epoch :  894  -  cost:  0.4187966\n",
      "epoch :  895  -  cost:  0.41873395\n",
      "epoch :  896  -  cost:  0.41867134\n",
      "epoch :  897  -  cost:  0.41860884\n",
      "epoch :  898  -  cost:  0.41854647\n",
      "epoch :  899  -  cost:  0.4184841\n",
      "epoch :  900  -  cost:  0.41842183\n",
      "epoch :  901  -  cost:  0.41835964\n",
      "epoch :  902  -  cost:  0.41829756\n",
      "epoch :  903  -  cost:  0.41823554\n",
      "epoch :  904  -  cost:  0.41817364\n",
      "epoch :  905  -  cost:  0.41811177\n",
      "epoch :  906  -  cost:  0.41804996\n",
      "epoch :  907  -  cost:  0.41798833\n",
      "epoch :  908  -  cost:  0.41792673\n",
      "epoch :  909  -  cost:  0.4178652\n",
      "epoch :  910  -  cost:  0.41780367\n",
      "epoch :  911  -  cost:  0.41774234\n",
      "epoch :  912  -  cost:  0.4176811\n",
      "epoch :  913  -  cost:  0.4176199\n",
      "epoch :  914  -  cost:  0.41755873\n",
      "epoch :  915  -  cost:  0.4174977\n",
      "epoch :  916  -  cost:  0.41743672\n",
      "epoch :  917  -  cost:  0.4173758\n",
      "epoch :  918  -  cost:  0.417315\n",
      "epoch :  919  -  cost:  0.41725424\n",
      "epoch :  920  -  cost:  0.4171936\n",
      "epoch :  921  -  cost:  0.41713306\n",
      "epoch :  922  -  cost:  0.41707256\n",
      "epoch :  923  -  cost:  0.41701213\n",
      "epoch :  924  -  cost:  0.41695175\n",
      "epoch :  925  -  cost:  0.41689155\n",
      "epoch :  926  -  cost:  0.4168313\n",
      "epoch :  927  -  cost:  0.41677126\n",
      "epoch :  928  -  cost:  0.41671115\n",
      "epoch :  929  -  cost:  0.41665122\n",
      "epoch :  930  -  cost:  0.4165913\n",
      "epoch :  931  -  cost:  0.41653153\n",
      "epoch :  932  -  cost:  0.41647172\n",
      "epoch :  933  -  cost:  0.41641212\n",
      "epoch :  934  -  cost:  0.41635257\n",
      "epoch :  935  -  cost:  0.416293\n",
      "epoch :  936  -  cost:  0.41623357\n",
      "epoch :  937  -  cost:  0.41617423\n",
      "epoch :  938  -  cost:  0.41611496\n",
      "epoch :  939  -  cost:  0.41605574\n",
      "epoch :  940  -  cost:  0.4159966\n",
      "epoch :  941  -  cost:  0.41593757\n",
      "epoch :  942  -  cost:  0.41587856\n",
      "epoch :  943  -  cost:  0.41581964\n",
      "epoch :  944  -  cost:  0.41576082\n",
      "epoch :  945  -  cost:  0.41570204\n",
      "epoch :  946  -  cost:  0.4156434\n",
      "epoch :  947  -  cost:  0.41558474\n",
      "epoch :  948  -  cost:  0.41552624\n",
      "epoch :  949  -  cost:  0.41546774\n",
      "epoch :  950  -  cost:  0.41540933\n",
      "epoch :  951  -  cost:  0.41535103\n",
      "epoch :  952  -  cost:  0.4152927\n",
      "epoch :  953  -  cost:  0.41523457\n",
      "epoch :  954  -  cost:  0.41517645\n",
      "epoch :  955  -  cost:  0.41511843\n",
      "epoch :  956  -  cost:  0.41506043\n",
      "epoch :  957  -  cost:  0.41500258\n",
      "epoch :  958  -  cost:  0.4149447\n",
      "epoch :  959  -  cost:  0.41488698\n",
      "epoch :  960  -  cost:  0.4148293\n",
      "epoch :  961  -  cost:  0.41477168\n",
      "epoch :  962  -  cost:  0.41471416\n",
      "epoch :  963  -  cost:  0.41465667\n",
      "epoch :  964  -  cost:  0.41459933\n",
      "epoch :  965  -  cost:  0.41454196\n",
      "epoch :  966  -  cost:  0.41448468\n",
      "epoch :  967  -  cost:  0.41442746\n",
      "epoch :  968  -  cost:  0.4143704\n",
      "epoch :  969  -  cost:  0.41431332\n",
      "epoch :  970  -  cost:  0.41425636\n",
      "epoch :  971  -  cost:  0.41419938\n",
      "epoch :  972  -  cost:  0.41414252\n",
      "epoch :  973  -  cost:  0.41408575\n",
      "epoch :  974  -  cost:  0.4140291\n",
      "epoch :  975  -  cost:  0.4139724\n",
      "epoch :  976  -  cost:  0.41391587\n",
      "epoch :  977  -  cost:  0.4138594\n",
      "epoch :  978  -  cost:  0.41380292\n",
      "epoch :  979  -  cost:  0.41374657\n",
      "epoch :  980  -  cost:  0.41369027\n",
      "epoch :  981  -  cost:  0.41363406\n",
      "epoch :  982  -  cost:  0.41357785\n",
      "epoch :  983  -  cost:  0.41352183\n",
      "epoch :  984  -  cost:  0.4134658\n",
      "epoch :  985  -  cost:  0.41340977\n",
      "epoch :  986  -  cost:  0.41335383\n",
      "epoch :  987  -  cost:  0.4132981\n",
      "epoch :  988  -  cost:  0.41324228\n",
      "epoch :  989  -  cost:  0.41318658\n",
      "epoch :  990  -  cost:  0.41313097\n",
      "epoch :  991  -  cost:  0.41307536\n",
      "epoch :  992  -  cost:  0.41301993\n",
      "epoch :  993  -  cost:  0.41296452\n",
      "epoch :  994  -  cost:  0.41290912\n",
      "epoch :  995  -  cost:  0.41285384\n",
      "epoch :  996  -  cost:  0.41279858\n",
      "epoch :  997  -  cost:  0.41274336\n",
      "epoch :  998  -  cost:  0.4126883\n",
      "epoch :  999  -  cost:  0.41263327\n",
      "Accuracy:  0.8095238\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import the required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import  shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "#define the one hot encode function\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode\n",
    " \n",
    "#Read the sonar dataset\n",
    "df = pd.read_csv(\"sonar.csv\")\n",
    "print(len(df.columns))\n",
    "X = df[df.columns[0:60]].values\n",
    "y=df[df.columns[60]]\n",
    "#encode the dependent variable containing categorical values\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "Y = one_hot_encode(y)\n",
    " \n",
    "#Transform the data in training and testing\n",
    "X,Y = shuffle(X,Y,random_state=1)\n",
    "train_x,test_x,train_y,test_y = train_test_split(X,Y,test_size=0.20, random_state=42)\n",
    " \n",
    " \n",
    "#define and initialize the variables to work with the tensors\n",
    "learning_rate = 0.1\n",
    "training_epochs = 1000\n",
    " \n",
    "#Array to store cost obtained in each epoch\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    " \n",
    "n_dim = X.shape[1]\n",
    "n_class = 2\n",
    " \n",
    "x = tf.placeholder(tf.float32,[None,n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    " \n",
    "#initialize all variables.\n",
    "init = tf.global_variables_initializer()\n",
    " \n",
    "#define the cost function\n",
    "y_ = tf.placeholder(tf.float32,[None,n_class])\n",
    "y = tf.nn.softmax(tf.matmul(x, W)+ b)\n",
    "cost_function = tf.reduce_mean(-tf.reduce_sum((y_ * tf.log(y)),reduction_indices=[1]))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    " \n",
    "#initialize the session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "mse_history = []\n",
    " \n",
    "#calculate the cost for each epoch\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step,feed_dict={x:train_x,y_:train_y})\n",
    "    cost = sess.run(cost_function,feed_dict={x: train_x,y_: train_y})\n",
    "    cost_history = np.append(cost_history,cost)\n",
    "    print('epoch : ', epoch,  ' - ', 'cost: ', cost)\n",
    " \n",
    "pred_y = sess.run(y, feed_dict={x: test_x})\n",
    " \n",
    "#Calculate Accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(pred_y,1), tf.argmax(test_y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy: \",sess.run(accuracy))\n",
    " \n",
    "plt.plot(range(len(cost_history)),cost_history)\n",
    "plt.axis([0,training_epochs,0,np.max(cost_history)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "epoch :  0  -  cost:  1.1257963\n",
      "epoch :  1  -  cost:  1.1578648\n",
      "epoch :  2  -  cost:  1.2049029\n",
      "epoch :  3  -  cost:  1.21298\n",
      "epoch :  4  -  cost:  1.2406025\n",
      "epoch :  5  -  cost:  1.2257776\n",
      "epoch :  6  -  cost:  1.2451794\n",
      "epoch :  7  -  cost:  1.2216278\n",
      "epoch :  8  -  cost:  1.240145\n",
      "epoch :  9  -  cost:  1.2153881\n",
      "epoch :  10  -  cost:  1.2350686\n",
      "epoch :  11  -  cost:  1.2084343\n",
      "epoch :  12  -  cost:  1.2290131\n",
      "epoch :  13  -  cost:  1.2017043\n",
      "epoch :  14  -  cost:  1.2234313\n",
      "epoch :  15  -  cost:  1.1948344\n",
      "epoch :  16  -  cost:  1.2174584\n",
      "epoch :  17  -  cost:  1.1881002\n",
      "epoch :  18  -  cost:  1.2116879\n",
      "epoch :  19  -  cost:  1.1813298\n",
      "epoch :  20  -  cost:  1.2057292\n",
      "epoch :  21  -  cost:  1.1746359\n",
      "epoch :  22  -  cost:  1.1998386\n",
      "epoch :  23  -  cost:  1.1679487\n",
      "epoch :  24  -  cost:  1.1938505\n",
      "epoch :  25  -  cost:  1.1613141\n",
      "epoch :  26  -  cost:  1.1878718\n",
      "epoch :  27  -  cost:  1.1547046\n",
      "epoch :  28  -  cost:  1.1818352\n",
      "epoch :  29  -  cost:  1.1481384\n",
      "epoch :  30  -  cost:  1.175784\n",
      "epoch :  31  -  cost:  1.141606\n",
      "epoch :  32  -  cost:  1.1696919\n",
      "epoch :  33  -  cost:  1.1351137\n",
      "epoch :  34  -  cost:  1.1635767\n",
      "epoch :  35  -  cost:  1.1286594\n",
      "epoch :  36  -  cost:  1.1574292\n",
      "epoch :  37  -  cost:  1.122245\n",
      "epoch :  38  -  cost:  1.1512561\n",
      "epoch :  39  -  cost:  1.1158701\n",
      "epoch :  40  -  cost:  1.1450557\n",
      "epoch :  41  -  cost:  1.1095358\n",
      "epoch :  42  -  cost:  1.1388298\n",
      "epoch :  43  -  cost:  1.1032422\n",
      "epoch :  44  -  cost:  1.1325799\n",
      "epoch :  45  -  cost:  1.0969899\n",
      "epoch :  46  -  cost:  1.1263076\n",
      "epoch :  47  -  cost:  1.0907791\n",
      "epoch :  48  -  cost:  1.1200143\n",
      "epoch :  49  -  cost:  1.0846097\n",
      "epoch :  50  -  cost:  1.113701\n",
      "epoch :  51  -  cost:  1.0784825\n",
      "epoch :  52  -  cost:  1.1073704\n",
      "epoch :  53  -  cost:  1.0723975\n",
      "epoch :  54  -  cost:  1.1010238\n",
      "epoch :  55  -  cost:  1.0663548\n",
      "epoch :  56  -  cost:  1.0946629\n",
      "epoch :  57  -  cost:  1.060355\n",
      "epoch :  58  -  cost:  1.0882903\n",
      "epoch :  59  -  cost:  1.0543977\n",
      "epoch :  60  -  cost:  1.0819077\n",
      "epoch :  61  -  cost:  1.048483\n",
      "epoch :  62  -  cost:  1.0755174\n",
      "epoch :  63  -  cost:  1.0426112\n",
      "epoch :  64  -  cost:  1.0691214\n",
      "epoch :  65  -  cost:  1.0367827\n",
      "epoch :  66  -  cost:  1.0627226\n",
      "epoch :  67  -  cost:  1.0309975\n",
      "epoch :  68  -  cost:  1.0563232\n",
      "epoch :  69  -  cost:  1.0252552\n",
      "epoch :  70  -  cost:  1.0499258\n",
      "epoch :  71  -  cost:  1.0195563\n",
      "epoch :  72  -  cost:  1.043533\n",
      "epoch :  73  -  cost:  1.0139011\n",
      "epoch :  74  -  cost:  1.037148\n",
      "epoch :  75  -  cost:  1.0082895\n",
      "epoch :  76  -  cost:  1.0307734\n",
      "epoch :  77  -  cost:  1.0027219\n",
      "epoch :  78  -  cost:  1.0244122\n",
      "epoch :  79  -  cost:  0.9971984\n",
      "epoch :  80  -  cost:  1.0180678\n",
      "epoch :  81  -  cost:  0.9917195\n",
      "epoch :  82  -  cost:  1.0117432\n",
      "epoch :  83  -  cost:  0.9862852\n",
      "epoch :  84  -  cost:  1.0054418\n",
      "epoch :  85  -  cost:  0.9808962\n",
      "epoch :  86  -  cost:  0.9991674\n",
      "epoch :  87  -  cost:  0.9755529\n",
      "epoch :  88  -  cost:  0.9929234\n",
      "epoch :  89  -  cost:  0.9702561\n",
      "epoch :  90  -  cost:  0.9867135\n",
      "epoch :  91  -  cost:  0.96500635\n",
      "epoch :  92  -  cost:  0.9805422\n",
      "epoch :  93  -  cost:  0.95980465\n",
      "epoch :  94  -  cost:  0.97441334\n",
      "epoch :  95  -  cost:  0.95465195\n",
      "epoch :  96  -  cost:  0.9683315\n",
      "epoch :  97  -  cost:  0.94954973\n",
      "epoch :  98  -  cost:  0.9623013\n",
      "epoch :  99  -  cost:  0.944499\n",
      "epoch :  100  -  cost:  0.9563277\n",
      "epoch :  101  -  cost:  0.9395016\n",
      "epoch :  102  -  cost:  0.95041543\n",
      "epoch :  103  -  cost:  0.93455935\n",
      "epoch :  104  -  cost:  0.9445703\n",
      "epoch :  105  -  cost:  0.9296746\n",
      "epoch :  106  -  cost:  0.938798\n",
      "epoch :  107  -  cost:  0.92484975\n",
      "epoch :  108  -  cost:  0.9331046\n",
      "epoch :  109  -  cost:  0.9200877\n",
      "epoch :  110  -  cost:  0.9274964\n",
      "epoch :  111  -  cost:  0.91539186\n",
      "epoch :  112  -  cost:  0.9219805\n",
      "epoch :  113  -  cost:  0.91076577\n",
      "epoch :  114  -  cost:  0.916564\n",
      "epoch :  115  -  cost:  0.90621394\n",
      "epoch :  116  -  cost:  0.9112547\n",
      "epoch :  117  -  cost:  0.90174085\n",
      "epoch :  118  -  cost:  0.9060605\n",
      "epoch :  119  -  cost:  0.8973519\n",
      "epoch :  120  -  cost:  0.9009902\n",
      "epoch :  121  -  cost:  0.893053\n",
      "epoch :  122  -  cost:  0.8960525\n",
      "epoch :  123  -  cost:  0.8888505\n",
      "epoch :  124  -  cost:  0.89125675\n",
      "epoch :  125  -  cost:  0.8847517\n",
      "epoch :  126  -  cost:  0.8866126\n",
      "epoch :  127  -  cost:  0.8807638\n",
      "epoch :  128  -  cost:  0.8821294\n",
      "epoch :  129  -  cost:  0.87689507\n",
      "epoch :  130  -  cost:  0.8778168\n",
      "epoch :  131  -  cost:  0.87315357\n",
      "epoch :  132  -  cost:  0.873684\n",
      "epoch :  133  -  cost:  0.8695479\n",
      "epoch :  134  -  cost:  0.8697398\n",
      "epoch :  135  -  cost:  0.8660861\n",
      "epoch :  136  -  cost:  0.86599153\n",
      "epoch :  137  -  cost:  0.86277604\n",
      "epoch :  138  -  cost:  0.86244583\n",
      "epoch :  139  -  cost:  0.8596247\n",
      "epoch :  140  -  cost:  0.8591071\n",
      "epoch :  141  -  cost:  0.8566375\n",
      "epoch :  142  -  cost:  0.85597736\n",
      "epoch :  143  -  cost:  0.8538183\n",
      "epoch :  144  -  cost:  0.85305643\n",
      "epoch :  145  -  cost:  0.8511688\n",
      "epoch :  146  -  cost:  0.85034084\n",
      "epoch :  147  -  cost:  0.8486882\n",
      "epoch :  148  -  cost:  0.8478243\n",
      "epoch :  149  -  cost:  0.8463726\n",
      "epoch :  150  -  cost:  0.84549725\n",
      "epoch :  151  -  cost:  0.84421563\n",
      "epoch :  152  -  cost:  0.8433473\n",
      "epoch :  153  -  cost:  0.842208\n",
      "epoch :  154  -  cost:  0.8413598\n",
      "epoch :  155  -  cost:  0.8403382\n",
      "epoch :  156  -  cost:  0.83951837\n",
      "epoch :  157  -  cost:  0.8385928\n",
      "epoch :  158  -  cost:  0.83780515\n",
      "epoch :  159  -  cost:  0.8369575\n",
      "epoch :  160  -  cost:  0.8362029\n",
      "epoch :  161  -  cost:  0.8354177\n",
      "epoch :  162  -  cost:  0.8346946\n",
      "epoch :  163  -  cost:  0.8339586\n",
      "epoch :  164  -  cost:  0.83326435\n",
      "epoch :  165  -  cost:  0.83256733\n",
      "epoch :  166  -  cost:  0.8318983\n",
      "epoch :  167  -  cost:  0.8312316\n",
      "epoch :  168  -  cost:  0.8305842\n",
      "epoch :  169  -  cost:  0.8299414\n",
      "epoch :  170  -  cost:  0.8293121\n",
      "epoch :  171  -  cost:  0.82868814\n",
      "epoch :  172  -  cost:  0.828074\n",
      "epoch :  173  -  cost:  0.82746506\n",
      "epoch :  174  -  cost:  0.8268636\n",
      "epoch :  175  -  cost:  0.82626706\n",
      "epoch :  176  -  cost:  0.82567626\n",
      "epoch :  177  -  cost:  0.82509017\n",
      "epoch :  178  -  cost:  0.8245087\n",
      "epoch :  179  -  cost:  0.8239314\n",
      "epoch :  180  -  cost:  0.82335836\n",
      "epoch :  181  -  cost:  0.8227889\n",
      "epoch :  182  -  cost:  0.8222233\n",
      "epoch :  183  -  cost:  0.8216612\n",
      "epoch :  184  -  cost:  0.8211025\n",
      "epoch :  185  -  cost:  0.82054716\n",
      "epoch :  186  -  cost:  0.81999516\n",
      "epoch :  187  -  cost:  0.81944627\n",
      "epoch :  188  -  cost:  0.81890047\n",
      "epoch :  189  -  cost:  0.81835777\n",
      "epoch :  190  -  cost:  0.81781816\n",
      "epoch :  191  -  cost:  0.8172815\n",
      "epoch :  192  -  cost:  0.81674767\n",
      "epoch :  193  -  cost:  0.816217\n",
      "epoch :  194  -  cost:  0.8156891\n",
      "epoch :  195  -  cost:  0.815164\n",
      "epoch :  196  -  cost:  0.8146419\n",
      "epoch :  197  -  cost:  0.8141225\n",
      "epoch :  198  -  cost:  0.8136059\n",
      "epoch :  199  -  cost:  0.81309205\n",
      "epoch :  200  -  cost:  0.812581\n",
      "epoch :  201  -  cost:  0.81207275\n",
      "epoch :  202  -  cost:  0.811567\n",
      "epoch :  203  -  cost:  0.811064\n",
      "epoch :  204  -  cost:  0.81056374\n",
      "epoch :  205  -  cost:  0.8100661\n",
      "epoch :  206  -  cost:  0.809571\n",
      "epoch :  207  -  cost:  0.80907845\n",
      "epoch :  208  -  cost:  0.8085886\n",
      "epoch :  209  -  cost:  0.80810124\n",
      "epoch :  210  -  cost:  0.8076164\n",
      "epoch :  211  -  cost:  0.8071341\n",
      "epoch :  212  -  cost:  0.8066543\n",
      "epoch :  213  -  cost:  0.806177\n",
      "epoch :  214  -  cost:  0.8057021\n",
      "epoch :  215  -  cost:  0.8052297\n",
      "epoch :  216  -  cost:  0.8047597\n",
      "epoch :  217  -  cost:  0.80429214\n",
      "epoch :  218  -  cost:  0.8038268\n",
      "epoch :  219  -  cost:  0.8033639\n",
      "epoch :  220  -  cost:  0.8029034\n",
      "epoch :  221  -  cost:  0.80244523\n",
      "epoch :  222  -  cost:  0.8019894\n",
      "epoch :  223  -  cost:  0.8015358\n",
      "epoch :  224  -  cost:  0.80108446\n",
      "epoch :  225  -  cost:  0.8006354\n",
      "epoch :  226  -  cost:  0.8001886\n",
      "epoch :  227  -  cost:  0.79974407\n",
      "epoch :  228  -  cost:  0.7993017\n",
      "epoch :  229  -  cost:  0.7988615\n",
      "epoch :  230  -  cost:  0.79842347\n",
      "epoch :  231  -  cost:  0.79798764\n",
      "epoch :  232  -  cost:  0.79755396\n",
      "epoch :  233  -  cost:  0.7971225\n",
      "epoch :  234  -  cost:  0.7966929\n",
      "epoch :  235  -  cost:  0.79626554\n",
      "epoch :  236  -  cost:  0.7958403\n",
      "epoch :  237  -  cost:  0.795417\n",
      "epoch :  238  -  cost:  0.7949959\n",
      "epoch :  239  -  cost:  0.79457676\n",
      "epoch :  240  -  cost:  0.79415977\n",
      "epoch :  241  -  cost:  0.7937447\n",
      "epoch :  242  -  cost:  0.7933315\n",
      "epoch :  243  -  cost:  0.7929204\n",
      "epoch :  244  -  cost:  0.7925112\n",
      "epoch :  245  -  cost:  0.79210407\n",
      "epoch :  246  -  cost:  0.7916988\n",
      "epoch :  247  -  cost:  0.7912954\n",
      "epoch :  248  -  cost:  0.7908941\n",
      "epoch :  249  -  cost:  0.79049456\n",
      "epoch :  250  -  cost:  0.7900968\n",
      "epoch :  251  -  cost:  0.789701\n",
      "epoch :  252  -  cost:  0.7893071\n",
      "epoch :  253  -  cost:  0.7889151\n",
      "epoch :  254  -  cost:  0.7885248\n",
      "epoch :  255  -  cost:  0.78813636\n",
      "epoch :  256  -  cost:  0.7877497\n",
      "epoch :  257  -  cost:  0.78736484\n",
      "epoch :  258  -  cost:  0.7869818\n",
      "epoch :  259  -  cost:  0.7866006\n",
      "epoch :  260  -  cost:  0.78622097\n",
      "epoch :  261  -  cost:  0.7858432\n",
      "epoch :  262  -  cost:  0.7854671\n",
      "epoch :  263  -  cost:  0.7850927\n",
      "epoch :  264  -  cost:  0.7847201\n",
      "epoch :  265  -  cost:  0.78434914\n",
      "epoch :  266  -  cost:  0.78397983\n",
      "epoch :  267  -  cost:  0.78361225\n",
      "epoch :  268  -  cost:  0.7832463\n",
      "epoch :  269  -  cost:  0.782882\n",
      "epoch :  270  -  cost:  0.7825194\n",
      "epoch :  271  -  cost:  0.7821583\n",
      "epoch :  272  -  cost:  0.78179896\n",
      "epoch :  273  -  cost:  0.78144115\n",
      "epoch :  274  -  cost:  0.7810849\n",
      "epoch :  275  -  cost:  0.7807302\n",
      "epoch :  276  -  cost:  0.78037715\n",
      "epoch :  277  -  cost:  0.78002566\n",
      "epoch :  278  -  cost:  0.7796757\n",
      "epoch :  279  -  cost:  0.77932733\n",
      "epoch :  280  -  cost:  0.77898043\n",
      "epoch :  281  -  cost:  0.7786351\n",
      "epoch :  282  -  cost:  0.7782913\n",
      "epoch :  283  -  cost:  0.7779489\n",
      "epoch :  284  -  cost:  0.777608\n",
      "epoch :  285  -  cost:  0.77726865\n",
      "epoch :  286  -  cost:  0.77693075\n",
      "epoch :  287  -  cost:  0.7765943\n",
      "epoch :  288  -  cost:  0.7762593\n",
      "epoch :  289  -  cost:  0.77592576\n",
      "epoch :  290  -  cost:  0.7755936\n",
      "epoch :  291  -  cost:  0.7752629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  292  -  cost:  0.77493364\n",
      "epoch :  293  -  cost:  0.7746058\n",
      "epoch :  294  -  cost:  0.77427924\n",
      "epoch :  295  -  cost:  0.7739541\n",
      "epoch :  296  -  cost:  0.77363044\n",
      "epoch :  297  -  cost:  0.77330804\n",
      "epoch :  298  -  cost:  0.77298707\n",
      "epoch :  299  -  cost:  0.77266747\n",
      "epoch :  300  -  cost:  0.7723492\n",
      "epoch :  301  -  cost:  0.77203214\n",
      "epoch :  302  -  cost:  0.7717165\n",
      "epoch :  303  -  cost:  0.77140224\n",
      "epoch :  304  -  cost:  0.7710892\n",
      "epoch :  305  -  cost:  0.7707776\n",
      "epoch :  306  -  cost:  0.77046704\n",
      "epoch :  307  -  cost:  0.77015793\n",
      "epoch :  308  -  cost:  0.76985\n",
      "epoch :  309  -  cost:  0.7695434\n",
      "epoch :  310  -  cost:  0.76923805\n",
      "epoch :  311  -  cost:  0.768934\n",
      "epoch :  312  -  cost:  0.76863116\n",
      "epoch :  313  -  cost:  0.76832956\n",
      "epoch :  314  -  cost:  0.7680292\n",
      "epoch :  315  -  cost:  0.76773\n",
      "epoch :  316  -  cost:  0.76743203\n",
      "epoch :  317  -  cost:  0.7671353\n",
      "epoch :  318  -  cost:  0.76683986\n",
      "epoch :  319  -  cost:  0.76654536\n",
      "epoch :  320  -  cost:  0.7662522\n",
      "epoch :  321  -  cost:  0.7659603\n",
      "epoch :  322  -  cost:  0.76566947\n",
      "epoch :  323  -  cost:  0.76537985\n",
      "epoch :  324  -  cost:  0.7650913\n",
      "epoch :  325  -  cost:  0.76480395\n",
      "epoch :  326  -  cost:  0.76451766\n",
      "epoch :  327  -  cost:  0.76423264\n",
      "epoch :  328  -  cost:  0.76394874\n",
      "epoch :  329  -  cost:  0.7636658\n",
      "epoch :  330  -  cost:  0.76338416\n",
      "epoch :  331  -  cost:  0.7631035\n",
      "epoch :  332  -  cost:  0.76282406\n",
      "epoch :  333  -  cost:  0.7625456\n",
      "epoch :  334  -  cost:  0.7622682\n",
      "epoch :  335  -  cost:  0.761992\n",
      "epoch :  336  -  cost:  0.7617167\n",
      "epoch :  337  -  cost:  0.7614426\n",
      "epoch :  338  -  cost:  0.76116955\n",
      "epoch :  339  -  cost:  0.76089764\n",
      "epoch :  340  -  cost:  0.7606266\n",
      "epoch :  341  -  cost:  0.7603568\n",
      "epoch :  342  -  cost:  0.76008785\n",
      "epoch :  343  -  cost:  0.75982004\n",
      "epoch :  344  -  cost:  0.7595532\n",
      "epoch :  345  -  cost:  0.75928736\n",
      "epoch :  346  -  cost:  0.7590226\n",
      "epoch :  347  -  cost:  0.75875884\n",
      "epoch :  348  -  cost:  0.7584959\n",
      "epoch :  349  -  cost:  0.7582342\n",
      "epoch :  350  -  cost:  0.75797343\n",
      "epoch :  351  -  cost:  0.75771356\n",
      "epoch :  352  -  cost:  0.7574548\n",
      "epoch :  353  -  cost:  0.75719696\n",
      "epoch :  354  -  cost:  0.75693995\n",
      "epoch :  355  -  cost:  0.75668406\n",
      "epoch :  356  -  cost:  0.7564291\n",
      "epoch :  357  -  cost:  0.75617504\n",
      "epoch :  358  -  cost:  0.75592196\n",
      "epoch :  359  -  cost:  0.7556698\n",
      "epoch :  360  -  cost:  0.75541854\n",
      "epoch :  361  -  cost:  0.7551683\n",
      "epoch :  362  -  cost:  0.7549188\n",
      "epoch :  363  -  cost:  0.7546704\n",
      "epoch :  364  -  cost:  0.75442284\n",
      "epoch :  365  -  cost:  0.7541762\n",
      "epoch :  366  -  cost:  0.7539305\n",
      "epoch :  367  -  cost:  0.75368565\n",
      "epoch :  368  -  cost:  0.75344163\n",
      "epoch :  369  -  cost:  0.7531987\n",
      "epoch :  370  -  cost:  0.75295645\n",
      "epoch :  371  -  cost:  0.7527151\n",
      "epoch :  372  -  cost:  0.7524747\n",
      "epoch :  373  -  cost:  0.7522351\n",
      "epoch :  374  -  cost:  0.75199646\n",
      "epoch :  375  -  cost:  0.7517586\n",
      "epoch :  376  -  cost:  0.7515215\n",
      "epoch :  377  -  cost:  0.75128543\n",
      "epoch :  378  -  cost:  0.7510501\n",
      "epoch :  379  -  cost:  0.7508157\n",
      "epoch :  380  -  cost:  0.75058204\n",
      "epoch :  381  -  cost:  0.7503493\n",
      "epoch :  382  -  cost:  0.75011724\n",
      "epoch :  383  -  cost:  0.7498861\n",
      "epoch :  384  -  cost:  0.74965584\n",
      "epoch :  385  -  cost:  0.74942625\n",
      "epoch :  386  -  cost:  0.74919754\n",
      "epoch :  387  -  cost:  0.74896955\n",
      "epoch :  388  -  cost:  0.74874246\n",
      "epoch :  389  -  cost:  0.74851614\n",
      "epoch :  390  -  cost:  0.74829054\n",
      "epoch :  391  -  cost:  0.7480659\n",
      "epoch :  392  -  cost:  0.74784184\n",
      "epoch :  393  -  cost:  0.7476186\n",
      "epoch :  394  -  cost:  0.7473962\n",
      "epoch :  395  -  cost:  0.74717456\n",
      "epoch :  396  -  cost:  0.74695367\n",
      "epoch :  397  -  cost:  0.74673355\n",
      "epoch :  398  -  cost:  0.74651414\n",
      "epoch :  399  -  cost:  0.7462956\n",
      "epoch :  400  -  cost:  0.74607766\n",
      "epoch :  401  -  cost:  0.7458605\n",
      "epoch :  402  -  cost:  0.7456441\n",
      "epoch :  403  -  cost:  0.7454285\n",
      "epoch :  404  -  cost:  0.74521357\n",
      "epoch :  405  -  cost:  0.7449993\n",
      "epoch :  406  -  cost:  0.74478585\n",
      "epoch :  407  -  cost:  0.7445731\n",
      "epoch :  408  -  cost:  0.74436104\n",
      "epoch :  409  -  cost:  0.74414974\n",
      "epoch :  410  -  cost:  0.74393916\n",
      "epoch :  411  -  cost:  0.74372923\n",
      "epoch :  412  -  cost:  0.7435201\n",
      "epoch :  413  -  cost:  0.7433115\n",
      "epoch :  414  -  cost:  0.74310374\n",
      "epoch :  415  -  cost:  0.7428966\n",
      "epoch :  416  -  cost:  0.7426902\n",
      "epoch :  417  -  cost:  0.74248445\n",
      "epoch :  418  -  cost:  0.74227935\n",
      "epoch :  419  -  cost:  0.74207497\n",
      "epoch :  420  -  cost:  0.7418713\n",
      "epoch :  421  -  cost:  0.74166816\n",
      "epoch :  422  -  cost:  0.7414658\n",
      "epoch :  423  -  cost:  0.7412641\n",
      "epoch :  424  -  cost:  0.74106306\n",
      "epoch :  425  -  cost:  0.7408627\n",
      "epoch :  426  -  cost:  0.7406629\n",
      "epoch :  427  -  cost:  0.74046385\n",
      "epoch :  428  -  cost:  0.7402654\n",
      "epoch :  429  -  cost:  0.7400676\n",
      "epoch :  430  -  cost:  0.7398704\n",
      "epoch :  431  -  cost:  0.73967385\n",
      "epoch :  432  -  cost:  0.739478\n",
      "epoch :  433  -  cost:  0.7392827\n",
      "epoch :  434  -  cost:  0.739088\n",
      "epoch :  435  -  cost:  0.73889405\n",
      "epoch :  436  -  cost:  0.7387007\n",
      "epoch :  437  -  cost:  0.73850787\n",
      "epoch :  438  -  cost:  0.73831564\n",
      "epoch :  439  -  cost:  0.73812425\n",
      "epoch :  440  -  cost:  0.7379333\n",
      "epoch :  441  -  cost:  0.73774296\n",
      "epoch :  442  -  cost:  0.7375532\n",
      "epoch :  443  -  cost:  0.737364\n",
      "epoch :  444  -  cost:  0.7371754\n",
      "epoch :  445  -  cost:  0.7369876\n",
      "epoch :  446  -  cost:  0.73680013\n",
      "epoch :  447  -  cost:  0.73661345\n",
      "epoch :  448  -  cost:  0.7364272\n",
      "epoch :  449  -  cost:  0.73624164\n",
      "epoch :  450  -  cost:  0.7360566\n",
      "epoch :  451  -  cost:  0.7358722\n",
      "epoch :  452  -  cost:  0.7356883\n",
      "epoch :  453  -  cost:  0.735505\n",
      "epoch :  454  -  cost:  0.7353223\n",
      "epoch :  455  -  cost:  0.7351402\n",
      "epoch :  456  -  cost:  0.7349585\n",
      "epoch :  457  -  cost:  0.7347774\n",
      "epoch :  458  -  cost:  0.73459697\n",
      "epoch :  459  -  cost:  0.734417\n",
      "epoch :  460  -  cost:  0.7342377\n",
      "epoch :  461  -  cost:  0.7340588\n",
      "epoch :  462  -  cost:  0.73388064\n",
      "epoch :  463  -  cost:  0.73370284\n",
      "epoch :  464  -  cost:  0.73352563\n",
      "epoch :  465  -  cost:  0.7333489\n",
      "epoch :  466  -  cost:  0.7331729\n",
      "epoch :  467  -  cost:  0.7329973\n",
      "epoch :  468  -  cost:  0.7328222\n",
      "epoch :  469  -  cost:  0.73264766\n",
      "epoch :  470  -  cost:  0.73247373\n",
      "epoch :  471  -  cost:  0.73230016\n",
      "epoch :  472  -  cost:  0.73212725\n",
      "epoch :  473  -  cost:  0.73195475\n",
      "epoch :  474  -  cost:  0.73178285\n",
      "epoch :  475  -  cost:  0.73161143\n",
      "epoch :  476  -  cost:  0.73144054\n",
      "epoch :  477  -  cost:  0.73127013\n",
      "epoch :  478  -  cost:  0.73110026\n",
      "epoch :  479  -  cost:  0.73093086\n",
      "epoch :  480  -  cost:  0.730762\n",
      "epoch :  481  -  cost:  0.7305936\n",
      "epoch :  482  -  cost:  0.7304257\n",
      "epoch :  483  -  cost:  0.7302584\n",
      "epoch :  484  -  cost:  0.7300914\n",
      "epoch :  485  -  cost:  0.72992504\n",
      "epoch :  486  -  cost:  0.72975916\n",
      "epoch :  487  -  cost:  0.7295937\n",
      "epoch :  488  -  cost:  0.72942877\n",
      "epoch :  489  -  cost:  0.7292643\n",
      "epoch :  490  -  cost:  0.7291002\n",
      "epoch :  491  -  cost:  0.72893673\n",
      "epoch :  492  -  cost:  0.7287737\n",
      "epoch :  493  -  cost:  0.7286111\n",
      "epoch :  494  -  cost:  0.7284491\n",
      "epoch :  495  -  cost:  0.7282874\n",
      "epoch :  496  -  cost:  0.7281263\n",
      "epoch :  497  -  cost:  0.7279656\n",
      "epoch :  498  -  cost:  0.72780526\n",
      "epoch :  499  -  cost:  0.7276455\n",
      "epoch :  500  -  cost:  0.7274862\n",
      "epoch :  501  -  cost:  0.7273274\n",
      "epoch :  502  -  cost:  0.72716904\n",
      "epoch :  503  -  cost:  0.727011\n",
      "epoch :  504  -  cost:  0.7268535\n",
      "epoch :  505  -  cost:  0.7266964\n",
      "epoch :  506  -  cost:  0.7265398\n",
      "epoch :  507  -  cost:  0.7263836\n",
      "epoch :  508  -  cost:  0.7262279\n",
      "epoch :  509  -  cost:  0.7260726\n",
      "epoch :  510  -  cost:  0.7259178\n",
      "epoch :  511  -  cost:  0.7257633\n",
      "epoch :  512  -  cost:  0.7256093\n",
      "epoch :  513  -  cost:  0.7254558\n",
      "epoch :  514  -  cost:  0.72530264\n",
      "epoch :  515  -  cost:  0.72515005\n",
      "epoch :  516  -  cost:  0.7249977\n",
      "epoch :  517  -  cost:  0.7248458\n",
      "epoch :  518  -  cost:  0.72469443\n",
      "epoch :  519  -  cost:  0.7245434\n",
      "epoch :  520  -  cost:  0.72439283\n",
      "epoch :  521  -  cost:  0.7242426\n",
      "epoch :  522  -  cost:  0.72409284\n",
      "epoch :  523  -  cost:  0.72394353\n",
      "epoch :  524  -  cost:  0.72379464\n",
      "epoch :  525  -  cost:  0.72364604\n",
      "epoch :  526  -  cost:  0.7234979\n",
      "epoch :  527  -  cost:  0.7233503\n",
      "epoch :  528  -  cost:  0.7232029\n",
      "epoch :  529  -  cost:  0.723056\n",
      "epoch :  530  -  cost:  0.72290957\n",
      "epoch :  531  -  cost:  0.72276336\n",
      "epoch :  532  -  cost:  0.72261775\n",
      "epoch :  533  -  cost:  0.72247237\n",
      "epoch :  534  -  cost:  0.7223275\n",
      "epoch :  535  -  cost:  0.7221829\n",
      "epoch :  536  -  cost:  0.72203887\n",
      "epoch :  537  -  cost:  0.72189504\n",
      "epoch :  538  -  cost:  0.7217517\n",
      "epoch :  539  -  cost:  0.7216087\n",
      "epoch :  540  -  cost:  0.72146606\n",
      "epoch :  541  -  cost:  0.7213239\n",
      "epoch :  542  -  cost:  0.72118205\n",
      "epoch :  543  -  cost:  0.72104067\n",
      "epoch :  544  -  cost:  0.72089946\n",
      "epoch :  545  -  cost:  0.72075886\n",
      "epoch :  546  -  cost:  0.72061855\n",
      "epoch :  547  -  cost:  0.72047853\n",
      "epoch :  548  -  cost:  0.72033894\n",
      "epoch :  549  -  cost:  0.72019976\n",
      "epoch :  550  -  cost:  0.7200609\n",
      "epoch :  551  -  cost:  0.7199224\n",
      "epoch :  552  -  cost:  0.71978426\n",
      "epoch :  553  -  cost:  0.7196466\n",
      "epoch :  554  -  cost:  0.7195091\n",
      "epoch :  555  -  cost:  0.7193721\n",
      "epoch :  556  -  cost:  0.71923554\n",
      "epoch :  557  -  cost:  0.7190991\n",
      "epoch :  558  -  cost:  0.71896315\n",
      "epoch :  559  -  cost:  0.71882755\n",
      "epoch :  560  -  cost:  0.7186924\n",
      "epoch :  561  -  cost:  0.7185574\n",
      "epoch :  562  -  cost:  0.71842283\n",
      "epoch :  563  -  cost:  0.71828854\n",
      "epoch :  564  -  cost:  0.71815485\n",
      "epoch :  565  -  cost:  0.71802133\n",
      "epoch :  566  -  cost:  0.71788806\n",
      "epoch :  567  -  cost:  0.71775526\n",
      "epoch :  568  -  cost:  0.71762276\n",
      "epoch :  569  -  cost:  0.7174906\n",
      "epoch :  570  -  cost:  0.7173588\n",
      "epoch :  571  -  cost:  0.7172274\n",
      "epoch :  572  -  cost:  0.7170962\n",
      "epoch :  573  -  cost:  0.71696544\n",
      "epoch :  574  -  cost:  0.71683496\n",
      "epoch :  575  -  cost:  0.7167048\n",
      "epoch :  576  -  cost:  0.71657497\n",
      "epoch :  577  -  cost:  0.71644557\n",
      "epoch :  578  -  cost:  0.71631634\n",
      "epoch :  579  -  cost:  0.71618754\n",
      "epoch :  580  -  cost:  0.716059\n",
      "epoch :  581  -  cost:  0.7159309\n",
      "epoch :  582  -  cost:  0.7158029\n",
      "epoch :  583  -  cost:  0.7156754\n",
      "epoch :  584  -  cost:  0.7155482\n",
      "epoch :  585  -  cost:  0.7154213\n",
      "epoch :  586  -  cost:  0.7152947\n",
      "epoch :  587  -  cost:  0.7151685\n",
      "epoch :  588  -  cost:  0.71504253\n",
      "epoch :  589  -  cost:  0.7149168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  590  -  cost:  0.7147916\n",
      "epoch :  591  -  cost:  0.7146666\n",
      "epoch :  592  -  cost:  0.71454185\n",
      "epoch :  593  -  cost:  0.71441746\n",
      "epoch :  594  -  cost:  0.71429336\n",
      "epoch :  595  -  cost:  0.71416944\n",
      "epoch :  596  -  cost:  0.71404606\n",
      "epoch :  597  -  cost:  0.71392286\n",
      "epoch :  598  -  cost:  0.7138\n",
      "epoch :  599  -  cost:  0.71367747\n",
      "epoch :  600  -  cost:  0.71355516\n",
      "epoch :  601  -  cost:  0.7134332\n",
      "epoch :  602  -  cost:  0.7133115\n",
      "epoch :  603  -  cost:  0.71319014\n",
      "epoch :  604  -  cost:  0.713069\n",
      "epoch :  605  -  cost:  0.7129482\n",
      "epoch :  606  -  cost:  0.7128276\n",
      "epoch :  607  -  cost:  0.7127075\n",
      "epoch :  608  -  cost:  0.71258765\n",
      "epoch :  609  -  cost:  0.71246797\n",
      "epoch :  610  -  cost:  0.71234864\n",
      "epoch :  611  -  cost:  0.7122296\n",
      "epoch :  612  -  cost:  0.7121108\n",
      "epoch :  613  -  cost:  0.7119923\n",
      "epoch :  614  -  cost:  0.7118741\n",
      "epoch :  615  -  cost:  0.71175617\n",
      "epoch :  616  -  cost:  0.7116385\n",
      "epoch :  617  -  cost:  0.71152115\n",
      "epoch :  618  -  cost:  0.7114041\n",
      "epoch :  619  -  cost:  0.7112873\n",
      "epoch :  620  -  cost:  0.71117073\n",
      "epoch :  621  -  cost:  0.71105456\n",
      "epoch :  622  -  cost:  0.71093863\n",
      "epoch :  623  -  cost:  0.7108228\n",
      "epoch :  624  -  cost:  0.7107074\n",
      "epoch :  625  -  cost:  0.71059227\n",
      "epoch :  626  -  cost:  0.71047735\n",
      "epoch :  627  -  cost:  0.7103628\n",
      "epoch :  628  -  cost:  0.7102484\n",
      "epoch :  629  -  cost:  0.7101343\n",
      "epoch :  630  -  cost:  0.7100206\n",
      "epoch :  631  -  cost:  0.70990705\n",
      "epoch :  632  -  cost:  0.70979375\n",
      "epoch :  633  -  cost:  0.7096808\n",
      "epoch :  634  -  cost:  0.709568\n",
      "epoch :  635  -  cost:  0.7094555\n",
      "epoch :  636  -  cost:  0.7093432\n",
      "epoch :  637  -  cost:  0.7092313\n",
      "epoch :  638  -  cost:  0.7091196\n",
      "epoch :  639  -  cost:  0.70900816\n",
      "epoch :  640  -  cost:  0.7088969\n",
      "epoch :  641  -  cost:  0.708786\n",
      "epoch :  642  -  cost:  0.7086753\n",
      "epoch :  643  -  cost:  0.70856494\n",
      "epoch :  644  -  cost:  0.70845467\n",
      "epoch :  645  -  cost:  0.70834476\n",
      "epoch :  646  -  cost:  0.708235\n",
      "epoch :  647  -  cost:  0.7081257\n",
      "epoch :  648  -  cost:  0.7080165\n",
      "epoch :  649  -  cost:  0.70790756\n",
      "epoch :  650  -  cost:  0.7077989\n",
      "epoch :  651  -  cost:  0.7076905\n",
      "epoch :  652  -  cost:  0.7075823\n",
      "epoch :  653  -  cost:  0.7074744\n",
      "epoch :  654  -  cost:  0.70736665\n",
      "epoch :  655  -  cost:  0.70725924\n",
      "epoch :  656  -  cost:  0.707152\n",
      "epoch :  657  -  cost:  0.707045\n",
      "epoch :  658  -  cost:  0.7069382\n",
      "epoch :  659  -  cost:  0.7068318\n",
      "epoch :  660  -  cost:  0.7067255\n",
      "epoch :  661  -  cost:  0.7066195\n",
      "epoch :  662  -  cost:  0.70651376\n",
      "epoch :  663  -  cost:  0.7064082\n",
      "epoch :  664  -  cost:  0.7063029\n",
      "epoch :  665  -  cost:  0.7061978\n",
      "epoch :  666  -  cost:  0.706093\n",
      "epoch :  667  -  cost:  0.7059884\n",
      "epoch :  668  -  cost:  0.705884\n",
      "epoch :  669  -  cost:  0.70577985\n",
      "epoch :  670  -  cost:  0.705676\n",
      "epoch :  671  -  cost:  0.7055722\n",
      "epoch :  672  -  cost:  0.70546883\n",
      "epoch :  673  -  cost:  0.7053656\n",
      "epoch :  674  -  cost:  0.70526254\n",
      "epoch :  675  -  cost:  0.7051598\n",
      "epoch :  676  -  cost:  0.70505726\n",
      "epoch :  677  -  cost:  0.7049549\n",
      "epoch :  678  -  cost:  0.7048529\n",
      "epoch :  679  -  cost:  0.7047509\n",
      "epoch :  680  -  cost:  0.70464927\n",
      "epoch :  681  -  cost:  0.7045478\n",
      "epoch :  682  -  cost:  0.7044466\n",
      "epoch :  683  -  cost:  0.70434564\n",
      "epoch :  684  -  cost:  0.7042448\n",
      "epoch :  685  -  cost:  0.7041443\n",
      "epoch :  686  -  cost:  0.70404404\n",
      "epoch :  687  -  cost:  0.7039439\n",
      "epoch :  688  -  cost:  0.70384395\n",
      "epoch :  689  -  cost:  0.7037442\n",
      "epoch :  690  -  cost:  0.70364475\n",
      "epoch :  691  -  cost:  0.7035454\n",
      "epoch :  692  -  cost:  0.70344645\n",
      "epoch :  693  -  cost:  0.70334756\n",
      "epoch :  694  -  cost:  0.703249\n",
      "epoch :  695  -  cost:  0.7031506\n",
      "epoch :  696  -  cost:  0.7030523\n",
      "epoch :  697  -  cost:  0.70295423\n",
      "epoch :  698  -  cost:  0.7028565\n",
      "epoch :  699  -  cost:  0.7027589\n",
      "epoch :  700  -  cost:  0.7026616\n",
      "epoch :  701  -  cost:  0.70256424\n",
      "epoch :  702  -  cost:  0.70246744\n",
      "epoch :  703  -  cost:  0.70237064\n",
      "epoch :  704  -  cost:  0.70227414\n",
      "epoch :  705  -  cost:  0.70217776\n",
      "epoch :  706  -  cost:  0.70208156\n",
      "epoch :  707  -  cost:  0.7019856\n",
      "epoch :  708  -  cost:  0.7018899\n",
      "epoch :  709  -  cost:  0.7017943\n",
      "epoch :  710  -  cost:  0.70169896\n",
      "epoch :  711  -  cost:  0.70160383\n",
      "epoch :  712  -  cost:  0.7015089\n",
      "epoch :  713  -  cost:  0.7014141\n",
      "epoch :  714  -  cost:  0.7013196\n",
      "epoch :  715  -  cost:  0.70122516\n",
      "epoch :  716  -  cost:  0.701131\n",
      "epoch :  717  -  cost:  0.70103705\n",
      "epoch :  718  -  cost:  0.7009433\n",
      "epoch :  719  -  cost:  0.7008497\n",
      "epoch :  720  -  cost:  0.70075625\n",
      "epoch :  721  -  cost:  0.7006631\n",
      "epoch :  722  -  cost:  0.7005701\n",
      "epoch :  723  -  cost:  0.70047724\n",
      "epoch :  724  -  cost:  0.7003847\n",
      "epoch :  725  -  cost:  0.70029217\n",
      "epoch :  726  -  cost:  0.7001999\n",
      "epoch :  727  -  cost:  0.70010793\n",
      "epoch :  728  -  cost:  0.700016\n",
      "epoch :  729  -  cost:  0.69992435\n",
      "epoch :  730  -  cost:  0.6998329\n",
      "epoch :  731  -  cost:  0.69974154\n",
      "epoch :  732  -  cost:  0.6996504\n",
      "epoch :  733  -  cost:  0.6995595\n",
      "epoch :  734  -  cost:  0.69946873\n",
      "epoch :  735  -  cost:  0.69937813\n",
      "epoch :  736  -  cost:  0.6992877\n",
      "epoch :  737  -  cost:  0.69919753\n",
      "epoch :  738  -  cost:  0.6991075\n",
      "epoch :  739  -  cost:  0.69901764\n",
      "epoch :  740  -  cost:  0.698928\n",
      "epoch :  741  -  cost:  0.69883853\n",
      "epoch :  742  -  cost:  0.69874924\n",
      "epoch :  743  -  cost:  0.69866014\n",
      "epoch :  744  -  cost:  0.69857115\n",
      "epoch :  745  -  cost:  0.6984824\n",
      "epoch :  746  -  cost:  0.6983937\n",
      "epoch :  747  -  cost:  0.69830537\n",
      "epoch :  748  -  cost:  0.6982171\n",
      "epoch :  749  -  cost:  0.698129\n",
      "epoch :  750  -  cost:  0.6980411\n",
      "epoch :  751  -  cost:  0.6979534\n",
      "epoch :  752  -  cost:  0.6978659\n",
      "epoch :  753  -  cost:  0.6977785\n",
      "epoch :  754  -  cost:  0.6976913\n",
      "epoch :  755  -  cost:  0.69760424\n",
      "epoch :  756  -  cost:  0.6975174\n",
      "epoch :  757  -  cost:  0.69743073\n",
      "epoch :  758  -  cost:  0.6973442\n",
      "epoch :  759  -  cost:  0.6972579\n",
      "epoch :  760  -  cost:  0.6971716\n",
      "epoch :  761  -  cost:  0.6970857\n",
      "epoch :  762  -  cost:  0.69699985\n",
      "epoch :  763  -  cost:  0.69691414\n",
      "epoch :  764  -  cost:  0.69682854\n",
      "epoch :  765  -  cost:  0.69674325\n",
      "epoch :  766  -  cost:  0.69665813\n",
      "epoch :  767  -  cost:  0.69657314\n",
      "epoch :  768  -  cost:  0.69648826\n",
      "epoch :  769  -  cost:  0.6964036\n",
      "epoch :  770  -  cost:  0.6963191\n",
      "epoch :  771  -  cost:  0.6962347\n",
      "epoch :  772  -  cost:  0.69615054\n",
      "epoch :  773  -  cost:  0.6960665\n",
      "epoch :  774  -  cost:  0.69598264\n",
      "epoch :  775  -  cost:  0.6958989\n",
      "epoch :  776  -  cost:  0.6958154\n",
      "epoch :  777  -  cost:  0.69573194\n",
      "epoch :  778  -  cost:  0.6956487\n",
      "epoch :  779  -  cost:  0.6955656\n",
      "epoch :  780  -  cost:  0.69548273\n",
      "epoch :  781  -  cost:  0.69539994\n",
      "epoch :  782  -  cost:  0.6953173\n",
      "epoch :  783  -  cost:  0.69523495\n",
      "epoch :  784  -  cost:  0.6951526\n",
      "epoch :  785  -  cost:  0.69507056\n",
      "epoch :  786  -  cost:  0.6949885\n",
      "epoch :  787  -  cost:  0.6949067\n",
      "epoch :  788  -  cost:  0.69482505\n",
      "epoch :  789  -  cost:  0.69474363\n",
      "epoch :  790  -  cost:  0.69466215\n",
      "epoch :  791  -  cost:  0.69458103\n",
      "epoch :  792  -  cost:  0.69449997\n",
      "epoch :  793  -  cost:  0.694419\n",
      "epoch :  794  -  cost:  0.6943383\n",
      "epoch :  795  -  cost:  0.6942577\n",
      "epoch :  796  -  cost:  0.69417727\n",
      "epoch :  797  -  cost:  0.6940969\n",
      "epoch :  798  -  cost:  0.6940168\n",
      "epoch :  799  -  cost:  0.6939368\n",
      "epoch :  800  -  cost:  0.69385695\n",
      "epoch :  801  -  cost:  0.69377714\n",
      "epoch :  802  -  cost:  0.69369775\n",
      "epoch :  803  -  cost:  0.69361824\n",
      "epoch :  804  -  cost:  0.6935389\n",
      "epoch :  805  -  cost:  0.6934599\n",
      "epoch :  806  -  cost:  0.6933809\n",
      "epoch :  807  -  cost:  0.6933021\n",
      "epoch :  808  -  cost:  0.6932235\n",
      "epoch :  809  -  cost:  0.69314486\n",
      "epoch :  810  -  cost:  0.6930665\n",
      "epoch :  811  -  cost:  0.6929883\n",
      "epoch :  812  -  cost:  0.6929102\n",
      "epoch :  813  -  cost:  0.69283223\n",
      "epoch :  814  -  cost:  0.6927543\n",
      "epoch :  815  -  cost:  0.69267666\n",
      "epoch :  816  -  cost:  0.6925992\n",
      "epoch :  817  -  cost:  0.6925218\n",
      "epoch :  818  -  cost:  0.6924445\n",
      "epoch :  819  -  cost:  0.6923674\n",
      "epoch :  820  -  cost:  0.6922904\n",
      "epoch :  821  -  cost:  0.6922136\n",
      "epoch :  822  -  cost:  0.6921369\n",
      "epoch :  823  -  cost:  0.6920603\n",
      "epoch :  824  -  cost:  0.69198394\n",
      "epoch :  825  -  cost:  0.69190764\n",
      "epoch :  826  -  cost:  0.69183147\n",
      "epoch :  827  -  cost:  0.6917555\n",
      "epoch :  828  -  cost:  0.6916796\n",
      "epoch :  829  -  cost:  0.6916039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  830  -  cost:  0.6915283\n",
      "epoch :  831  -  cost:  0.6914528\n",
      "epoch :  832  -  cost:  0.6913775\n",
      "epoch :  833  -  cost:  0.69130236\n",
      "epoch :  834  -  cost:  0.6912272\n",
      "epoch :  835  -  cost:  0.6911523\n",
      "epoch :  836  -  cost:  0.69107753\n",
      "epoch :  837  -  cost:  0.6910029\n",
      "epoch :  838  -  cost:  0.69092834\n",
      "epoch :  839  -  cost:  0.69085383\n",
      "epoch :  840  -  cost:  0.6907796\n",
      "epoch :  841  -  cost:  0.69070554\n",
      "epoch :  842  -  cost:  0.6906315\n",
      "epoch :  843  -  cost:  0.69055766\n",
      "epoch :  844  -  cost:  0.69048387\n",
      "epoch :  845  -  cost:  0.6904103\n",
      "epoch :  846  -  cost:  0.69033676\n",
      "epoch :  847  -  cost:  0.69026345\n",
      "epoch :  848  -  cost:  0.6901902\n",
      "epoch :  849  -  cost:  0.6901171\n",
      "epoch :  850  -  cost:  0.69004416\n",
      "epoch :  851  -  cost:  0.6899713\n",
      "epoch :  852  -  cost:  0.68989855\n",
      "epoch :  853  -  cost:  0.68982595\n",
      "epoch :  854  -  cost:  0.6897536\n",
      "epoch :  855  -  cost:  0.6896812\n",
      "epoch :  856  -  cost:  0.68960893\n",
      "epoch :  857  -  cost:  0.6895368\n",
      "epoch :  858  -  cost:  0.68946487\n",
      "epoch :  859  -  cost:  0.6893931\n",
      "epoch :  860  -  cost:  0.68932134\n",
      "epoch :  861  -  cost:  0.68924975\n",
      "epoch :  862  -  cost:  0.6891782\n",
      "epoch :  863  -  cost:  0.68910694\n",
      "epoch :  864  -  cost:  0.68903565\n",
      "epoch :  865  -  cost:  0.68896455\n",
      "epoch :  866  -  cost:  0.68889356\n",
      "epoch :  867  -  cost:  0.68882275\n",
      "epoch :  868  -  cost:  0.688752\n",
      "epoch :  869  -  cost:  0.6886813\n",
      "epoch :  870  -  cost:  0.6886109\n",
      "epoch :  871  -  cost:  0.6885405\n",
      "epoch :  872  -  cost:  0.68847024\n",
      "epoch :  873  -  cost:  0.6884001\n",
      "epoch :  874  -  cost:  0.6883301\n",
      "epoch :  875  -  cost:  0.68826014\n",
      "epoch :  876  -  cost:  0.68819046\n",
      "epoch :  877  -  cost:  0.6881207\n",
      "epoch :  878  -  cost:  0.68805116\n",
      "epoch :  879  -  cost:  0.6879817\n",
      "epoch :  880  -  cost:  0.6879124\n",
      "epoch :  881  -  cost:  0.6878432\n",
      "epoch :  882  -  cost:  0.68777406\n",
      "epoch :  883  -  cost:  0.6877051\n",
      "epoch :  884  -  cost:  0.68763626\n",
      "epoch :  885  -  cost:  0.68756753\n",
      "epoch :  886  -  cost:  0.6874989\n",
      "epoch :  887  -  cost:  0.68743044\n",
      "epoch :  888  -  cost:  0.687362\n",
      "epoch :  889  -  cost:  0.68729377\n",
      "epoch :  890  -  cost:  0.6872256\n",
      "epoch :  891  -  cost:  0.6871576\n",
      "epoch :  892  -  cost:  0.6870897\n",
      "epoch :  893  -  cost:  0.68702185\n",
      "epoch :  894  -  cost:  0.6869541\n",
      "epoch :  895  -  cost:  0.6868865\n",
      "epoch :  896  -  cost:  0.68681896\n",
      "epoch :  897  -  cost:  0.6867516\n",
      "epoch :  898  -  cost:  0.6866843\n",
      "epoch :  899  -  cost:  0.68661714\n",
      "epoch :  900  -  cost:  0.68655014\n",
      "epoch :  901  -  cost:  0.68648314\n",
      "epoch :  902  -  cost:  0.6864164\n",
      "epoch :  903  -  cost:  0.6863497\n",
      "epoch :  904  -  cost:  0.68628305\n",
      "epoch :  905  -  cost:  0.68621653\n",
      "epoch :  906  -  cost:  0.68615013\n",
      "epoch :  907  -  cost:  0.6860839\n",
      "epoch :  908  -  cost:  0.6860177\n",
      "epoch :  909  -  cost:  0.6859516\n",
      "epoch :  910  -  cost:  0.6858857\n",
      "epoch :  911  -  cost:  0.68581975\n",
      "epoch :  912  -  cost:  0.68575406\n",
      "epoch :  913  -  cost:  0.6856884\n",
      "epoch :  914  -  cost:  0.6856229\n",
      "epoch :  915  -  cost:  0.6855574\n",
      "epoch :  916  -  cost:  0.6854921\n",
      "epoch :  917  -  cost:  0.6854269\n",
      "epoch :  918  -  cost:  0.68536174\n",
      "epoch :  919  -  cost:  0.6852968\n",
      "epoch :  920  -  cost:  0.6852318\n",
      "epoch :  921  -  cost:  0.6851671\n",
      "epoch :  922  -  cost:  0.68510234\n",
      "epoch :  923  -  cost:  0.6850378\n",
      "epoch :  924  -  cost:  0.68497324\n",
      "epoch :  925  -  cost:  0.6849089\n",
      "epoch :  926  -  cost:  0.68484455\n",
      "epoch :  927  -  cost:  0.6847804\n",
      "epoch :  928  -  cost:  0.68471634\n",
      "epoch :  929  -  cost:  0.6846523\n",
      "epoch :  930  -  cost:  0.6845885\n",
      "epoch :  931  -  cost:  0.6845247\n",
      "epoch :  932  -  cost:  0.68446106\n",
      "epoch :  933  -  cost:  0.68439746\n",
      "epoch :  934  -  cost:  0.684334\n",
      "epoch :  935  -  cost:  0.6842706\n",
      "epoch :  936  -  cost:  0.6842074\n",
      "epoch :  937  -  cost:  0.68414414\n",
      "epoch :  938  -  cost:  0.684081\n",
      "epoch :  939  -  cost:  0.68401814\n",
      "epoch :  940  -  cost:  0.68395525\n",
      "epoch :  941  -  cost:  0.68389237\n",
      "epoch :  942  -  cost:  0.6838298\n",
      "epoch :  943  -  cost:  0.68376714\n",
      "epoch :  944  -  cost:  0.68370473\n",
      "epoch :  945  -  cost:  0.6836423\n",
      "epoch :  946  -  cost:  0.6835801\n",
      "epoch :  947  -  cost:  0.6835178\n",
      "epoch :  948  -  cost:  0.6834557\n",
      "epoch :  949  -  cost:  0.68339366\n",
      "epoch :  950  -  cost:  0.6833318\n",
      "epoch :  951  -  cost:  0.68327004\n",
      "epoch :  952  -  cost:  0.6832083\n",
      "epoch :  953  -  cost:  0.68314666\n",
      "epoch :  954  -  cost:  0.6830852\n",
      "epoch :  955  -  cost:  0.68302375\n",
      "epoch :  956  -  cost:  0.68296236\n",
      "epoch :  957  -  cost:  0.68290114\n",
      "epoch :  958  -  cost:  0.68283993\n",
      "epoch :  959  -  cost:  0.682779\n",
      "epoch :  960  -  cost:  0.6827179\n",
      "epoch :  961  -  cost:  0.6826571\n",
      "epoch :  962  -  cost:  0.6825964\n",
      "epoch :  963  -  cost:  0.6825357\n",
      "epoch :  964  -  cost:  0.68247515\n",
      "epoch :  965  -  cost:  0.68241465\n",
      "epoch :  966  -  cost:  0.68235415\n",
      "epoch :  967  -  cost:  0.68229383\n",
      "epoch :  968  -  cost:  0.6822336\n",
      "epoch :  969  -  cost:  0.68217343\n",
      "epoch :  970  -  cost:  0.6821135\n",
      "epoch :  971  -  cost:  0.68205357\n",
      "epoch :  972  -  cost:  0.6819937\n",
      "epoch :  973  -  cost:  0.68193394\n",
      "epoch :  974  -  cost:  0.6818742\n",
      "epoch :  975  -  cost:  0.6818146\n",
      "epoch :  976  -  cost:  0.6817551\n",
      "epoch :  977  -  cost:  0.6816957\n",
      "epoch :  978  -  cost:  0.68163645\n",
      "epoch :  979  -  cost:  0.68157715\n",
      "epoch :  980  -  cost:  0.681518\n",
      "epoch :  981  -  cost:  0.68145895\n",
      "epoch :  982  -  cost:  0.68140006\n",
      "epoch :  983  -  cost:  0.6813411\n",
      "epoch :  984  -  cost:  0.68128234\n",
      "epoch :  985  -  cost:  0.6812237\n",
      "epoch :  986  -  cost:  0.68116504\n",
      "epoch :  987  -  cost:  0.68110657\n",
      "epoch :  988  -  cost:  0.68104804\n",
      "epoch :  989  -  cost:  0.6809897\n",
      "epoch :  990  -  cost:  0.68093145\n",
      "epoch :  991  -  cost:  0.6808733\n",
      "epoch :  992  -  cost:  0.6808151\n",
      "epoch :  993  -  cost:  0.68075716\n",
      "epoch :  994  -  cost:  0.68069917\n",
      "epoch :  995  -  cost:  0.6806415\n",
      "epoch :  996  -  cost:  0.6805836\n",
      "epoch :  997  -  cost:  0.68052596\n",
      "epoch :  998  -  cost:  0.6804684\n",
      "epoch :  999  -  cost:  0.6804108\n",
      "Accuracy:  0.71428573\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import the required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import  shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "#define the one hot encode function\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode\n",
    " \n",
    "#Read the sonar dataset\n",
    "df = pd.read_csv(\"wine.csv\")\n",
    "print(len(df.columns))\n",
    "X = df[df.columns[1:14]].values\n",
    "y=df[df.columns[0]]\n",
    "#encode the dependent variable containing categorical values\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "Y = one_hot_encode(y)\n",
    " \n",
    "#Transform the data in training and testing\n",
    "X,Y = shuffle(X,Y,random_state=1)\n",
    "train_x,test_x,train_y,test_y = train_test_split(X,Y,test_size=0.27, random_state=5)\n",
    " \n",
    " \n",
    "#define and initialize the variables to work with the tensors\n",
    "learning_rate = 0.00001\n",
    "training_epochs = 1000\n",
    " \n",
    "#Array to store cost obtained in each epoch\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    " \n",
    "n_dim = X.shape[1]\n",
    "n_class = 3\n",
    " \n",
    "x = tf.placeholder(tf.float32,[None,n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    " \n",
    "#initialize all variables.\n",
    "init = tf.global_variables_initializer()\n",
    " \n",
    "#define the cost function\n",
    "y_ = tf.placeholder(tf.float32,[None,n_class])\n",
    "y = tf.nn.softmax(tf.matmul(x, W)+ b)\n",
    "cost_function = tf.reduce_mean(-tf.reduce_sum((y_ * tf.log(y)),reduction_indices=[1]))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    " \n",
    "#initialize the session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "mse_history = []\n",
    " \n",
    "#calculate the cost for each epoch\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step,feed_dict={x:train_x,y_:train_y})\n",
    "    cost = sess.run(cost_function,feed_dict={x: train_x,y_: train_y})\n",
    "    cost_history = np.append(cost_history,cost)\n",
    "    print('epoch : ', epoch,  ' - ', 'cost: ', cost)\n",
    " \n",
    "pred_y = sess.run(y, feed_dict={x: test_x})\n",
    " \n",
    "#Calculate Accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(pred_y,1), tf.argmax(test_y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy: \",sess.run(accuracy))\n",
    " \n",
    "plt.plot(range(len(cost_history)),cost_history)\n",
    "plt.axis([0,training_epochs,0,np.max(cost_history)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 60)\n",
      "(166, 60)\n",
      "(166, 2)\n",
      "(42, 60)\n",
      "n_dim 60\n",
      "epoch :  0  -  cost:  5.9629607  - MSE:  32.94892174428104 - Train Accuracy:  0.43975905\n",
      "epoch :  1  -  cost:  5.5249066  - MSE:  28.012396409557173 - Train Accuracy:  0.43975905\n",
      "epoch :  2  -  cost:  4.9199038  - MSE:  23.897542231215052 - Train Accuracy:  0.43975905\n",
      "epoch :  3  -  cost:  4.5044003  - MSE:  20.437228348454028 - Train Accuracy:  0.43975905\n",
      "epoch :  4  -  cost:  3.6554613  - MSE:  14.414121722793332 - Train Accuracy:  0.43975905\n",
      "epoch :  5  -  cost:  3.3779044  - MSE:  12.3831914482283 - Train Accuracy:  0.43975905\n",
      "epoch :  6  -  cost:  3.119934  - MSE:  10.92214437515476 - Train Accuracy:  0.43975905\n",
      "epoch :  7  -  cost:  2.9028025  - MSE:  9.988183634366811 - Train Accuracy:  0.43975905\n",
      "epoch :  8  -  cost:  2.5051057  - MSE:  8.47370287647229 - Train Accuracy:  0.43975905\n",
      "epoch :  9  -  cost:  2.1939397  - MSE:  7.589602905036078 - Train Accuracy:  0.43975905\n",
      "epoch :  10  -  cost:  1.9621881  - MSE:  6.68301290923636 - Train Accuracy:  0.43975905\n",
      "epoch :  11  -  cost:  1.5019557  - MSE:  4.916795235568803 - Train Accuracy:  0.45180723\n",
      "epoch :  12  -  cost:  1.2498502  - MSE:  4.043852659192559 - Train Accuracy:  0.46385542\n",
      "epoch :  13  -  cost:  1.0147687  - MSE:  3.3091796477438113 - Train Accuracy:  0.46385542\n",
      "epoch :  14  -  cost:  0.92210203  - MSE:  3.280169277639961 - Train Accuracy:  0.4759036\n",
      "epoch :  15  -  cost:  0.8592796  - MSE:  3.1057215501927855 - Train Accuracy:  0.59638554\n",
      "epoch :  16  -  cost:  0.78060603  - MSE:  2.920175514172854 - Train Accuracy:  0.5903614\n",
      "epoch :  17  -  cost:  0.7401915  - MSE:  2.8352873758747292 - Train Accuracy:  0.6506024\n",
      "epoch :  18  -  cost:  0.7098386  - MSE:  2.845346386354475 - Train Accuracy:  0.6566265\n",
      "epoch :  19  -  cost:  0.6946766  - MSE:  2.834189012928584 - Train Accuracy:  0.6626506\n",
      "epoch :  20  -  cost:  0.6842839  - MSE:  2.8163330282589323 - Train Accuracy:  0.6686747\n",
      "epoch :  21  -  cost:  0.67663383  - MSE:  2.812161255068229 - Train Accuracy:  0.6626506\n",
      "epoch :  22  -  cost:  0.66652167  - MSE:  2.7992128981189963 - Train Accuracy:  0.6686747\n",
      "epoch :  23  -  cost:  0.65834516  - MSE:  2.7871667934291815 - Train Accuracy:  0.67469877\n",
      "epoch :  24  -  cost:  0.65390414  - MSE:  2.787645879036345 - Train Accuracy:  0.6807229\n",
      "epoch :  25  -  cost:  0.65043247  - MSE:  2.778305581077401 - Train Accuracy:  0.6807229\n",
      "epoch :  26  -  cost:  0.6475322  - MSE:  2.7759098685817882 - Train Accuracy:  0.70481926\n",
      "epoch :  27  -  cost:  0.6451598  - MSE:  2.7701365413079593 - Train Accuracy:  0.7108434\n",
      "epoch :  28  -  cost:  0.6430306  - MSE:  2.7662123049300726 - Train Accuracy:  0.7108434\n",
      "epoch :  29  -  cost:  0.6358816  - MSE:  2.755753531855908 - Train Accuracy:  0.7108434\n",
      "epoch :  30  -  cost:  0.6329453  - MSE:  2.6599939935195147 - Train Accuracy:  0.71686745\n",
      "epoch :  31  -  cost:  0.6308794  - MSE:  2.6532498518223724 - Train Accuracy:  0.71686745\n",
      "epoch :  32  -  cost:  0.62750775  - MSE:  2.639305503673325 - Train Accuracy:  0.71686745\n",
      "epoch :  33  -  cost:  0.6248923  - MSE:  2.588758664336264 - Train Accuracy:  0.72289157\n",
      "epoch :  34  -  cost:  0.6226843  - MSE:  2.6361450262847943 - Train Accuracy:  0.72289157\n",
      "epoch :  35  -  cost:  0.6211411  - MSE:  2.6255815609703284 - Train Accuracy:  0.72289157\n",
      "epoch :  36  -  cost:  0.6199582  - MSE:  2.6220024511345588 - Train Accuracy:  0.72289157\n",
      "epoch :  37  -  cost:  0.61818933  - MSE:  2.6111694590936447 - Train Accuracy:  0.7289157\n",
      "epoch :  38  -  cost:  0.6157865  - MSE:  2.608864584353045 - Train Accuracy:  0.73493975\n",
      "epoch :  39  -  cost:  0.6139357  - MSE:  2.5884636596542787 - Train Accuracy:  0.73493975\n",
      "epoch :  40  -  cost:  0.6192683  - MSE:  2.60085304122403 - Train Accuracy:  0.73493975\n",
      "epoch :  41  -  cost:  0.6142864  - MSE:  2.5780426305952453 - Train Accuracy:  0.73493975\n",
      "epoch :  42  -  cost:  0.61704785  - MSE:  2.55891952444589 - Train Accuracy:  0.73493975\n",
      "epoch :  43  -  cost:  0.612853  - MSE:  2.556497889759094 - Train Accuracy:  0.73493975\n",
      "epoch :  44  -  cost:  0.60943794  - MSE:  2.564299961785693 - Train Accuracy:  0.73493975\n",
      "epoch :  45  -  cost:  0.60839814  - MSE:  2.56724378682834 - Train Accuracy:  0.73493975\n",
      "epoch :  46  -  cost:  0.60756844  - MSE:  2.576298099165708 - Train Accuracy:  0.73493975\n",
      "epoch :  47  -  cost:  0.6068013  - MSE:  2.571256300276122 - Train Accuracy:  0.73493975\n",
      "epoch :  48  -  cost:  0.6068475  - MSE:  2.58624095804601 - Train Accuracy:  0.73493975\n",
      "epoch :  49  -  cost:  0.61155295  - MSE:  2.4516845545302774 - Train Accuracy:  0.73493975\n",
      "epoch :  50  -  cost:  0.60534054  - MSE:  2.577758760035537 - Train Accuracy:  0.73493975\n",
      "epoch :  51  -  cost:  0.6052953  - MSE:  2.5377550682227246 - Train Accuracy:  0.73493975\n",
      "epoch :  52  -  cost:  0.6068667  - MSE:  2.5780364508276286 - Train Accuracy:  0.73493975\n",
      "epoch :  53  -  cost:  0.61153823  - MSE:  2.429481768219896 - Train Accuracy:  0.73493975\n",
      "epoch :  54  -  cost:  0.6071346  - MSE:  2.4152057758582735 - Train Accuracy:  0.73493975\n",
      "epoch :  55  -  cost:  0.6051569  - MSE:  2.356632607521039 - Train Accuracy:  0.73493975\n",
      "epoch :  56  -  cost:  0.60155255  - MSE:  2.3461364830359126 - Train Accuracy:  0.73493975\n",
      "epoch :  57  -  cost:  0.59993595  - MSE:  2.3410985896826153 - Train Accuracy:  0.73493975\n",
      "epoch :  58  -  cost:  0.59896016  - MSE:  2.342622479962001 - Train Accuracy:  0.73493975\n",
      "epoch :  59  -  cost:  0.5979525  - MSE:  2.347867255671216 - Train Accuracy:  0.73493975\n",
      "epoch :  60  -  cost:  0.5973371  - MSE:  2.3395449334499014 - Train Accuracy:  0.73493975\n",
      "epoch :  61  -  cost:  0.59717524  - MSE:  2.3618163195392814 - Train Accuracy:  0.7409639\n",
      "epoch :  62  -  cost:  0.59791094  - MSE:  2.356715717860195 - Train Accuracy:  0.7409639\n",
      "epoch :  63  -  cost:  0.59487474  - MSE:  2.348142102815328 - Train Accuracy:  0.7409639\n",
      "epoch :  64  -  cost:  0.59279925  - MSE:  2.3536233563689595 - Train Accuracy:  0.73493975\n",
      "epoch :  65  -  cost:  0.5919648  - MSE:  2.3535426145353466 - Train Accuracy:  0.73493975\n",
      "epoch :  66  -  cost:  0.591874  - MSE:  2.3449208687198286 - Train Accuracy:  0.7409639\n",
      "epoch :  67  -  cost:  0.5898875  - MSE:  2.343138386071071 - Train Accuracy:  0.7409639\n",
      "epoch :  68  -  cost:  0.5856502  - MSE:  2.335963801998519 - Train Accuracy:  0.73493975\n",
      "epoch :  69  -  cost:  0.58438605  - MSE:  2.3258179226180453 - Train Accuracy:  0.7409639\n",
      "epoch :  70  -  cost:  0.58394665  - MSE:  2.3247528487182283 - Train Accuracy:  0.7409639\n",
      "epoch :  71  -  cost:  0.5835231  - MSE:  2.323123078687137 - Train Accuracy:  0.7409639\n",
      "epoch :  72  -  cost:  0.5830579  - MSE:  2.321070408797273 - Train Accuracy:  0.7409639\n",
      "epoch :  73  -  cost:  0.58245325  - MSE:  2.318758557778934 - Train Accuracy:  0.7409639\n",
      "epoch :  74  -  cost:  0.58115697  - MSE:  2.318998067153535 - Train Accuracy:  0.7409639\n",
      "epoch :  75  -  cost:  0.5795982  - MSE:  2.333904395611551 - Train Accuracy:  0.7409639\n",
      "epoch :  76  -  cost:  0.57914823  - MSE:  2.320695306704519 - Train Accuracy:  0.73493975\n",
      "epoch :  77  -  cost:  0.5765282  - MSE:  2.308182345258124 - Train Accuracy:  0.7409639\n",
      "epoch :  78  -  cost:  0.573996  - MSE:  2.3039803705490947 - Train Accuracy:  0.7409639\n",
      "epoch :  79  -  cost:  0.574043  - MSE:  2.306758229646272 - Train Accuracy:  0.7409639\n",
      "epoch :  80  -  cost:  0.57343  - MSE:  2.31134360429134 - Train Accuracy:  0.7409639\n",
      "epoch :  81  -  cost:  0.57266486  - MSE:  2.308861449654483 - Train Accuracy:  0.7409639\n",
      "epoch :  82  -  cost:  0.57201415  - MSE:  2.293749592832594 - Train Accuracy:  0.7409639\n",
      "epoch :  83  -  cost:  0.57172513  - MSE:  2.2948545053900755 - Train Accuracy:  0.7409639\n",
      "epoch :  84  -  cost:  0.5714582  - MSE:  2.294824025346748 - Train Accuracy:  0.7409639\n",
      "epoch :  85  -  cost:  0.5711914  - MSE:  2.2941138060690625 - Train Accuracy:  0.7409639\n",
      "epoch :  86  -  cost:  0.5709051  - MSE:  2.293036223113361 - Train Accuracy:  0.7409639\n",
      "epoch :  87  -  cost:  0.57055205  - MSE:  2.292244585723319 - Train Accuracy:  0.7409639\n",
      "epoch :  88  -  cost:  0.5701012  - MSE:  2.295893131741614 - Train Accuracy:  0.7409639\n",
      "epoch :  89  -  cost:  0.56970567  - MSE:  2.296353324115973 - Train Accuracy:  0.7409639\n",
      "epoch :  90  -  cost:  0.5693433  - MSE:  2.296428280098947 - Train Accuracy:  0.7409639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  91  -  cost:  0.5690077  - MSE:  2.2960844235086673 - Train Accuracy:  0.7409639\n",
      "epoch :  92  -  cost:  0.56869173  - MSE:  2.296082463997738 - Train Accuracy:  0.7409639\n",
      "epoch :  93  -  cost:  0.5683893  - MSE:  2.295445950541019 - Train Accuracy:  0.7409639\n",
      "epoch :  94  -  cost:  0.5680949  - MSE:  2.2958320900027864 - Train Accuracy:  0.7409639\n",
      "epoch :  95  -  cost:  0.56780326  - MSE:  2.294820295299603 - Train Accuracy:  0.7409639\n",
      "epoch :  96  -  cost:  0.5675067  - MSE:  2.2954501123312006 - Train Accuracy:  0.7409639\n",
      "epoch :  97  -  cost:  0.5671955  - MSE:  2.2944179681015404 - Train Accuracy:  0.7409639\n",
      "epoch :  98  -  cost:  0.56684995  - MSE:  2.2952304021841807 - Train Accuracy:  0.7409639\n",
      "epoch :  99  -  cost:  0.56643003  - MSE:  2.2946223990039325 - Train Accuracy:  0.7409639\n",
      "epoch :  100  -  cost:  0.56590426  - MSE:  2.2955737602040194 - Train Accuracy:  0.7409639\n",
      "epoch :  101  -  cost:  0.56539166  - MSE:  2.294960982351226 - Train Accuracy:  0.7409639\n",
      "epoch :  102  -  cost:  0.5649619  - MSE:  2.2953852508862718 - Train Accuracy:  0.7409639\n",
      "epoch :  103  -  cost:  0.5645582  - MSE:  2.2954892970428316 - Train Accuracy:  0.7409639\n",
      "epoch :  104  -  cost:  0.5640047  - MSE:  2.295431663075081 - Train Accuracy:  0.7409639\n",
      "epoch :  105  -  cost:  0.5623511  - MSE:  2.2956352083656943 - Train Accuracy:  0.74698794\n",
      "epoch :  106  -  cost:  0.5612205  - MSE:  2.295542971703804 - Train Accuracy:  0.74698794\n",
      "epoch :  107  -  cost:  0.56088465  - MSE:  2.2936220511123557 - Train Accuracy:  0.74698794\n",
      "epoch :  108  -  cost:  0.5605898  - MSE:  2.2936407575021 - Train Accuracy:  0.74698794\n",
      "epoch :  109  -  cost:  0.5603071  - MSE:  2.292087907079205 - Train Accuracy:  0.74698794\n",
      "epoch :  110  -  cost:  0.56002146  - MSE:  2.291266810162677 - Train Accuracy:  0.74698794\n",
      "epoch :  111  -  cost:  0.5596934  - MSE:  2.289823912423979 - Train Accuracy:  0.74698794\n",
      "epoch :  112  -  cost:  0.5590567  - MSE:  2.288017526606709 - Train Accuracy:  0.74698794\n",
      "epoch :  113  -  cost:  0.5541642  - MSE:  2.2843800766511957 - Train Accuracy:  0.74698794\n",
      "epoch :  114  -  cost:  0.55334026  - MSE:  2.2811818453348813 - Train Accuracy:  0.74698794\n",
      "epoch :  115  -  cost:  0.55274737  - MSE:  2.2812635640061467 - Train Accuracy:  0.74698794\n",
      "epoch :  116  -  cost:  0.55248183  - MSE:  2.2823847576801835 - Train Accuracy:  0.73493975\n",
      "epoch :  117  -  cost:  0.55224097  - MSE:  2.283224917580168 - Train Accuracy:  0.73493975\n",
      "epoch :  118  -  cost:  0.55201006  - MSE:  2.2838786856241238 - Train Accuracy:  0.73493975\n",
      "epoch :  119  -  cost:  0.55178463  - MSE:  2.284411951105371 - Train Accuracy:  0.73493975\n",
      "epoch :  120  -  cost:  0.5515633  - MSE:  2.2848634508475385 - Train Accuracy:  0.73493975\n",
      "epoch :  121  -  cost:  0.5513444  - MSE:  2.285269820045012 - Train Accuracy:  0.73493975\n",
      "epoch :  122  -  cost:  0.5511277  - MSE:  2.2856415291141343 - Train Accuracy:  0.73493975\n",
      "epoch :  123  -  cost:  0.5509127  - MSE:  2.2859832680784304 - Train Accuracy:  0.73493975\n",
      "epoch :  124  -  cost:  0.5506987  - MSE:  2.286320907134474 - Train Accuracy:  0.73493975\n",
      "epoch :  125  -  cost:  0.5504855  - MSE:  2.2866528057139126 - Train Accuracy:  0.73493975\n",
      "epoch :  126  -  cost:  0.550273  - MSE:  2.2869937549601924 - Train Accuracy:  0.73493975\n",
      "epoch :  127  -  cost:  0.5500604  - MSE:  2.2873737696822154 - Train Accuracy:  0.73493975\n",
      "epoch :  128  -  cost:  0.5498467  - MSE:  2.287792815319777 - Train Accuracy:  0.73493975\n",
      "epoch :  129  -  cost:  0.5496307  - MSE:  2.2882753197483217 - Train Accuracy:  0.73493975\n",
      "epoch :  130  -  cost:  0.54941  - MSE:  2.2888672802853294 - Train Accuracy:  0.73493975\n",
      "epoch :  131  -  cost:  0.54917955  - MSE:  2.289615136472754 - Train Accuracy:  0.73493975\n",
      "epoch :  132  -  cost:  0.548928  - MSE:  2.2906090759539417 - Train Accuracy:  0.73493975\n",
      "epoch :  133  -  cost:  0.5486243  - MSE:  2.292330774387808 - Train Accuracy:  0.73493975\n",
      "epoch :  134  -  cost:  0.5482243  - MSE:  2.2945897118156933 - Train Accuracy:  0.73493975\n",
      "epoch :  135  -  cost:  0.547761  - MSE:  2.29715597240883 - Train Accuracy:  0.73493975\n",
      "epoch :  136  -  cost:  0.54733425  - MSE:  2.2996254816825683 - Train Accuracy:  0.73493975\n",
      "epoch :  137  -  cost:  0.5468986  - MSE:  2.301317080490047 - Train Accuracy:  0.73493975\n",
      "epoch :  138  -  cost:  0.546412  - MSE:  2.302109482358043 - Train Accuracy:  0.73493975\n",
      "epoch :  139  -  cost:  0.54597974  - MSE:  2.302729575010513 - Train Accuracy:  0.73493975\n",
      "epoch :  140  -  cost:  0.5456339  - MSE:  2.3038572831903243 - Train Accuracy:  0.73493975\n",
      "epoch :  141  -  cost:  0.5453349  - MSE:  2.30458212152357 - Train Accuracy:  0.73493975\n",
      "epoch :  142  -  cost:  0.54506063  - MSE:  2.3058007283634003 - Train Accuracy:  0.73493975\n",
      "epoch :  143  -  cost:  0.5448015  - MSE:  2.306973627109342 - Train Accuracy:  0.73493975\n",
      "epoch :  144  -  cost:  0.54455245  - MSE:  2.3083512246956213 - Train Accuracy:  0.73493975\n",
      "epoch :  145  -  cost:  0.54431045  - MSE:  2.309714505234585 - Train Accuracy:  0.73493975\n",
      "epoch :  146  -  cost:  0.5440739  - MSE:  2.3110220308910705 - Train Accuracy:  0.73493975\n",
      "epoch :  147  -  cost:  0.5438416  - MSE:  2.312285607339009 - Train Accuracy:  0.73493975\n",
      "epoch :  148  -  cost:  0.54361296  - MSE:  2.313484237827837 - Train Accuracy:  0.73493975\n",
      "epoch :  149  -  cost:  0.5433872  - MSE:  2.3146029298100164 - Train Accuracy:  0.73493975\n",
      "epoch :  150  -  cost:  0.543164  - MSE:  2.315621757982356 - Train Accuracy:  0.73493975\n",
      "epoch :  151  -  cost:  0.54294306  - MSE:  2.316539917062851 - Train Accuracy:  0.73493975\n",
      "epoch :  152  -  cost:  0.54272395  - MSE:  2.3173341850948908 - Train Accuracy:  0.73493975\n",
      "epoch :  153  -  cost:  0.5425066  - MSE:  2.3179959810910398 - Train Accuracy:  0.73493975\n",
      "epoch :  154  -  cost:  0.5422906  - MSE:  2.318526511814909 - Train Accuracy:  0.73493975\n",
      "epoch :  155  -  cost:  0.542076  - MSE:  2.318917053502552 - Train Accuracy:  0.73493975\n",
      "epoch :  156  -  cost:  0.5418626  - MSE:  2.3191725568990282 - Train Accuracy:  0.73493975\n",
      "epoch :  157  -  cost:  0.5416501  - MSE:  2.3192764679658007 - Train Accuracy:  0.7409639\n",
      "epoch :  158  -  cost:  0.54143834  - MSE:  2.319204725759891 - Train Accuracy:  0.7409639\n",
      "epoch :  159  -  cost:  0.54122734  - MSE:  2.3189618790841746 - Train Accuracy:  0.7409639\n",
      "epoch :  160  -  cost:  0.5410167  - MSE:  2.3185033097330416 - Train Accuracy:  0.7409639\n",
      "epoch :  161  -  cost:  0.54080606  - MSE:  2.3177928597897504 - Train Accuracy:  0.7409639\n",
      "epoch :  162  -  cost:  0.5405951  - MSE:  2.3168104508144087 - Train Accuracy:  0.7409639\n",
      "epoch :  163  -  cost:  0.54038334  - MSE:  2.31547927764505 - Train Accuracy:  0.7409639\n",
      "epoch :  164  -  cost:  0.5401695  - MSE:  2.3137267759777806 - Train Accuracy:  0.7409639\n",
      "epoch :  165  -  cost:  0.53995174  - MSE:  2.3114105829057223 - Train Accuracy:  0.7409639\n",
      "epoch :  166  -  cost:  0.53972584  - MSE:  2.308335416282003 - Train Accuracy:  0.7409639\n",
      "epoch :  167  -  cost:  0.53948396  - MSE:  2.3040184388592166 - Train Accuracy:  0.7409639\n",
      "epoch :  168  -  cost:  0.5392095  - MSE:  2.2982232221495553 - Train Accuracy:  0.7409639\n",
      "epoch :  169  -  cost:  0.53888273  - MSE:  2.291717138549047 - Train Accuracy:  0.7409639\n",
      "epoch :  170  -  cost:  0.5385394  - MSE:  2.2859124120413945 - Train Accuracy:  0.7409639\n",
      "epoch :  171  -  cost:  0.5382621  - MSE:  2.282733562309465 - Train Accuracy:  0.7409639\n",
      "epoch :  172  -  cost:  0.53802353  - MSE:  2.282208221602617 - Train Accuracy:  0.7409639\n",
      "epoch :  173  -  cost:  0.5377935  - MSE:  2.282489948646444 - Train Accuracy:  0.7409639\n",
      "epoch :  174  -  cost:  0.53756714  - MSE:  2.282798657978835 - Train Accuracy:  0.7409639\n",
      "epoch :  175  -  cost:  0.53734237  - MSE:  2.2829370313430344 - Train Accuracy:  0.7409639\n",
      "epoch :  176  -  cost:  0.5371175  - MSE:  2.282805579553428 - Train Accuracy:  0.7409639\n",
      "epoch :  177  -  cost:  0.53689003  - MSE:  2.282291413640184 - Train Accuracy:  0.7409639\n",
      "epoch :  178  -  cost:  0.5366571  - MSE:  2.2811858289268874 - Train Accuracy:  0.7409639\n",
      "epoch :  179  -  cost:  0.5364144  - MSE:  2.279165147681491 - Train Accuracy:  0.7409639\n",
      "epoch :  180  -  cost:  0.53615683  - MSE:  2.2757602140760036 - Train Accuracy:  0.7409639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  181  -  cost:  0.53588396  - MSE:  2.2707828489563022 - Train Accuracy:  0.7409639\n",
      "epoch :  182  -  cost:  0.5356037  - MSE:  2.2648309092704046 - Train Accuracy:  0.7409639\n",
      "epoch :  183  -  cost:  0.53532404  - MSE:  2.259482228914934 - Train Accuracy:  0.7409639\n",
      "epoch :  184  -  cost:  0.5350454  - MSE:  2.255153782466421 - Train Accuracy:  0.7409639\n",
      "epoch :  185  -  cost:  0.53476524  - MSE:  2.251715789190553 - Train Accuracy:  0.7409639\n",
      "epoch :  186  -  cost:  0.5344837  - MSE:  2.249566820140209 - Train Accuracy:  0.7409639\n",
      "epoch :  187  -  cost:  0.5341995  - MSE:  2.2487903965628453 - Train Accuracy:  0.7409639\n",
      "epoch :  188  -  cost:  0.5339122  - MSE:  2.2490169510761753 - Train Accuracy:  0.7409639\n",
      "epoch :  189  -  cost:  0.53362954  - MSE:  2.2496596786963177 - Train Accuracy:  0.7409639\n",
      "epoch :  190  -  cost:  0.5333613  - MSE:  2.2499944494860245 - Train Accuracy:  0.7409639\n",
      "epoch :  191  -  cost:  0.5331032  - MSE:  2.249740413142438 - Train Accuracy:  0.7409639\n",
      "epoch :  192  -  cost:  0.5328547  - MSE:  2.2490982559066333 - Train Accuracy:  0.7409639\n",
      "epoch :  193  -  cost:  0.53261435  - MSE:  2.2484404102637012 - Train Accuracy:  0.7409639\n",
      "epoch :  194  -  cost:  0.53238076  - MSE:  2.2483992733445537 - Train Accuracy:  0.7409639\n",
      "epoch :  195  -  cost:  0.532152  - MSE:  2.2478348935427657 - Train Accuracy:  0.7409639\n",
      "epoch :  196  -  cost:  0.5319276  - MSE:  2.247856144840825 - Train Accuracy:  0.7409639\n",
      "epoch :  197  -  cost:  0.5317059  - MSE:  2.2473637779408655 - Train Accuracy:  0.7409639\n",
      "epoch :  198  -  cost:  0.53148746  - MSE:  2.247072292930098 - Train Accuracy:  0.7409639\n",
      "epoch :  199  -  cost:  0.5312716  - MSE:  2.247136655629233 - Train Accuracy:  0.7409639\n",
      "epoch :  200  -  cost:  0.5310574  - MSE:  2.246771917877866 - Train Accuracy:  0.7409639\n",
      "epoch :  201  -  cost:  0.5308454  - MSE:  2.246811851707848 - Train Accuracy:  0.7409639\n",
      "epoch :  202  -  cost:  0.530635  - MSE:  2.2467514704804503 - Train Accuracy:  0.7409639\n",
      "epoch :  203  -  cost:  0.53042555  - MSE:  2.24690428736038 - Train Accuracy:  0.7409639\n",
      "epoch :  204  -  cost:  0.5302161  - MSE:  2.246697633923189 - Train Accuracy:  0.7409639\n",
      "epoch :  205  -  cost:  0.5300057  - MSE:  2.246516325181232 - Train Accuracy:  0.7409639\n",
      "epoch :  206  -  cost:  0.5297922  - MSE:  2.246545111685459 - Train Accuracy:  0.7409639\n",
      "epoch :  207  -  cost:  0.5295691  - MSE:  2.2463215582506253 - Train Accuracy:  0.7409639\n",
      "epoch :  208  -  cost:  0.52931404  - MSE:  2.246183015311074 - Train Accuracy:  0.7409639\n",
      "epoch :  209  -  cost:  0.52888775  - MSE:  2.2462308771617923 - Train Accuracy:  0.7409639\n",
      "epoch :  210  -  cost:  0.52749926  - MSE:  2.247286661972902 - Train Accuracy:  0.7409639\n",
      "epoch :  211  -  cost:  0.526888  - MSE:  2.247054779662507 - Train Accuracy:  0.7409639\n",
      "epoch :  212  -  cost:  0.5263953  - MSE:  2.244939296536672 - Train Accuracy:  0.7409639\n",
      "epoch :  213  -  cost:  0.5261278  - MSE:  2.2434431731763502 - Train Accuracy:  0.7409639\n",
      "epoch :  214  -  cost:  0.5258993  - MSE:  2.2425433108137574 - Train Accuracy:  0.7409639\n",
      "epoch :  215  -  cost:  0.52568096  - MSE:  2.2420900999975775 - Train Accuracy:  0.7409639\n",
      "epoch :  216  -  cost:  0.52546644  - MSE:  2.2420317438680053 - Train Accuracy:  0.7409639\n",
      "epoch :  217  -  cost:  0.52525085  - MSE:  2.242057338008757 - Train Accuracy:  0.7409639\n",
      "epoch :  218  -  cost:  0.52502674  - MSE:  2.2421284757580384 - Train Accuracy:  0.7409639\n",
      "epoch :  219  -  cost:  0.52477443  - MSE:  2.242239055964381 - Train Accuracy:  0.7409639\n",
      "epoch :  220  -  cost:  0.5244396  - MSE:  2.2423652219763293 - Train Accuracy:  0.7409639\n",
      "epoch :  221  -  cost:  0.5240708  - MSE:  2.242625901105936 - Train Accuracy:  0.7409639\n",
      "epoch :  222  -  cost:  0.5238046  - MSE:  2.2432827809820957 - Train Accuracy:  0.7409639\n",
      "epoch :  223  -  cost:  0.52368873  - MSE:  2.242536590599367 - Train Accuracy:  0.7409639\n",
      "epoch :  224  -  cost:  0.5238615  - MSE:  2.2438506014131905 - Train Accuracy:  0.7409639\n",
      "epoch :  225  -  cost:  0.52345073  - MSE:  2.242301337981418 - Train Accuracy:  0.7409639\n",
      "epoch :  226  -  cost:  0.5226597  - MSE:  2.241203116875949 - Train Accuracy:  0.7409639\n",
      "epoch :  227  -  cost:  0.5224307  - MSE:  2.2410720029653586 - Train Accuracy:  0.7409639\n",
      "epoch :  228  -  cost:  0.5222169  - MSE:  2.2411321711586214 - Train Accuracy:  0.7409639\n",
      "epoch :  229  -  cost:  0.5220103  - MSE:  2.240667067148301 - Train Accuracy:  0.7409639\n",
      "epoch :  230  -  cost:  0.52181053  - MSE:  2.2407964746264075 - Train Accuracy:  0.7409639\n",
      "epoch :  231  -  cost:  0.5215974  - MSE:  2.240150156875908 - Train Accuracy:  0.7409639\n",
      "epoch :  232  -  cost:  0.5213866  - MSE:  2.2402713828628205 - Train Accuracy:  0.7409639\n",
      "epoch :  233  -  cost:  0.5211695  - MSE:  2.2396620385558967 - Train Accuracy:  0.7409639\n",
      "epoch :  234  -  cost:  0.52096194  - MSE:  2.2396045887394194 - Train Accuracy:  0.7409639\n",
      "epoch :  235  -  cost:  0.52076066  - MSE:  2.239190004413478 - Train Accuracy:  0.7409639\n",
      "epoch :  236  -  cost:  0.5205639  - MSE:  2.2390020937935176 - Train Accuracy:  0.7409639\n",
      "epoch :  237  -  cost:  0.52036875  - MSE:  2.238738546502399 - Train Accuracy:  0.7409639\n",
      "epoch :  238  -  cost:  0.5201738  - MSE:  2.2385320351171343 - Train Accuracy:  0.7409639\n",
      "epoch :  239  -  cost:  0.5199783  - MSE:  2.238333686666477 - Train Accuracy:  0.7409639\n",
      "epoch :  240  -  cost:  0.5197808  - MSE:  2.2381673702415545 - Train Accuracy:  0.7409639\n",
      "epoch :  241  -  cost:  0.51957893  - MSE:  2.2380402566994357 - Train Accuracy:  0.7409639\n",
      "epoch :  242  -  cost:  0.51936746  - MSE:  2.2379740906376044 - Train Accuracy:  0.7409639\n",
      "epoch :  243  -  cost:  0.5191321  - MSE:  2.2379884307619444 - Train Accuracy:  0.7409639\n",
      "epoch :  244  -  cost:  0.5188317  - MSE:  2.2380684200045144 - Train Accuracy:  0.7409639\n",
      "epoch :  245  -  cost:  0.51839334  - MSE:  2.237909983580561 - Train Accuracy:  0.7409639\n",
      "epoch :  246  -  cost:  0.5179571  - MSE:  2.2368736169720442 - Train Accuracy:  0.7409639\n",
      "epoch :  247  -  cost:  0.5175432  - MSE:  2.235435382182708 - Train Accuracy:  0.7409639\n",
      "epoch :  248  -  cost:  0.51633114  - MSE:  2.2338051794523457 - Train Accuracy:  0.7409639\n",
      "epoch :  249  -  cost:  0.51585  - MSE:  2.2335043096389198 - Train Accuracy:  0.7409639\n",
      "epoch :  250  -  cost:  0.51561815  - MSE:  2.233623113899241 - Train Accuracy:  0.7409639\n",
      "epoch :  251  -  cost:  0.5154151  - MSE:  2.234037690918208 - Train Accuracy:  0.7409639\n",
      "epoch :  252  -  cost:  0.5152203  - MSE:  2.2343165550046926 - Train Accuracy:  0.7409639\n",
      "epoch :  253  -  cost:  0.5150297  - MSE:  2.2344892596683215 - Train Accuracy:  0.7409639\n",
      "epoch :  254  -  cost:  0.51484203  - MSE:  2.234572854107894 - Train Accuracy:  0.7409639\n",
      "epoch :  255  -  cost:  0.5146561  - MSE:  2.2345674147540886 - Train Accuracy:  0.7409639\n",
      "epoch :  256  -  cost:  0.5144717  - MSE:  2.234501685509506 - Train Accuracy:  0.7409639\n",
      "epoch :  257  -  cost:  0.51428854  - MSE:  2.2344240145671117 - Train Accuracy:  0.7409639\n",
      "epoch :  258  -  cost:  0.5141063  - MSE:  2.234305049270291 - Train Accuracy:  0.7409639\n",
      "epoch :  259  -  cost:  0.5139248  - MSE:  2.234152098532175 - Train Accuracy:  0.7409639\n",
      "epoch :  260  -  cost:  0.5137439  - MSE:  2.233976180794868 - Train Accuracy:  0.7409639\n",
      "epoch :  261  -  cost:  0.51356345  - MSE:  2.2337859021669906 - Train Accuracy:  0.7409639\n",
      "epoch :  262  -  cost:  0.51338345  - MSE:  2.2335883514345776 - Train Accuracy:  0.7409639\n",
      "epoch :  263  -  cost:  0.5132035  - MSE:  2.233394224104479 - Train Accuracy:  0.7409639\n",
      "epoch :  264  -  cost:  0.5130236  - MSE:  2.2332185216343214 - Train Accuracy:  0.7409639\n",
      "epoch :  265  -  cost:  0.51284343  - MSE:  2.2330852892876836 - Train Accuracy:  0.7409639\n",
      "epoch :  266  -  cost:  0.5126627  - MSE:  2.233028676079909 - Train Accuracy:  0.7409639\n",
      "epoch :  267  -  cost:  0.51248056  - MSE:  2.233108772827226 - Train Accuracy:  0.7409639\n",
      "epoch :  268  -  cost:  0.5122967  - MSE:  2.2334848314154305 - Train Accuracy:  0.7409639\n",
      "epoch :  269  -  cost:  0.51210886  - MSE:  2.234307096527184 - Train Accuracy:  0.7409639\n",
      "epoch :  270  -  cost:  0.5119144  - MSE:  2.235975395963233 - Train Accuracy:  0.7409639\n",
      "epoch :  271  -  cost:  0.51170814  - MSE:  2.239210011633194 - Train Accuracy:  0.7409639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  272  -  cost:  0.51147896  - MSE:  2.245176812922737 - Train Accuracy:  0.7409639\n",
      "epoch :  273  -  cost:  0.51119304  - MSE:  2.2554793547066274 - Train Accuracy:  0.7409639\n",
      "epoch :  274  -  cost:  0.5107578  - MSE:  2.2707624546354235 - Train Accuracy:  0.7409639\n",
      "epoch :  275  -  cost:  0.5103294  - MSE:  2.2771936436932076 - Train Accuracy:  0.7409639\n",
      "epoch :  276  -  cost:  0.51005787  - MSE:  2.260367960783385 - Train Accuracy:  0.7409639\n",
      "epoch :  277  -  cost:  0.50985795  - MSE:  2.280545911154109 - Train Accuracy:  0.7409639\n",
      "epoch :  278  -  cost:  0.5100722  - MSE:  2.2330357358846866 - Train Accuracy:  0.7409639\n",
      "epoch :  279  -  cost:  0.5090058  - MSE:  2.271769871979167 - Train Accuracy:  0.7409639\n",
      "epoch :  280  -  cost:  0.5086755  - MSE:  2.2760880225868747 - Train Accuracy:  0.7409639\n",
      "epoch :  281  -  cost:  0.5082972  - MSE:  2.2769969542423176 - Train Accuracy:  0.7409639\n",
      "epoch :  282  -  cost:  0.50791985  - MSE:  2.278017168960532 - Train Accuracy:  0.7409639\n",
      "epoch :  283  -  cost:  0.5076379  - MSE:  2.2745411741562354 - Train Accuracy:  0.7409639\n",
      "epoch :  284  -  cost:  0.5081283  - MSE:  2.2778645641954127 - Train Accuracy:  0.7409639\n",
      "epoch :  285  -  cost:  0.50956935  - MSE:  2.238841268512435 - Train Accuracy:  0.7409639\n",
      "epoch :  286  -  cost:  0.5092562  - MSE:  2.2374974130583105 - Train Accuracy:  0.7409639\n",
      "epoch :  287  -  cost:  0.50900227  - MSE:  2.2358978581277116 - Train Accuracy:  0.7409639\n",
      "epoch :  288  -  cost:  0.5087175  - MSE:  2.2337725905680172 - Train Accuracy:  0.7409639\n",
      "epoch :  289  -  cost:  0.50829905  - MSE:  2.2301058687493427 - Train Accuracy:  0.7409639\n",
      "epoch :  290  -  cost:  0.507484  - MSE:  2.223357452696729 - Train Accuracy:  0.7409639\n",
      "epoch :  291  -  cost:  0.50591147  - MSE:  2.252781095595444 - Train Accuracy:  0.7409639\n",
      "epoch :  292  -  cost:  0.5056397  - MSE:  2.267172936655516 - Train Accuracy:  0.7409639\n",
      "epoch :  293  -  cost:  0.50691205  - MSE:  2.2286276883980483 - Train Accuracy:  0.7409639\n",
      "epoch :  294  -  cost:  0.5053998  - MSE:  2.2386945732911068 - Train Accuracy:  0.7409639\n",
      "epoch :  295  -  cost:  0.504231  - MSE:  2.265224067808317 - Train Accuracy:  0.7409639\n",
      "epoch :  296  -  cost:  0.50395554  - MSE:  2.265734906455473 - Train Accuracy:  0.7409639\n",
      "epoch :  297  -  cost:  0.50369936  - MSE:  2.266477596101823 - Train Accuracy:  0.7409639\n",
      "epoch :  298  -  cost:  0.50345576  - MSE:  2.2668407900824663 - Train Accuracy:  0.7409639\n",
      "epoch :  299  -  cost:  0.50322205  - MSE:  2.267445192077681 - Train Accuracy:  0.7409639\n",
      "epoch :  300  -  cost:  0.50299567  - MSE:  2.2679260831747987 - Train Accuracy:  0.7409639\n",
      "epoch :  301  -  cost:  0.502775  - MSE:  2.268581763684525 - Train Accuracy:  0.7409639\n",
      "epoch :  302  -  cost:  0.5025582  - MSE:  2.269257022533845 - Train Accuracy:  0.7409639\n",
      "epoch :  303  -  cost:  0.50234455  - MSE:  2.270049412714701 - Train Accuracy:  0.7409639\n",
      "epoch :  304  -  cost:  0.5021324  - MSE:  2.2709991116569497 - Train Accuracy:  0.7409639\n",
      "epoch :  305  -  cost:  0.501921  - MSE:  2.27204050013547 - Train Accuracy:  0.7409639\n",
      "epoch :  306  -  cost:  0.5017087  - MSE:  2.273271538327143 - Train Accuracy:  0.7409639\n",
      "epoch :  307  -  cost:  0.5014939  - MSE:  2.2745670096100614 - Train Accuracy:  0.7409639\n",
      "epoch :  308  -  cost:  0.5012736  - MSE:  2.276025772126839 - Train Accuracy:  0.7409639\n",
      "epoch :  309  -  cost:  0.5010431  - MSE:  2.2774935048746103 - Train Accuracy:  0.7409639\n",
      "epoch :  310  -  cost:  0.5007964  - MSE:  2.279026229079959 - Train Accuracy:  0.7409639\n",
      "epoch :  311  -  cost:  0.5005354  - MSE:  2.2804452567098963 - Train Accuracy:  0.7409639\n",
      "epoch :  312  -  cost:  0.5002854  - MSE:  2.2816875891841484 - Train Accuracy:  0.7409639\n",
      "epoch :  313  -  cost:  0.5000648  - MSE:  2.282571672031795 - Train Accuracy:  0.7409639\n",
      "epoch :  314  -  cost:  0.49986392  - MSE:  2.2832000032989757 - Train Accuracy:  0.7409639\n",
      "epoch :  315  -  cost:  0.49967372  - MSE:  2.283574084443478 - Train Accuracy:  0.7409639\n",
      "epoch :  316  -  cost:  0.49948782  - MSE:  2.283874379939744 - Train Accuracy:  0.7409639\n",
      "epoch :  317  -  cost:  0.4993047  - MSE:  2.2840058433683046 - Train Accuracy:  0.7409639\n",
      "epoch :  318  -  cost:  0.4991246  - MSE:  2.284115406601839 - Train Accuracy:  0.7409639\n",
      "epoch :  319  -  cost:  0.4989452  - MSE:  2.2841305263563485 - Train Accuracy:  0.7409639\n",
      "epoch :  320  -  cost:  0.49876803  - MSE:  2.284116905453808 - Train Accuracy:  0.7409639\n",
      "epoch :  321  -  cost:  0.49859256  - MSE:  2.2841197453982014 - Train Accuracy:  0.7409639\n",
      "epoch :  322  -  cost:  0.49841815  - MSE:  2.2840643602223216 - Train Accuracy:  0.7409639\n",
      "epoch :  323  -  cost:  0.49824557  - MSE:  2.2840311649107683 - Train Accuracy:  0.7409639\n",
      "epoch :  324  -  cost:  0.49807382  - MSE:  2.284018838489954 - Train Accuracy:  0.7409639\n",
      "epoch :  325  -  cost:  0.49790278  - MSE:  2.2839608597895693 - Train Accuracy:  0.7409639\n",
      "epoch :  326  -  cost:  0.49773338  - MSE:  2.2838913296411443 - Train Accuracy:  0.7409639\n",
      "epoch :  327  -  cost:  0.4975643  - MSE:  2.2838454691978134 - Train Accuracy:  0.7409639\n",
      "epoch :  328  -  cost:  0.49739602  - MSE:  2.2837679614039192 - Train Accuracy:  0.7409639\n",
      "epoch :  329  -  cost:  0.4972291  - MSE:  2.283731379545782 - Train Accuracy:  0.7409639\n",
      "epoch :  330  -  cost:  0.49706236  - MSE:  2.283661698144372 - Train Accuracy:  0.7409639\n",
      "epoch :  331  -  cost:  0.4968964  - MSE:  2.283591987015577 - Train Accuracy:  0.7409639\n",
      "epoch :  332  -  cost:  0.49673146  - MSE:  2.2835191632493097 - Train Accuracy:  0.74698794\n",
      "epoch :  333  -  cost:  0.49656686  - MSE:  2.283459586550535 - Train Accuracy:  0.74698794\n",
      "epoch :  334  -  cost:  0.49640283  - MSE:  2.2832979464409764 - Train Accuracy:  0.74698794\n",
      "epoch :  335  -  cost:  0.49623957  - MSE:  2.283138207941223 - Train Accuracy:  0.74698794\n",
      "epoch :  336  -  cost:  0.49607694  - MSE:  2.2830032249528776 - Train Accuracy:  0.74698794\n",
      "epoch :  337  -  cost:  0.4959146  - MSE:  2.2828426314588715 - Train Accuracy:  0.74698794\n",
      "epoch :  338  -  cost:  0.4957529  - MSE:  2.282685001901257 - Train Accuracy:  0.74698794\n",
      "epoch :  339  -  cost:  0.49559197  - MSE:  2.2825280197705085 - Train Accuracy:  0.74698794\n",
      "epoch :  340  -  cost:  0.49543133  - MSE:  2.2823934965892483 - Train Accuracy:  0.74698794\n",
      "epoch :  341  -  cost:  0.49527124  - MSE:  2.2822360767140073 - Train Accuracy:  0.74698794\n",
      "epoch :  342  -  cost:  0.49511153  - MSE:  2.2820816589467268 - Train Accuracy:  0.74698794\n",
      "epoch :  343  -  cost:  0.4949525  - MSE:  2.2819271064040008 - Train Accuracy:  0.74698794\n",
      "epoch :  344  -  cost:  0.4947939  - MSE:  2.281797010627479 - Train Accuracy:  0.74698794\n",
      "epoch :  345  -  cost:  0.4946356  - MSE:  2.281644105224694 - Train Accuracy:  0.74698794\n",
      "epoch :  346  -  cost:  0.49447784  - MSE:  2.2814964905051505 - Train Accuracy:  0.74698794\n",
      "epoch :  347  -  cost:  0.49432057  - MSE:  2.2813487841897144 - Train Accuracy:  0.74698794\n",
      "epoch :  348  -  cost:  0.49416378  - MSE:  2.2812016032652203 - Train Accuracy:  0.74698794\n",
      "epoch :  349  -  cost:  0.4940073  - MSE:  2.281075550357155 - Train Accuracy:  0.74698794\n",
      "epoch :  350  -  cost:  0.49385136  - MSE:  2.280930711330117 - Train Accuracy:  0.74698794\n",
      "epoch :  351  -  cost:  0.49369574  - MSE:  2.280788542446097 - Train Accuracy:  0.74698794\n",
      "epoch :  352  -  cost:  0.49354044  - MSE:  2.2806479675642715 - Train Accuracy:  0.74698794\n",
      "epoch :  353  -  cost:  0.49338573  - MSE:  2.280507423954647 - Train Accuracy:  0.74698794\n",
      "epoch :  354  -  cost:  0.49323145  - MSE:  2.280388725358103 - Train Accuracy:  0.74698794\n",
      "epoch :  355  -  cost:  0.49307737  - MSE:  2.2802506421800492 - Train Accuracy:  0.74698794\n",
      "epoch :  356  -  cost:  0.49292374  - MSE:  2.2801151986234642 - Train Accuracy:  0.74698794\n",
      "epoch :  357  -  cost:  0.49277055  - MSE:  2.279983678740754 - Train Accuracy:  0.74698794\n",
      "epoch :  358  -  cost:  0.49261764  - MSE:  2.2798512973209935 - Train Accuracy:  0.74698794\n",
      "epoch :  359  -  cost:  0.4924651  - MSE:  2.2797199384455604 - Train Accuracy:  0.74698794\n",
      "epoch :  360  -  cost:  0.49231303  - MSE:  2.279590743011505 - Train Accuracy:  0.74698794\n",
      "epoch :  361  -  cost:  0.49216124  - MSE:  2.2794620078078403 - Train Accuracy:  0.74698794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  362  -  cost:  0.49200988  - MSE:  2.2793333035287344 - Train Accuracy:  0.74698794\n",
      "epoch :  363  -  cost:  0.49185887  - MSE:  2.2792244897297356 - Train Accuracy:  0.74698794\n",
      "epoch :  364  -  cost:  0.49170813  - MSE:  2.279095816861844 - Train Accuracy:  0.74698794\n",
      "epoch :  365  -  cost:  0.4915578  - MSE:  2.2789737351920243 - Train Accuracy:  0.74698794\n",
      "epoch :  366  -  cost:  0.49140778  - MSE:  2.278854556337341 - Train Accuracy:  0.74698794\n",
      "epoch :  367  -  cost:  0.49125814  - MSE:  2.2787345228668436 - Train Accuracy:  0.74698794\n",
      "epoch :  368  -  cost:  0.49110878  - MSE:  2.278619334335064 - Train Accuracy:  0.74698794\n",
      "epoch :  369  -  cost:  0.49095976  - MSE:  2.2785005522110753 - Train Accuracy:  0.74698794\n",
      "epoch :  370  -  cost:  0.49081114  - MSE:  2.278383835452451 - Train Accuracy:  0.74698794\n",
      "epoch :  371  -  cost:  0.4906628  - MSE:  2.2782700944312926 - Train Accuracy:  0.74698794\n",
      "epoch :  372  -  cost:  0.4905148  - MSE:  2.278156079413952 - Train Accuracy:  0.74698794\n",
      "epoch :  373  -  cost:  0.4903671  - MSE:  2.278043724174783 - Train Accuracy:  0.74698794\n",
      "epoch :  374  -  cost:  0.4902198  - MSE:  2.2779324096951235 - Train Accuracy:  0.74698794\n",
      "epoch :  375  -  cost:  0.49007273  - MSE:  2.277824406915419 - Train Accuracy:  0.74698794\n",
      "epoch :  376  -  cost:  0.48992604  - MSE:  2.2777161985382897 - Train Accuracy:  0.74698794\n",
      "epoch :  377  -  cost:  0.48977956  - MSE:  2.2776072261199003 - Train Accuracy:  0.74698794\n",
      "epoch :  378  -  cost:  0.48963344  - MSE:  2.2775032179125088 - Train Accuracy:  0.74698794\n",
      "epoch :  379  -  cost:  0.48948762  - MSE:  2.2773960591265103 - Train Accuracy:  0.74698794\n",
      "epoch :  380  -  cost:  0.48934206  - MSE:  2.277294296149253 - Train Accuracy:  0.74698794\n",
      "epoch :  381  -  cost:  0.48919693  - MSE:  2.277192790102753 - Train Accuracy:  0.74698794\n",
      "epoch :  382  -  cost:  0.489052  - MSE:  2.2770939401783585 - Train Accuracy:  0.74698794\n",
      "epoch :  383  -  cost:  0.48890737  - MSE:  2.2769939022350885 - Train Accuracy:  0.74698794\n",
      "epoch :  384  -  cost:  0.4887631  - MSE:  2.2768946507694987 - Train Accuracy:  0.74698794\n",
      "epoch :  385  -  cost:  0.488619  - MSE:  2.2767974369900164 - Train Accuracy:  0.74698794\n",
      "epoch :  386  -  cost:  0.48847523  - MSE:  2.2767028537095624 - Train Accuracy:  0.74698794\n",
      "epoch :  387  -  cost:  0.48833176  - MSE:  2.2766101865418746 - Train Accuracy:  0.74698794\n",
      "epoch :  388  -  cost:  0.4881886  - MSE:  2.276518986073524 - Train Accuracy:  0.74698794\n",
      "epoch :  389  -  cost:  0.48804566  - MSE:  2.2764245417984186 - Train Accuracy:  0.74698794\n",
      "epoch :  390  -  cost:  0.48790303  - MSE:  2.2763331208549777 - Train Accuracy:  0.74698794\n",
      "epoch :  391  -  cost:  0.4877606  - MSE:  2.2762468757124488 - Train Accuracy:  0.74698794\n",
      "epoch :  392  -  cost:  0.48761854  - MSE:  2.276158238640155 - Train Accuracy:  0.74698794\n",
      "epoch :  393  -  cost:  0.4874767  - MSE:  2.2760736132404573 - Train Accuracy:  0.74698794\n",
      "epoch :  394  -  cost:  0.48733515  - MSE:  2.2759875370463076 - Train Accuracy:  0.74698794\n",
      "epoch :  395  -  cost:  0.4871938  - MSE:  2.275903679850174 - Train Accuracy:  0.74698794\n",
      "epoch :  396  -  cost:  0.48705274  - MSE:  2.275816480682535 - Train Accuracy:  0.74698794\n",
      "epoch :  397  -  cost:  0.48691192  - MSE:  2.275734267657131 - Train Accuracy:  0.74698794\n",
      "epoch :  398  -  cost:  0.48677137  - MSE:  2.275651001751041 - Train Accuracy:  0.74698794\n",
      "epoch :  399  -  cost:  0.4866311  - MSE:  2.2755712280317946 - Train Accuracy:  0.74698794\n",
      "epoch :  400  -  cost:  0.48649105  - MSE:  2.275490827508347 - Train Accuracy:  0.74698794\n",
      "epoch :  401  -  cost:  0.48635116  - MSE:  2.2754159787298023 - Train Accuracy:  0.74698794\n",
      "epoch :  402  -  cost:  0.48621148  - MSE:  2.275343262757277 - Train Accuracy:  0.74698794\n",
      "epoch :  403  -  cost:  0.48607194  - MSE:  2.2752762173094614 - Train Accuracy:  0.7409639\n",
      "epoch :  404  -  cost:  0.4859326  - MSE:  2.275211166051599 - Train Accuracy:  0.7409639\n",
      "epoch :  405  -  cost:  0.48579338  - MSE:  2.275152447861223 - Train Accuracy:  0.7409639\n",
      "epoch :  406  -  cost:  0.4856542  - MSE:  2.2750972442098765 - Train Accuracy:  0.7409639\n",
      "epoch :  407  -  cost:  0.4855151  - MSE:  2.2750659375983764 - Train Accuracy:  0.7409639\n",
      "epoch :  408  -  cost:  0.48537573  - MSE:  2.275052388093326 - Train Accuracy:  0.7409639\n",
      "epoch :  409  -  cost:  0.4852361  - MSE:  2.2750465101540933 - Train Accuracy:  0.7409639\n",
      "epoch :  410  -  cost:  0.4850958  - MSE:  2.275057112512259 - Train Accuracy:  0.7409639\n",
      "epoch :  411  -  cost:  0.4849544  - MSE:  2.2750860521891565 - Train Accuracy:  0.7409639\n",
      "epoch :  412  -  cost:  0.48481014  - MSE:  2.275145698612314 - Train Accuracy:  0.7409639\n",
      "epoch :  413  -  cost:  0.48466015  - MSE:  2.2752435525902865 - Train Accuracy:  0.7409639\n",
      "epoch :  414  -  cost:  0.48449385  - MSE:  2.27541889415576 - Train Accuracy:  0.7409639\n",
      "epoch :  415  -  cost:  0.48426342  - MSE:  2.2757248120128333 - Train Accuracy:  0.7409639\n",
      "epoch :  416  -  cost:  0.4835341  - MSE:  2.276263726591909 - Train Accuracy:  0.7409639\n",
      "epoch :  417  -  cost:  0.48444563  - MSE:  2.276133832600049 - Train Accuracy:  0.74698794\n",
      "epoch :  418  -  cost:  0.48448196  - MSE:  2.159726315200249 - Train Accuracy:  0.75301206\n",
      "epoch :  419  -  cost:  0.48406154  - MSE:  2.1743442566003006 - Train Accuracy:  0.75301206\n",
      "epoch :  420  -  cost:  0.48388493  - MSE:  2.1790699524595802 - Train Accuracy:  0.75301206\n",
      "epoch :  421  -  cost:  0.48372623  - MSE:  2.1830344080908626 - Train Accuracy:  0.75301206\n",
      "epoch :  422  -  cost:  0.4835756  - MSE:  2.18660091412544 - Train Accuracy:  0.75301206\n",
      "epoch :  423  -  cost:  0.48342964  - MSE:  2.189917915825938 - Train Accuracy:  0.75301206\n",
      "epoch :  424  -  cost:  0.48328686  - MSE:  2.193055509401354 - Train Accuracy:  0.75301206\n",
      "epoch :  425  -  cost:  0.4831461  - MSE:  2.196055863432755 - Train Accuracy:  0.75301206\n",
      "epoch :  426  -  cost:  0.48300713  - MSE:  2.1989394088599323 - Train Accuracy:  0.75301206\n",
      "epoch :  427  -  cost:  0.48286945  - MSE:  2.2017380863451153 - Train Accuracy:  0.75301206\n",
      "epoch :  428  -  cost:  0.48273274  - MSE:  2.204447422467933 - Train Accuracy:  0.75301206\n",
      "epoch :  429  -  cost:  0.48259693  - MSE:  2.2070822614816534 - Train Accuracy:  0.75301206\n",
      "epoch :  430  -  cost:  0.48246187  - MSE:  2.2096541757073997 - Train Accuracy:  0.75301206\n",
      "epoch :  431  -  cost:  0.48232728  - MSE:  2.212172723770282 - Train Accuracy:  0.75301206\n",
      "epoch :  432  -  cost:  0.48219335  - MSE:  2.214645285100791 - Train Accuracy:  0.75301206\n",
      "epoch :  433  -  cost:  0.4820598  - MSE:  2.217083716637839 - Train Accuracy:  0.75301206\n",
      "epoch :  434  -  cost:  0.48192665  - MSE:  2.2194942073785553 - Train Accuracy:  0.75301206\n",
      "epoch :  435  -  cost:  0.48179382  - MSE:  2.2218927798372525 - Train Accuracy:  0.75301206\n",
      "epoch :  436  -  cost:  0.48166147  - MSE:  2.2242896815710202 - Train Accuracy:  0.75301206\n",
      "epoch :  437  -  cost:  0.48152933  - MSE:  2.226539380320272 - Train Accuracy:  0.75301206\n",
      "epoch :  438  -  cost:  0.48139742  - MSE:  2.2288314394732156 - Train Accuracy:  0.75301206\n",
      "epoch :  439  -  cost:  0.48126546  - MSE:  2.2311846612108672 - Train Accuracy:  0.75301206\n",
      "epoch :  440  -  cost:  0.48113325  - MSE:  2.233638643145529 - Train Accuracy:  0.75301206\n",
      "epoch :  441  -  cost:  0.48100066  - MSE:  2.236224180522423 - Train Accuracy:  0.75301206\n",
      "epoch :  442  -  cost:  0.48086715  - MSE:  2.2390149761775775 - Train Accuracy:  0.75301206\n",
      "epoch :  443  -  cost:  0.48073205  - MSE:  2.2421117243308477 - Train Accuracy:  0.75301206\n",
      "epoch :  444  -  cost:  0.4805936  - MSE:  2.2456250499768733 - Train Accuracy:  0.75301206\n",
      "epoch :  445  -  cost:  0.4804472  - MSE:  2.249800526336235 - Train Accuracy:  0.75301206\n",
      "epoch :  446  -  cost:  0.48027727  - MSE:  2.2550676571627584 - Train Accuracy:  0.75301206\n",
      "epoch :  447  -  cost:  0.47999927  - MSE:  2.262300900800185 - Train Accuracy:  0.75301206\n",
      "epoch :  448  -  cost:  0.4786768  - MSE:  2.2726105126635097 - Train Accuracy:  0.75301206\n",
      "epoch :  449  -  cost:  0.47756314  - MSE:  2.2783618113373927 - Train Accuracy:  0.75301206\n",
      "epoch :  450  -  cost:  0.47737333  - MSE:  2.275924158541639 - Train Accuracy:  0.75301206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  451  -  cost:  0.47719863  - MSE:  2.2739661430562177 - Train Accuracy:  0.75301206\n",
      "epoch :  452  -  cost:  0.4769957  - MSE:  2.2722325190054296 - Train Accuracy:  0.75301206\n",
      "epoch :  453  -  cost:  0.47664085  - MSE:  2.270137637603541 - Train Accuracy:  0.75301206\n",
      "epoch :  454  -  cost:  0.4756809  - MSE:  2.266284313368564 - Train Accuracy:  0.75301206\n",
      "epoch :  455  -  cost:  0.4751218  - MSE:  2.263700226124123 - Train Accuracy:  0.75301206\n",
      "epoch :  456  -  cost:  0.4748681  - MSE:  2.263215661718131 - Train Accuracy:  0.75301206\n",
      "epoch :  457  -  cost:  0.47466296  - MSE:  2.2613599345317383 - Train Accuracy:  0.75301206\n",
      "epoch :  458  -  cost:  0.47447714  - MSE:  2.2610773001966855 - Train Accuracy:  0.75301206\n",
      "epoch :  459  -  cost:  0.47431344  - MSE:  2.2603585334398852 - Train Accuracy:  0.75301206\n",
      "epoch :  460  -  cost:  0.4741593  - MSE:  2.2598635451724234 - Train Accuracy:  0.75301206\n",
      "epoch :  461  -  cost:  0.47401056  - MSE:  2.2593950316683795 - Train Accuracy:  0.75301206\n",
      "epoch :  462  -  cost:  0.4738656  - MSE:  2.2589566743294056 - Train Accuracy:  0.75301206\n",
      "epoch :  463  -  cost:  0.4737234  - MSE:  2.2585449575287484 - Train Accuracy:  0.75301206\n",
      "epoch :  464  -  cost:  0.4735835  - MSE:  2.258163614200874 - Train Accuracy:  0.75301206\n",
      "epoch :  465  -  cost:  0.4734453  - MSE:  2.257798551769586 - Train Accuracy:  0.75301206\n",
      "epoch :  466  -  cost:  0.4733087  - MSE:  2.2574513674105314 - Train Accuracy:  0.75301206\n",
      "epoch :  467  -  cost:  0.4731732  - MSE:  2.2571154332093832 - Train Accuracy:  0.75301206\n",
      "epoch :  468  -  cost:  0.47303888  - MSE:  2.2567855185850036 - Train Accuracy:  0.75301206\n",
      "epoch :  469  -  cost:  0.47290546  - MSE:  2.2564729740524276 - Train Accuracy:  0.75301206\n",
      "epoch :  470  -  cost:  0.4727728  - MSE:  2.256167876524694 - Train Accuracy:  0.75301206\n",
      "epoch :  471  -  cost:  0.47264084  - MSE:  2.255873354851228 - Train Accuracy:  0.75301206\n",
      "epoch :  472  -  cost:  0.47250962  - MSE:  2.2555865892008975 - Train Accuracy:  0.75301206\n",
      "epoch :  473  -  cost:  0.47237894  - MSE:  2.25530629498585 - Train Accuracy:  0.75301206\n",
      "epoch :  474  -  cost:  0.47224882  - MSE:  2.2550365414293374 - Train Accuracy:  0.75301206\n",
      "epoch :  475  -  cost:  0.47211912  - MSE:  2.2547737193140684 - Train Accuracy:  0.75301206\n",
      "epoch :  476  -  cost:  0.47198996  - MSE:  2.2545091432025894 - Train Accuracy:  0.75301206\n",
      "epoch :  477  -  cost:  0.47186124  - MSE:  2.254258922829382 - Train Accuracy:  0.75301206\n",
      "epoch :  478  -  cost:  0.47173294  - MSE:  2.253954965218794 - Train Accuracy:  0.75301206\n",
      "epoch :  479  -  cost:  0.47160506  - MSE:  2.2537141906705194 - Train Accuracy:  0.7590361\n",
      "epoch :  480  -  cost:  0.47147745  - MSE:  2.253479579585214 - Train Accuracy:  0.7590361\n",
      "epoch :  481  -  cost:  0.47135025  - MSE:  2.2532453727268793 - Train Accuracy:  0.7590361\n",
      "epoch :  482  -  cost:  0.47122344  - MSE:  2.25301519033386 - Train Accuracy:  0.7590361\n",
      "epoch :  483  -  cost:  0.47109696  - MSE:  2.2527947651265654 - Train Accuracy:  0.7590361\n",
      "epoch :  484  -  cost:  0.4709708  - MSE:  2.2525666663997224 - Train Accuracy:  0.7590361\n",
      "epoch :  485  -  cost:  0.47084492  - MSE:  2.252350180414669 - Train Accuracy:  0.7590361\n",
      "epoch :  486  -  cost:  0.4707195  - MSE:  2.2521401980782554 - Train Accuracy:  0.7590361\n",
      "epoch :  487  -  cost:  0.47059426  - MSE:  2.2519307661680377 - Train Accuracy:  0.7590361\n",
      "epoch :  488  -  cost:  0.47046927  - MSE:  2.251658986438956 - Train Accuracy:  0.7590361\n",
      "epoch :  489  -  cost:  0.4703447  - MSE:  2.251445369280149 - Train Accuracy:  0.7590361\n",
      "epoch :  490  -  cost:  0.47022033  - MSE:  2.251234423499936 - Train Accuracy:  0.7590361\n",
      "epoch :  491  -  cost:  0.47009626  - MSE:  2.25103181005314 - Train Accuracy:  0.7590361\n",
      "epoch :  492  -  cost:  0.4699725  - MSE:  2.25083159304661 - Train Accuracy:  0.7590361\n",
      "epoch :  493  -  cost:  0.46984896  - MSE:  2.250618110911848 - Train Accuracy:  0.7590361\n",
      "epoch :  494  -  cost:  0.46972573  - MSE:  2.2504191164747387 - Train Accuracy:  0.7590361\n",
      "epoch :  495  -  cost:  0.46960273  - MSE:  2.2502258894068334 - Train Accuracy:  0.7590361\n",
      "epoch :  496  -  cost:  0.46948007  - MSE:  2.2500335814742174 - Train Accuracy:  0.7590361\n",
      "epoch :  497  -  cost:  0.46935764  - MSE:  2.249834176883427 - Train Accuracy:  0.7590361\n",
      "epoch :  498  -  cost:  0.46923542  - MSE:  2.249647141684293 - Train Accuracy:  0.7590361\n",
      "epoch :  499  -  cost:  0.4691135  - MSE:  2.2494576468025493 - Train Accuracy:  0.7590361\n",
      "epoch :  500  -  cost:  0.4689918  - MSE:  2.24926144778408 - Train Accuracy:  0.7590361\n",
      "epoch :  501  -  cost:  0.46887037  - MSE:  2.249076637825496 - Train Accuracy:  0.7590361\n",
      "epoch :  502  -  cost:  0.46874923  - MSE:  2.2488968715306945 - Train Accuracy:  0.7590361\n",
      "epoch :  503  -  cost:  0.4686283  - MSE:  2.2487117974243285 - Train Accuracy:  0.7590361\n",
      "epoch :  504  -  cost:  0.46850762  - MSE:  2.2485329035591266 - Train Accuracy:  0.7590361\n",
      "epoch :  505  -  cost:  0.4683872  - MSE:  2.2483563284796624 - Train Accuracy:  0.7590361\n",
      "epoch :  506  -  cost:  0.46826696  - MSE:  2.248178056836936 - Train Accuracy:  0.7590361\n",
      "epoch :  507  -  cost:  0.46814704  - MSE:  2.2480062163440775 - Train Accuracy:  0.7590361\n",
      "epoch :  508  -  cost:  0.46802723  - MSE:  2.247832616233923 - Train Accuracy:  0.7590361\n",
      "epoch :  509  -  cost:  0.4679078  - MSE:  2.247662368713253 - Train Accuracy:  0.7590361\n",
      "epoch :  510  -  cost:  0.46778855  - MSE:  2.2474844266589877 - Train Accuracy:  0.7590361\n",
      "epoch :  511  -  cost:  0.46766952  - MSE:  2.2473152645099623 - Train Accuracy:  0.7590361\n",
      "epoch :  512  -  cost:  0.46755072  - MSE:  2.2471374953687953 - Train Accuracy:  0.7590361\n",
      "epoch :  513  -  cost:  0.46743214  - MSE:  2.2469744242448284 - Train Accuracy:  0.7590361\n",
      "epoch :  514  -  cost:  0.46731383  - MSE:  2.246816028175646 - Train Accuracy:  0.7590361\n",
      "epoch :  515  -  cost:  0.46719572  - MSE:  2.246646144312026 - Train Accuracy:  0.7590361\n",
      "epoch :  516  -  cost:  0.46707782  - MSE:  2.2464870396397236 - Train Accuracy:  0.7590361\n",
      "epoch :  517  -  cost:  0.46696013  - MSE:  2.2463193298337294 - Train Accuracy:  0.7590361\n",
      "epoch :  518  -  cost:  0.4668427  - MSE:  2.24616059492596 - Train Accuracy:  0.7590361\n",
      "epoch :  519  -  cost:  0.46672544  - MSE:  2.2460026228468797 - Train Accuracy:  0.7590361\n",
      "epoch :  520  -  cost:  0.4666085  - MSE:  2.2458428549229428 - Train Accuracy:  0.7590361\n",
      "epoch :  521  -  cost:  0.4664917  - MSE:  2.2456895202821143 - Train Accuracy:  0.7590361\n",
      "epoch :  522  -  cost:  0.46637514  - MSE:  2.245529598123587 - Train Accuracy:  0.7590361\n",
      "epoch :  523  -  cost:  0.46625882  - MSE:  2.245379744327509 - Train Accuracy:  0.7590361\n",
      "epoch :  524  -  cost:  0.4661426  - MSE:  2.245219019317331 - Train Accuracy:  0.7590361\n",
      "epoch :  525  -  cost:  0.46602672  - MSE:  2.245063327196349 - Train Accuracy:  0.7590361\n",
      "epoch :  526  -  cost:  0.4659109  - MSE:  2.244909066515539 - Train Accuracy:  0.7590361\n",
      "epoch :  527  -  cost:  0.46579546  - MSE:  2.244759905091657 - Train Accuracy:  0.7590361\n",
      "epoch :  528  -  cost:  0.4656801  - MSE:  2.2446053386828346 - Train Accuracy:  0.7590361\n",
      "epoch :  529  -  cost:  0.465565  - MSE:  2.2444534821412683 - Train Accuracy:  0.7590361\n",
      "epoch :  530  -  cost:  0.4654501  - MSE:  2.2443090244076935 - Train Accuracy:  0.7590361\n",
      "epoch :  531  -  cost:  0.46533534  - MSE:  2.2441619592565933 - Train Accuracy:  0.7590361\n",
      "epoch :  532  -  cost:  0.4652209  - MSE:  2.244009044568968 - Train Accuracy:  0.7590361\n",
      "epoch :  533  -  cost:  0.46510652  - MSE:  2.243869436546286 - Train Accuracy:  0.7590361\n",
      "epoch :  534  -  cost:  0.46499234  - MSE:  2.2437274759812604 - Train Accuracy:  0.7590361\n",
      "epoch :  535  -  cost:  0.4648784  - MSE:  2.2435833457479517 - Train Accuracy:  0.7590361\n",
      "epoch :  536  -  cost:  0.46476465  - MSE:  2.243440957051112 - Train Accuracy:  0.75301206\n",
      "epoch :  537  -  cost:  0.464651  - MSE:  2.2432985767056604 - Train Accuracy:  0.75301206\n",
      "epoch :  538  -  cost:  0.46453756  - MSE:  2.24315754965247 - Train Accuracy:  0.75301206\n",
      "epoch :  539  -  cost:  0.46442422  - MSE:  2.243019909055216 - Train Accuracy:  0.75301206\n",
      "epoch :  540  -  cost:  0.46431112  - MSE:  2.2428779161984105 - Train Accuracy:  0.75301206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  541  -  cost:  0.46419814  - MSE:  2.2427442727937215 - Train Accuracy:  0.75301206\n",
      "epoch :  542  -  cost:  0.46408528  - MSE:  2.2426093920140793 - Train Accuracy:  0.75301206\n",
      "epoch :  543  -  cost:  0.46397248  - MSE:  2.242478667272619 - Train Accuracy:  0.75301206\n",
      "epoch :  544  -  cost:  0.4638598  - MSE:  2.2423497740875376 - Train Accuracy:  0.75301206\n",
      "epoch :  545  -  cost:  0.46374708  - MSE:  2.2422233044659445 - Train Accuracy:  0.7590361\n",
      "epoch :  546  -  cost:  0.4636344  - MSE:  2.242096899358568 - Train Accuracy:  0.7590361\n",
      "epoch :  547  -  cost:  0.46352175  - MSE:  2.241974162552622 - Train Accuracy:  0.7590361\n",
      "epoch :  548  -  cost:  0.46340892  - MSE:  2.241860199357846 - Train Accuracy:  0.7590361\n",
      "epoch :  549  -  cost:  0.46329585  - MSE:  2.2417448949778116 - Train Accuracy:  0.7590361\n",
      "epoch :  550  -  cost:  0.4631824  - MSE:  2.2416421387949192 - Train Accuracy:  0.7590361\n",
      "epoch :  551  -  cost:  0.46306825  - MSE:  2.241545398014999 - Train Accuracy:  0.7590361\n",
      "epoch :  552  -  cost:  0.46295285  - MSE:  2.2414582497786832 - Train Accuracy:  0.7590361\n",
      "epoch :  553  -  cost:  0.46283576  - MSE:  2.2413806178912252 - Train Accuracy:  0.7590361\n",
      "epoch :  554  -  cost:  0.462715  - MSE:  2.241319453833346 - Train Accuracy:  0.7590361\n",
      "epoch :  555  -  cost:  0.4625874  - MSE:  2.241280184589785 - Train Accuracy:  0.7590361\n",
      "epoch :  556  -  cost:  0.46244344  - MSE:  2.2412587851094923 - Train Accuracy:  0.7590361\n",
      "epoch :  557  -  cost:  0.4622507  - MSE:  2.241271184021921 - Train Accuracy:  0.7590361\n",
      "epoch :  558  -  cost:  0.46181878  - MSE:  2.2412129738946582 - Train Accuracy:  0.7590361\n",
      "epoch :  559  -  cost:  0.45912308  - MSE:  2.239454095315055 - Train Accuracy:  0.7590361\n",
      "epoch :  560  -  cost:  0.45921874  - MSE:  2.2513716968983166 - Train Accuracy:  0.76506025\n",
      "epoch :  561  -  cost:  0.45834163  - MSE:  2.2578504996525317 - Train Accuracy:  0.76506025\n",
      "epoch :  562  -  cost:  0.45776257  - MSE:  2.2617106896209638 - Train Accuracy:  0.76506025\n",
      "epoch :  563  -  cost:  0.45745012  - MSE:  2.2637155270410925 - Train Accuracy:  0.76506025\n",
      "epoch :  564  -  cost:  0.45709532  - MSE:  2.263410909075035 - Train Accuracy:  0.7710843\n",
      "epoch :  565  -  cost:  0.45600307  - MSE:  2.2570117950826534 - Train Accuracy:  0.7710843\n",
      "epoch :  566  -  cost:  0.45567143  - MSE:  2.2486770042593327 - Train Accuracy:  0.7710843\n",
      "epoch :  567  -  cost:  0.45633578  - MSE:  2.271681791499945 - Train Accuracy:  0.7710843\n",
      "epoch :  568  -  cost:  0.45581082  - MSE:  2.247934050469825 - Train Accuracy:  0.7710843\n",
      "epoch :  569  -  cost:  0.45603418  - MSE:  2.2751333257874693 - Train Accuracy:  0.7710843\n",
      "epoch :  570  -  cost:  0.45520505  - MSE:  2.2495944493855324 - Train Accuracy:  0.7710843\n",
      "epoch :  571  -  cost:  0.45462  - MSE:  2.275967658975815 - Train Accuracy:  0.7710843\n",
      "epoch :  572  -  cost:  0.4545333  - MSE:  2.2507342652533273 - Train Accuracy:  0.7710843\n",
      "epoch :  573  -  cost:  0.4538721  - MSE:  2.275190717850092 - Train Accuracy:  0.7710843\n",
      "epoch :  574  -  cost:  0.45357937  - MSE:  2.263289289465136 - Train Accuracy:  0.7710843\n",
      "epoch :  575  -  cost:  0.4534513  - MSE:  2.2664014406607307 - Train Accuracy:  0.7710843\n",
      "epoch :  576  -  cost:  0.45333862  - MSE:  2.266454184707029 - Train Accuracy:  0.7710843\n",
      "epoch :  577  -  cost:  0.4532273  - MSE:  2.2663238199243545 - Train Accuracy:  0.7710843\n",
      "epoch :  578  -  cost:  0.4531168  - MSE:  2.2661992140907703 - Train Accuracy:  0.7710843\n",
      "epoch :  579  -  cost:  0.4530071  - MSE:  2.2660849785311323 - Train Accuracy:  0.7710843\n",
      "epoch :  580  -  cost:  0.45289814  - MSE:  2.2659779825312274 - Train Accuracy:  0.7710843\n",
      "epoch :  581  -  cost:  0.45278963  - MSE:  2.265864319648738 - Train Accuracy:  0.7710843\n",
      "epoch :  582  -  cost:  0.45268172  - MSE:  2.2657466558803376 - Train Accuracy:  0.7710843\n",
      "epoch :  583  -  cost:  0.4525743  - MSE:  2.265629486863676 - Train Accuracy:  0.7710843\n",
      "epoch :  584  -  cost:  0.45246732  - MSE:  2.2655024164626383 - Train Accuracy:  0.7710843\n",
      "epoch :  585  -  cost:  0.45236072  - MSE:  2.265371898611447 - Train Accuracy:  0.7710843\n",
      "epoch :  586  -  cost:  0.4522546  - MSE:  2.2652305564550157 - Train Accuracy:  0.7710843\n",
      "epoch :  587  -  cost:  0.4521488  - MSE:  2.265084870472174 - Train Accuracy:  0.7710843\n",
      "epoch :  588  -  cost:  0.45204332  - MSE:  2.2649305579835985 - Train Accuracy:  0.7710843\n",
      "epoch :  589  -  cost:  0.45193818  - MSE:  2.264768294341031 - Train Accuracy:  0.7710843\n",
      "epoch :  590  -  cost:  0.45183337  - MSE:  2.2645987183253875 - Train Accuracy:  0.7710843\n",
      "epoch :  591  -  cost:  0.45172873  - MSE:  2.264424914340569 - Train Accuracy:  0.76506025\n",
      "epoch :  592  -  cost:  0.45162448  - MSE:  2.264240761476458 - Train Accuracy:  0.76506025\n",
      "epoch :  593  -  cost:  0.45152047  - MSE:  2.2640485454770563 - Train Accuracy:  0.76506025\n",
      "epoch :  594  -  cost:  0.45141658  - MSE:  2.263849477163722 - Train Accuracy:  0.76506025\n",
      "epoch :  595  -  cost:  0.45131302  - MSE:  2.263643323060909 - Train Accuracy:  0.76506025\n",
      "epoch :  596  -  cost:  0.45120957  - MSE:  2.2634299967963534 - Train Accuracy:  0.76506025\n",
      "epoch :  597  -  cost:  0.45110625  - MSE:  2.263206807738317 - Train Accuracy:  0.76506025\n",
      "epoch :  598  -  cost:  0.45100302  - MSE:  2.2629762331604124 - Train Accuracy:  0.76506025\n",
      "epoch :  599  -  cost:  0.45089987  - MSE:  2.2627328998189165 - Train Accuracy:  0.76506025\n",
      "epoch :  600  -  cost:  0.45079678  - MSE:  2.2624824578835563 - Train Accuracy:  0.76506025\n",
      "epoch :  601  -  cost:  0.4506936  - MSE:  2.2622146364527103 - Train Accuracy:  0.76506025\n",
      "epoch :  602  -  cost:  0.45059028  - MSE:  2.261939009499796 - Train Accuracy:  0.76506025\n",
      "epoch :  603  -  cost:  0.45048657  - MSE:  2.2616446364615617 - Train Accuracy:  0.76506025\n",
      "epoch :  604  -  cost:  0.4503823  - MSE:  2.2613305188361856 - Train Accuracy:  0.76506025\n",
      "epoch :  605  -  cost:  0.45027688  - MSE:  2.260991735054788 - Train Accuracy:  0.76506025\n",
      "epoch :  606  -  cost:  0.45016962  - MSE:  2.260623243397116 - Train Accuracy:  0.76506025\n",
      "epoch :  607  -  cost:  0.45005816  - MSE:  2.2602148341469777 - Train Accuracy:  0.76506025\n",
      "epoch :  608  -  cost:  0.44993693  - MSE:  2.2597386863553544 - Train Accuracy:  0.76506025\n",
      "epoch :  609  -  cost:  0.44978374  - MSE:  2.25917171640328 - Train Accuracy:  0.76506025\n",
      "epoch :  610  -  cost:  0.44943932  - MSE:  2.2584079002749666 - Train Accuracy:  0.76506025\n",
      "epoch :  611  -  cost:  0.44739398  - MSE:  2.256507965246284 - Train Accuracy:  0.76506025\n",
      "epoch :  612  -  cost:  0.4491572  - MSE:  2.2460972502168324 - Train Accuracy:  0.76506025\n",
      "epoch :  613  -  cost:  0.44518363  - MSE:  2.245692717516586 - Train Accuracy:  0.7710843\n",
      "epoch :  614  -  cost:  0.44486734  - MSE:  2.241300543489043 - Train Accuracy:  0.7710843\n",
      "epoch :  615  -  cost:  0.44831222  - MSE:  2.2363500569462635 - Train Accuracy:  0.76506025\n",
      "epoch :  616  -  cost:  0.44887882  - MSE:  2.2368578302449857 - Train Accuracy:  0.7590361\n",
      "epoch :  617  -  cost:  0.45497012  - MSE:  2.2711831873621855 - Train Accuracy:  0.7590361\n",
      "epoch :  618  -  cost:  0.45377326  - MSE:  2.2543407882068256 - Train Accuracy:  0.7590361\n",
      "epoch :  619  -  cost:  0.45284587  - MSE:  2.2531276658565402 - Train Accuracy:  0.7590361\n",
      "epoch :  620  -  cost:  0.44865602  - MSE:  2.255049530463416 - Train Accuracy:  0.76506025\n",
      "epoch :  621  -  cost:  0.44784242  - MSE:  2.2566694746825573 - Train Accuracy:  0.76506025\n",
      "epoch :  622  -  cost:  0.44756344  - MSE:  2.2543938666187864 - Train Accuracy:  0.76506025\n",
      "epoch :  623  -  cost:  0.44737202  - MSE:  2.2516891240776973 - Train Accuracy:  0.76506025\n",
      "epoch :  624  -  cost:  0.44721547  - MSE:  2.2496854173621457 - Train Accuracy:  0.76506025\n",
      "epoch :  625  -  cost:  0.44707692  - MSE:  2.2477607731572085 - Train Accuracy:  0.76506025\n",
      "epoch :  626  -  cost:  0.446948  - MSE:  2.2461512834835125 - Train Accuracy:  0.76506025\n",
      "epoch :  627  -  cost:  0.44682467  - MSE:  2.2446510496640535 - Train Accuracy:  0.76506025\n",
      "epoch :  628  -  cost:  0.44670445  - MSE:  2.243239358926556 - Train Accuracy:  0.76506025\n",
      "epoch :  629  -  cost:  0.44658536  - MSE:  2.2418808534550267 - Train Accuracy:  0.76506025\n",
      "epoch :  630  -  cost:  0.44646478  - MSE:  2.2405493318743637 - Train Accuracy:  0.76506025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  631  -  cost:  0.44633806  - MSE:  2.239246026983696 - Train Accuracy:  0.76506025\n",
      "epoch :  632  -  cost:  0.4461903  - MSE:  2.238011483904755 - Train Accuracy:  0.76506025\n",
      "epoch :  633  -  cost:  0.44594178  - MSE:  2.2370784310231873 - Train Accuracy:  0.76506025\n",
      "epoch :  634  -  cost:  0.44430074  - MSE:  2.237139615205191 - Train Accuracy:  0.76506025\n",
      "epoch :  635  -  cost:  0.4511172  - MSE:  2.228244573525908 - Train Accuracy:  0.75301206\n",
      "epoch :  636  -  cost:  0.4443272  - MSE:  2.2316128694806365 - Train Accuracy:  0.76506025\n",
      "epoch :  637  -  cost:  0.44484177  - MSE:  2.2242972457154786 - Train Accuracy:  0.7590361\n",
      "epoch :  638  -  cost:  0.4422121  - MSE:  2.232936744710735 - Train Accuracy:  0.76506025\n",
      "epoch :  639  -  cost:  0.4434956  - MSE:  2.2202901631688743 - Train Accuracy:  0.7590361\n",
      "epoch :  640  -  cost:  0.44001472  - MSE:  2.2216968146540332 - Train Accuracy:  0.7710843\n",
      "epoch :  641  -  cost:  0.4398324  - MSE:  2.2179559674646647 - Train Accuracy:  0.7710843\n",
      "epoch :  642  -  cost:  0.4397214  - MSE:  2.2173920783700405 - Train Accuracy:  0.7710843\n",
      "epoch :  643  -  cost:  0.4396146  - MSE:  2.217058376393667 - Train Accuracy:  0.7710843\n",
      "epoch :  644  -  cost:  0.43951026  - MSE:  2.216789229056605 - Train Accuracy:  0.7710843\n",
      "epoch :  645  -  cost:  0.4394075  - MSE:  2.2165433993436388 - Train Accuracy:  0.7710843\n",
      "epoch :  646  -  cost:  0.4393059  - MSE:  2.216310367733088 - Train Accuracy:  0.7710843\n",
      "epoch :  647  -  cost:  0.4392051  - MSE:  2.2160878621605518 - Train Accuracy:  0.7710843\n",
      "epoch :  648  -  cost:  0.43910506  - MSE:  2.215869054299638 - Train Accuracy:  0.7710843\n",
      "epoch :  649  -  cost:  0.43900555  - MSE:  2.215661262748977 - Train Accuracy:  0.7710843\n",
      "epoch :  650  -  cost:  0.43890652  - MSE:  2.2154542387923404 - Train Accuracy:  0.7710843\n",
      "epoch :  651  -  cost:  0.43880787  - MSE:  2.215248903844219 - Train Accuracy:  0.7710843\n",
      "epoch :  652  -  cost:  0.43870962  - MSE:  2.2150442495903273 - Train Accuracy:  0.7710843\n",
      "epoch :  653  -  cost:  0.43861175  - MSE:  2.2148359618210653 - Train Accuracy:  0.7710843\n",
      "epoch :  654  -  cost:  0.43851405  - MSE:  2.2146320091709693 - Train Accuracy:  0.7710843\n",
      "epoch :  655  -  cost:  0.43841678  - MSE:  2.214420435487498 - Train Accuracy:  0.7710843\n",
      "epoch :  656  -  cost:  0.43831965  - MSE:  2.2142105865183037 - Train Accuracy:  0.7710843\n",
      "epoch :  657  -  cost:  0.43822283  - MSE:  2.2139956245280055 - Train Accuracy:  0.7710843\n",
      "epoch :  658  -  cost:  0.43812627  - MSE:  2.2137805933259833 - Train Accuracy:  0.7710843\n",
      "epoch :  659  -  cost:  0.43802997  - MSE:  2.2135624365542763 - Train Accuracy:  0.7710843\n",
      "epoch :  660  -  cost:  0.43793386  - MSE:  2.2133389455473855 - Train Accuracy:  0.7710843\n",
      "epoch :  661  -  cost:  0.43783796  - MSE:  2.2131143240316025 - Train Accuracy:  0.7710843\n",
      "epoch :  662  -  cost:  0.43774226  - MSE:  2.2128822344760413 - Train Accuracy:  0.7710843\n",
      "epoch :  663  -  cost:  0.43764672  - MSE:  2.2126509740257783 - Train Accuracy:  0.7710843\n",
      "epoch :  664  -  cost:  0.43755144  - MSE:  2.2124190212132517 - Train Accuracy:  0.7710843\n",
      "epoch :  665  -  cost:  0.43745628  - MSE:  2.2121857235181195 - Train Accuracy:  0.7710843\n",
      "epoch :  666  -  cost:  0.4373613  - MSE:  2.211944856030004 - Train Accuracy:  0.7710843\n",
      "epoch :  667  -  cost:  0.43726638  - MSE:  2.2117014603483653 - Train Accuracy:  0.7710843\n",
      "epoch :  668  -  cost:  0.43717167  - MSE:  2.211452178881941 - Train Accuracy:  0.7710843\n",
      "epoch :  669  -  cost:  0.43707702  - MSE:  2.2111994461069804 - Train Accuracy:  0.7710843\n",
      "epoch :  670  -  cost:  0.43698248  - MSE:  2.2109507816351077 - Train Accuracy:  0.7710843\n",
      "epoch :  671  -  cost:  0.43688798  - MSE:  2.210691330649603 - Train Accuracy:  0.7710843\n",
      "epoch :  672  -  cost:  0.43679342  - MSE:  2.2104360264223586 - Train Accuracy:  0.7710843\n",
      "epoch :  673  -  cost:  0.43669876  - MSE:  2.210169011215071 - Train Accuracy:  0.7710843\n",
      "epoch :  674  -  cost:  0.43660387  - MSE:  2.209902236404176 - Train Accuracy:  0.7710843\n",
      "epoch :  675  -  cost:  0.43650863  - MSE:  2.2096388605293638 - Train Accuracy:  0.7710843\n",
      "epoch :  676  -  cost:  0.43641257  - MSE:  2.209371521186193 - Train Accuracy:  0.7710843\n",
      "epoch :  677  -  cost:  0.43631524  - MSE:  2.209104466177012 - Train Accuracy:  0.7710843\n",
      "epoch :  678  -  cost:  0.4362156  - MSE:  2.2088482715638142 - Train Accuracy:  0.7710843\n",
      "epoch :  679  -  cost:  0.43611088  - MSE:  2.2085998235552813 - Train Accuracy:  0.7710843\n",
      "epoch :  680  -  cost:  0.43599445  - MSE:  2.2083768615098363 - Train Accuracy:  0.7710843\n",
      "epoch :  681  -  cost:  0.43584126  - MSE:  2.2082029537302836 - Train Accuracy:  0.7710843\n",
      "epoch :  682  -  cost:  0.43551558  - MSE:  2.208027377089912 - Train Accuracy:  0.7710843\n",
      "epoch :  683  -  cost:  0.4346661  - MSE:  2.2074088569018846 - Train Accuracy:  0.7710843\n",
      "epoch :  684  -  cost:  0.4346086  - MSE:  2.205023902605226 - Train Accuracy:  0.7710843\n",
      "epoch :  685  -  cost:  0.4355211  - MSE:  2.2037948397159646 - Train Accuracy:  0.7710843\n",
      "epoch :  686  -  cost:  0.43871978  - MSE:  2.2221689596410323 - Train Accuracy:  0.76506025\n",
      "epoch :  687  -  cost:  0.43480605  - MSE:  2.2011028909377197 - Train Accuracy:  0.7710843\n",
      "epoch :  688  -  cost:  0.43554  - MSE:  2.215041743266559 - Train Accuracy:  0.7710843\n",
      "epoch :  689  -  cost:  0.43523633  - MSE:  2.2069993534572725 - Train Accuracy:  0.7710843\n",
      "epoch :  690  -  cost:  0.43491888  - MSE:  2.2022918431459266 - Train Accuracy:  0.7710843\n",
      "epoch :  691  -  cost:  0.4336028  - MSE:  2.200416415777385 - Train Accuracy:  0.7710843\n",
      "epoch :  692  -  cost:  0.43293065  - MSE:  2.1998456744960087 - Train Accuracy:  0.7710843\n",
      "epoch :  693  -  cost:  0.43265745  - MSE:  2.202427436935145 - Train Accuracy:  0.7710843\n",
      "epoch :  694  -  cost:  0.43256065  - MSE:  2.202095670444019 - Train Accuracy:  0.7710843\n",
      "epoch :  695  -  cost:  0.43246707  - MSE:  2.2016002386589086 - Train Accuracy:  0.7710843\n",
      "epoch :  696  -  cost:  0.43237492  - MSE:  2.2011405444154506 - Train Accuracy:  0.7710843\n",
      "epoch :  697  -  cost:  0.43228388  - MSE:  2.200750841554139 - Train Accuracy:  0.7710843\n",
      "epoch :  698  -  cost:  0.4321935  - MSE:  2.2004331484133535 - Train Accuracy:  0.7710843\n",
      "epoch :  699  -  cost:  0.4321038  - MSE:  2.200176705182711 - Train Accuracy:  0.7710843\n",
      "epoch :  700  -  cost:  0.43201473  - MSE:  2.1999710608886214 - Train Accuracy:  0.7710843\n",
      "epoch :  701  -  cost:  0.43192607  - MSE:  2.1998085306913673 - Train Accuracy:  0.7710843\n",
      "epoch :  702  -  cost:  0.43183783  - MSE:  2.1996801851676007 - Train Accuracy:  0.7710843\n",
      "epoch :  703  -  cost:  0.43175  - MSE:  2.1995837107634832 - Train Accuracy:  0.7710843\n",
      "epoch :  704  -  cost:  0.43166256  - MSE:  2.199512867697501 - Train Accuracy:  0.7710843\n",
      "epoch :  705  -  cost:  0.43157542  - MSE:  2.1994606161390986 - Train Accuracy:  0.7710843\n",
      "epoch :  706  -  cost:  0.43148872  - MSE:  2.199408344532774 - Train Accuracy:  0.7710843\n",
      "epoch :  707  -  cost:  0.43140233  - MSE:  2.199375101251316 - Train Accuracy:  0.7710843\n",
      "epoch :  708  -  cost:  0.4313161  - MSE:  2.1993536256197386 - Train Accuracy:  0.7710843\n",
      "epoch :  709  -  cost:  0.4312302  - MSE:  2.19933975614804 - Train Accuracy:  0.7710843\n",
      "epoch :  710  -  cost:  0.43114454  - MSE:  2.199329089716566 - Train Accuracy:  0.7710843\n",
      "epoch :  711  -  cost:  0.4310591  - MSE:  2.1993251947471855 - Train Accuracy:  0.7710843\n",
      "epoch :  712  -  cost:  0.4309739  - MSE:  2.1993246179918846 - Train Accuracy:  0.7710843\n",
      "epoch :  713  -  cost:  0.43088895  - MSE:  2.1993317661802587 - Train Accuracy:  0.7710843\n",
      "epoch :  714  -  cost:  0.43080416  - MSE:  2.199338077942807 - Train Accuracy:  0.7710843\n",
      "epoch :  715  -  cost:  0.4307196  - MSE:  2.1993473051596246 - Train Accuracy:  0.77710843\n",
      "epoch :  716  -  cost:  0.43063533  - MSE:  2.1993540252792005 - Train Accuracy:  0.77710843\n",
      "epoch :  717  -  cost:  0.43055108  - MSE:  2.199366424520094 - Train Accuracy:  0.77710843\n",
      "epoch :  718  -  cost:  0.43046716  - MSE:  2.1993758640139283 - Train Accuracy:  0.77710843\n",
      "epoch :  719  -  cost:  0.43038338  - MSE:  2.1993815115729864 - Train Accuracy:  0.77710843\n",
      "epoch :  720  -  cost:  0.43029982  - MSE:  2.199390202663875 - Train Accuracy:  0.77710843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  721  -  cost:  0.4302164  - MSE:  2.1993966695532614 - Train Accuracy:  0.77710843\n",
      "epoch :  722  -  cost:  0.43013316  - MSE:  2.1994029260647325 - Train Accuracy:  0.77710843\n",
      "epoch :  723  -  cost:  0.43005008  - MSE:  2.1994064744020623 - Train Accuracy:  0.77710843\n",
      "epoch :  724  -  cost:  0.42996716  - MSE:  2.1994082575124123 - Train Accuracy:  0.77710843\n",
      "epoch :  725  -  cost:  0.4298845  - MSE:  2.1994071107596707 - Train Accuracy:  0.77710843\n",
      "epoch :  726  -  cost:  0.42980188  - MSE:  2.199402652976267 - Train Accuracy:  0.77710843\n",
      "epoch :  727  -  cost:  0.42971936  - MSE:  2.1994039394570986 - Train Accuracy:  0.77710843\n",
      "epoch :  728  -  cost:  0.42963713  - MSE:  2.199398674093956 - Train Accuracy:  0.77710843\n",
      "epoch :  729  -  cost:  0.429555  - MSE:  2.1993921532862064 - Train Accuracy:  0.77710843\n",
      "epoch :  730  -  cost:  0.42947295  - MSE:  2.199383627616845 - Train Accuracy:  0.77710843\n",
      "epoch :  731  -  cost:  0.42939106  - MSE:  2.199373818900691 - Train Accuracy:  0.77710843\n",
      "epoch :  732  -  cost:  0.42930934  - MSE:  2.1993629612274366 - Train Accuracy:  0.77710843\n",
      "epoch :  733  -  cost:  0.42922768  - MSE:  2.199346011038931 - Train Accuracy:  0.77710843\n",
      "epoch :  734  -  cost:  0.42914608  - MSE:  2.19933255215428 - Train Accuracy:  0.77710843\n",
      "epoch :  735  -  cost:  0.4290646  - MSE:  2.199314432554717 - Train Accuracy:  0.77710843\n",
      "epoch :  736  -  cost:  0.4289833  - MSE:  2.199297372364028 - Train Accuracy:  0.77710843\n",
      "epoch :  737  -  cost:  0.428902  - MSE:  2.1992731312301217 - Train Accuracy:  0.77710843\n",
      "epoch :  738  -  cost:  0.42882073  - MSE:  2.199248850134216 - Train Accuracy:  0.77710843\n",
      "epoch :  739  -  cost:  0.42873943  - MSE:  2.1992297454717002 - Train Accuracy:  0.77710843\n",
      "epoch :  740  -  cost:  0.42865813  - MSE:  2.1992023792045745 - Train Accuracy:  0.77710843\n",
      "epoch :  741  -  cost:  0.42857683  - MSE:  2.199178404084769 - Train Accuracy:  0.77710843\n",
      "epoch :  742  -  cost:  0.42849526  - MSE:  2.1991560428045807 - Train Accuracy:  0.77710843\n",
      "epoch :  743  -  cost:  0.42841366  - MSE:  2.1991321783161744 - Train Accuracy:  0.77710843\n",
      "epoch :  744  -  cost:  0.42833167  - MSE:  2.1991064538996365 - Train Accuracy:  0.77710843\n",
      "epoch :  745  -  cost:  0.42824942  - MSE:  2.1990823238684305 - Train Accuracy:  0.77710843\n",
      "epoch :  746  -  cost:  0.42816654  - MSE:  2.1990595410162928 - Train Accuracy:  0.78313255\n",
      "epoch :  747  -  cost:  0.42808297  - MSE:  2.1990332123070337 - Train Accuracy:  0.78313255\n",
      "epoch :  748  -  cost:  0.4279986  - MSE:  2.1990038646848715 - Train Accuracy:  0.78313255\n",
      "epoch :  749  -  cost:  0.42791334  - MSE:  2.1989668270368004 - Train Accuracy:  0.78313255\n",
      "epoch :  750  -  cost:  0.42782748  - MSE:  2.1989276903868493 - Train Accuracy:  0.78313255\n",
      "epoch :  751  -  cost:  0.42774123  - MSE:  2.1988735548763585 - Train Accuracy:  0.78313255\n",
      "epoch :  752  -  cost:  0.427655  - MSE:  2.1987905792634748 - Train Accuracy:  0.78313255\n",
      "epoch :  753  -  cost:  0.42756897  - MSE:  2.198675323180002 - Train Accuracy:  0.78313255\n",
      "epoch :  754  -  cost:  0.42748326  - MSE:  2.1985333434918566 - Train Accuracy:  0.78313255\n",
      "epoch :  755  -  cost:  0.4273981  - MSE:  2.1983694585579734 - Train Accuracy:  0.78313255\n",
      "epoch :  756  -  cost:  0.42731342  - MSE:  2.1981789164644874 - Train Accuracy:  0.78313255\n",
      "epoch :  757  -  cost:  0.4272293  - MSE:  2.1979728456747503 - Train Accuracy:  0.78313255\n",
      "epoch :  758  -  cost:  0.42714575  - MSE:  2.1977602452346323 - Train Accuracy:  0.78313255\n",
      "epoch :  759  -  cost:  0.42706275  - MSE:  2.1975379119989293 - Train Accuracy:  0.78313255\n",
      "epoch :  760  -  cost:  0.42698026  - MSE:  2.1973122870197006 - Train Accuracy:  0.78313255\n",
      "epoch :  761  -  cost:  0.42689827  - MSE:  2.1970843296883906 - Train Accuracy:  0.7891566\n",
      "epoch :  762  -  cost:  0.42681682  - MSE:  2.1968549637369925 - Train Accuracy:  0.7891566\n",
      "epoch :  763  -  cost:  0.42673576  - MSE:  2.196625160730259 - Train Accuracy:  0.7891566\n",
      "epoch :  764  -  cost:  0.42665508  - MSE:  2.1963945685888304 - Train Accuracy:  0.7891566\n",
      "epoch :  765  -  cost:  0.4265749  - MSE:  2.196172110635498 - Train Accuracy:  0.7891566\n",
      "epoch :  766  -  cost:  0.42649502  - MSE:  2.1959464480596305 - Train Accuracy:  0.7891566\n",
      "epoch :  767  -  cost:  0.42641553  - MSE:  2.195717035150667 - Train Accuracy:  0.7891566\n",
      "epoch :  768  -  cost:  0.42633635  - MSE:  2.195497941868144 - Train Accuracy:  0.7891566\n",
      "epoch :  769  -  cost:  0.42625752  - MSE:  2.195283976654364 - Train Accuracy:  0.7891566\n",
      "epoch :  770  -  cost:  0.426179  - MSE:  2.195075913240685 - Train Accuracy:  0.7891566\n",
      "epoch :  771  -  cost:  0.42610076  - MSE:  2.194877011552813 - Train Accuracy:  0.7891566\n",
      "epoch :  772  -  cost:  0.42602277  - MSE:  2.1946807671536264 - Train Accuracy:  0.7891566\n",
      "epoch :  773  -  cost:  0.42594504  - MSE:  2.1944825132989823 - Train Accuracy:  0.7891566\n",
      "epoch :  774  -  cost:  0.42586756  - MSE:  2.1942893650716053 - Train Accuracy:  0.7891566\n",
      "epoch :  775  -  cost:  0.42579034  - MSE:  2.194098484810403 - Train Accuracy:  0.7891566\n",
      "epoch :  776  -  cost:  0.42571327  - MSE:  2.1939060289676746 - Train Accuracy:  0.7891566\n",
      "epoch :  777  -  cost:  0.42563647  - MSE:  2.1937212042792527 - Train Accuracy:  0.7891566\n",
      "epoch :  778  -  cost:  0.42555982  - MSE:  2.1935335589263074 - Train Accuracy:  0.7891566\n",
      "epoch :  779  -  cost:  0.42548338  - MSE:  2.193346544802856 - Train Accuracy:  0.7891566\n",
      "epoch :  780  -  cost:  0.42540708  - MSE:  2.193163461376934 - Train Accuracy:  0.7891566\n",
      "epoch :  781  -  cost:  0.42533094  - MSE:  2.1929742263807195 - Train Accuracy:  0.7891566\n",
      "epoch :  782  -  cost:  0.425255  - MSE:  2.192791891338867 - Train Accuracy:  0.79518074\n",
      "epoch :  783  -  cost:  0.42517912  - MSE:  2.1926106384714337 - Train Accuracy:  0.79518074\n",
      "epoch :  784  -  cost:  0.42510334  - MSE:  2.1924215836678402 - Train Accuracy:  0.79518074\n",
      "epoch :  785  -  cost:  0.42502773  - MSE:  2.1922452811172826 - Train Accuracy:  0.79518074\n",
      "epoch :  786  -  cost:  0.4249522  - MSE:  2.1920611328917605 - Train Accuracy:  0.79518074\n",
      "epoch :  787  -  cost:  0.42487684  - MSE:  2.191885338233878 - Train Accuracy:  0.79518074\n",
      "epoch :  788  -  cost:  0.42480147  - MSE:  2.1916943554292994 - Train Accuracy:  0.79518074\n",
      "epoch :  789  -  cost:  0.4247262  - MSE:  2.1915094176500025 - Train Accuracy:  0.79518074\n",
      "epoch :  790  -  cost:  0.4246509  - MSE:  2.1913194787114656 - Train Accuracy:  0.79518074\n",
      "epoch :  791  -  cost:  0.42457563  - MSE:  2.1911191663452536 - Train Accuracy:  0.79518074\n",
      "epoch :  792  -  cost:  0.42450035  - MSE:  2.190919139507772 - Train Accuracy:  0.79518074\n",
      "epoch :  793  -  cost:  0.42442498  - MSE:  2.190707607083572 - Train Accuracy:  0.79518074\n",
      "epoch :  794  -  cost:  0.4243495  - MSE:  2.1904893141870163 - Train Accuracy:  0.79518074\n",
      "epoch :  795  -  cost:  0.42427388  - MSE:  2.1902569857165863 - Train Accuracy:  0.79518074\n",
      "epoch :  796  -  cost:  0.4241981  - MSE:  2.190016018804017 - Train Accuracy:  0.79518074\n",
      "epoch :  797  -  cost:  0.42412195  - MSE:  2.1897520473923664 - Train Accuracy:  0.79518074\n",
      "epoch :  798  -  cost:  0.4240455  - MSE:  2.189475107800884 - Train Accuracy:  0.79518074\n",
      "epoch :  799  -  cost:  0.4239684  - MSE:  2.189170119369209 - Train Accuracy:  0.79518074\n",
      "epoch :  800  -  cost:  0.4238906  - MSE:  2.18884083848205 - Train Accuracy:  0.79518074\n",
      "epoch :  801  -  cost:  0.42381185  - MSE:  2.1884714234330667 - Train Accuracy:  0.79518074\n",
      "epoch :  802  -  cost:  0.4237316  - MSE:  2.188062842946955 - Train Accuracy:  0.79518074\n",
      "epoch :  803  -  cost:  0.4236496  - MSE:  2.187589721927044 - Train Accuracy:  0.79518074\n",
      "epoch :  804  -  cost:  0.42356476  - MSE:  2.1870465056690516 - Train Accuracy:  0.79518074\n",
      "epoch :  805  -  cost:  0.4234759  - MSE:  2.186409805060941 - Train Accuracy:  0.79518074\n",
      "epoch :  806  -  cost:  0.42338046  - MSE:  2.1856342615420807 - Train Accuracy:  0.79518074\n",
      "epoch :  807  -  cost:  0.42327425  - MSE:  2.184697066712413 - Train Accuracy:  0.79518074\n",
      "epoch :  808  -  cost:  0.42314744  - MSE:  2.183523445270446 - Train Accuracy:  0.79518074\n",
      "epoch :  809  -  cost:  0.4229749  - MSE:  2.181966505731796 - Train Accuracy:  0.79518074\n",
      "epoch :  810  -  cost:  0.42267475  - MSE:  2.179761685021757 - Train Accuracy:  0.79518074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  811  -  cost:  0.4220053  - MSE:  2.176405652247593 - Train Accuracy:  0.79518074\n",
      "epoch :  812  -  cost:  0.42125556  - MSE:  2.1723685616789856 - Train Accuracy:  0.79518074\n",
      "epoch :  813  -  cost:  0.4210564  - MSE:  2.1719781570287835 - Train Accuracy:  0.79518074\n",
      "epoch :  814  -  cost:  0.4209292  - MSE:  2.1725109481033305 - Train Accuracy:  0.79518074\n",
      "epoch :  815  -  cost:  0.42082188  - MSE:  2.1732865409367603 - Train Accuracy:  0.79518074\n",
      "epoch :  816  -  cost:  0.4207245  - MSE:  2.1741405100150275 - Train Accuracy:  0.79518074\n",
      "epoch :  817  -  cost:  0.4206332  - MSE:  2.1749942850074255 - Train Accuracy:  0.79518074\n",
      "epoch :  818  -  cost:  0.4205458  - MSE:  2.1758060180050904 - Train Accuracy:  0.79518074\n",
      "epoch :  819  -  cost:  0.42046118  - MSE:  2.176551287999577 - Train Accuracy:  0.79518074\n",
      "epoch :  820  -  cost:  0.4203786  - MSE:  2.177231271446549 - Train Accuracy:  0.79518074\n",
      "epoch :  821  -  cost:  0.42029727  - MSE:  2.177826728554603 - Train Accuracy:  0.79518074\n",
      "epoch :  822  -  cost:  0.42021647  - MSE:  2.1783432998137506 - Train Accuracy:  0.79518074\n",
      "epoch :  823  -  cost:  0.42013523  - MSE:  2.1787708010255895 - Train Accuracy:  0.79518074\n",
      "epoch :  824  -  cost:  0.420052  - MSE:  2.1790892852320773 - Train Accuracy:  0.79518074\n",
      "epoch :  825  -  cost:  0.41996348  - MSE:  2.1792737560452373 - Train Accuracy:  0.79518074\n",
      "epoch :  826  -  cost:  0.41986084  - MSE:  2.179255118449451 - Train Accuracy:  0.79518074\n",
      "epoch :  827  -  cost:  0.41971156  - MSE:  2.178846448755947 - Train Accuracy:  0.79518074\n",
      "epoch :  828  -  cost:  0.41932204  - MSE:  2.1774438419069693 - Train Accuracy:  0.8012048\n",
      "epoch :  829  -  cost:  0.41792724  - MSE:  2.172306914592959 - Train Accuracy:  0.8072289\n",
      "epoch :  830  -  cost:  0.4176507  - MSE:  2.1718796184771167 - Train Accuracy:  0.8072289\n",
      "epoch :  831  -  cost:  0.41755742  - MSE:  2.175040902542581 - Train Accuracy:  0.8072289\n",
      "epoch :  832  -  cost:  0.4174776  - MSE:  2.1769013268534403 - Train Accuracy:  0.8072289\n",
      "epoch :  833  -  cost:  0.4174034  - MSE:  2.178181522502397 - Train Accuracy:  0.8072289\n",
      "epoch :  834  -  cost:  0.4173321  - MSE:  2.179141937492141 - Train Accuracy:  0.8072289\n",
      "epoch :  835  -  cost:  0.4172627  - MSE:  2.179918691026901 - Train Accuracy:  0.8072289\n",
      "epoch :  836  -  cost:  0.41719446  - MSE:  2.180563408611478 - Train Accuracy:  0.8072289\n",
      "epoch :  837  -  cost:  0.41712698  - MSE:  2.181136297235657 - Train Accuracy:  0.8072289\n",
      "epoch :  838  -  cost:  0.4170598  - MSE:  2.1816554194233864 - Train Accuracy:  0.8072289\n",
      "epoch :  839  -  cost:  0.41699255  - MSE:  2.18215130619778 - Train Accuracy:  0.8072289\n",
      "epoch :  840  -  cost:  0.41692457  - MSE:  2.1826360605792585 - Train Accuracy:  0.8072289\n",
      "epoch :  841  -  cost:  0.41685468  - MSE:  2.183138978584825 - Train Accuracy:  0.8072289\n",
      "epoch :  842  -  cost:  0.41678086  - MSE:  2.1836838974277972 - Train Accuracy:  0.8072289\n",
      "epoch :  843  -  cost:  0.41669726  - MSE:  2.184321380967001 - Train Accuracy:  0.8072289\n",
      "epoch :  844  -  cost:  0.41658717  - MSE:  2.1851070872256377 - Train Accuracy:  0.8072289\n",
      "epoch :  845  -  cost:  0.41640267  - MSE:  2.1860801236076384 - Train Accuracy:  0.8072289\n",
      "epoch :  846  -  cost:  0.41618806  - MSE:  2.187018423211402 - Train Accuracy:  0.8072289\n",
      "epoch :  847  -  cost:  0.4160787  - MSE:  2.1872655495858 - Train Accuracy:  0.8072289\n",
      "epoch :  848  -  cost:  0.4159841  - MSE:  2.1872494830010134 - Train Accuracy:  0.8072289\n",
      "epoch :  849  -  cost:  0.4158988  - MSE:  2.1870424612743755 - Train Accuracy:  0.8072289\n",
      "epoch :  850  -  cost:  0.41581962  - MSE:  2.1867400339100675 - Train Accuracy:  0.8072289\n",
      "epoch :  851  -  cost:  0.41574478  - MSE:  2.1863769880629267 - Train Accuracy:  0.813253\n",
      "epoch :  852  -  cost:  0.41567305  - MSE:  2.185984834879584 - Train Accuracy:  0.813253\n",
      "epoch :  853  -  cost:  0.41560364  - MSE:  2.1855744966142265 - Train Accuracy:  0.813253\n",
      "epoch :  854  -  cost:  0.41553608  - MSE:  2.1851639374305103 - Train Accuracy:  0.813253\n",
      "epoch :  855  -  cost:  0.41546988  - MSE:  2.184752795080523 - Train Accuracy:  0.813253\n",
      "epoch :  856  -  cost:  0.41540483  - MSE:  2.1843369672312942 - Train Accuracy:  0.813253\n",
      "epoch :  857  -  cost:  0.4153406  - MSE:  2.1839376326647337 - Train Accuracy:  0.813253\n",
      "epoch :  858  -  cost:  0.41527718  - MSE:  2.183536217435346 - Train Accuracy:  0.813253\n",
      "epoch :  859  -  cost:  0.41521448  - MSE:  2.1831424415504523 - Train Accuracy:  0.813253\n",
      "epoch :  860  -  cost:  0.41515222  - MSE:  2.182748438837119 - Train Accuracy:  0.813253\n",
      "epoch :  861  -  cost:  0.4150905  - MSE:  2.18235519501005 - Train Accuracy:  0.813253\n",
      "epoch :  862  -  cost:  0.41502914  - MSE:  2.181963926500982 - Train Accuracy:  0.813253\n",
      "epoch :  863  -  cost:  0.41496804  - MSE:  2.181562568210447 - Train Accuracy:  0.813253\n",
      "epoch :  864  -  cost:  0.4149074  - MSE:  2.1811594440442925 - Train Accuracy:  0.813253\n",
      "epoch :  865  -  cost:  0.4148469  - MSE:  2.1807349930633992 - Train Accuracy:  0.813253\n",
      "epoch :  866  -  cost:  0.4147866  - MSE:  2.180299834663198 - Train Accuracy:  0.813253\n",
      "epoch :  867  -  cost:  0.41472644  - MSE:  2.1798326841024767 - Train Accuracy:  0.813253\n",
      "epoch :  868  -  cost:  0.41466647  - MSE:  2.179337089120829 - Train Accuracy:  0.813253\n",
      "epoch :  869  -  cost:  0.41460645  - MSE:  2.178794613438065 - Train Accuracy:  0.813253\n",
      "epoch :  870  -  cost:  0.41454646  - MSE:  2.1781954602733338 - Train Accuracy:  0.813253\n",
      "epoch :  871  -  cost:  0.4144863  - MSE:  2.177518729210701 - Train Accuracy:  0.813253\n",
      "epoch :  872  -  cost:  0.41442594  - MSE:  2.17673164293122 - Train Accuracy:  0.813253\n",
      "epoch :  873  -  cost:  0.4143651  - MSE:  2.175794783609741 - Train Accuracy:  0.813253\n",
      "epoch :  874  -  cost:  0.41430348  - MSE:  2.1746470183525446 - Train Accuracy:  0.813253\n",
      "epoch :  875  -  cost:  0.41424042  - MSE:  2.1731740878855867 - Train Accuracy:  0.813253\n",
      "epoch :  876  -  cost:  0.4141748  - MSE:  2.1712017330655833 - Train Accuracy:  0.813253\n",
      "epoch :  877  -  cost:  0.4141038  - MSE:  2.168362966677234 - Train Accuracy:  0.813253\n",
      "epoch :  878  -  cost:  0.4140196  - MSE:  2.1639237854060194 - Train Accuracy:  0.813253\n",
      "epoch :  879  -  cost:  0.41389373  - MSE:  2.156091360284949 - Train Accuracy:  0.813253\n",
      "epoch :  880  -  cost:  0.4135521  - MSE:  2.1407268011603575 - Train Accuracy:  0.813253\n",
      "epoch :  881  -  cost:  0.4126714  - MSE:  2.120504805858063 - Train Accuracy:  0.8192771\n",
      "epoch :  882  -  cost:  0.41394222  - MSE:  2.191129184036195 - Train Accuracy:  0.813253\n",
      "epoch :  883  -  cost:  0.41377598  - MSE:  2.185872179636196 - Train Accuracy:  0.813253\n",
      "epoch :  884  -  cost:  0.41360107  - MSE:  2.1784825341749543 - Train Accuracy:  0.813253\n",
      "epoch :  885  -  cost:  0.41305864  - MSE:  2.159413363458802 - Train Accuracy:  0.813253\n",
      "epoch :  886  -  cost:  0.41091162  - MSE:  2.1264554188925793 - Train Accuracy:  0.8192771\n",
      "epoch :  887  -  cost:  0.41239083  - MSE:  2.1564790295978025 - Train Accuracy:  0.8192771\n",
      "epoch :  888  -  cost:  0.4132429  - MSE:  2.1320248397430035 - Train Accuracy:  0.813253\n",
      "epoch :  889  -  cost:  0.42251343  - MSE:  2.225219236528642 - Train Accuracy:  0.8072289\n",
      "epoch :  890  -  cost:  0.42103252  - MSE:  2.208711772001024 - Train Accuracy:  0.8072289\n",
      "epoch :  891  -  cost:  0.41457987  - MSE:  2.2145996909120584 - Train Accuracy:  0.813253\n",
      "epoch :  892  -  cost:  0.41289836  - MSE:  2.1866121354060946 - Train Accuracy:  0.813253\n",
      "epoch :  893  -  cost:  0.4100464  - MSE:  2.1376089514603427 - Train Accuracy:  0.8192771\n",
      "epoch :  894  -  cost:  0.40983522  - MSE:  2.1344150691746324 - Train Accuracy:  0.8192771\n",
      "epoch :  895  -  cost:  0.40973866  - MSE:  2.134181296973349 - Train Accuracy:  0.8192771\n",
      "epoch :  896  -  cost:  0.4096666  - MSE:  2.1333392780205185 - Train Accuracy:  0.8192771\n",
      "epoch :  897  -  cost:  0.40960106  - MSE:  2.1326085112889306 - Train Accuracy:  0.8192771\n",
      "epoch :  898  -  cost:  0.40953854  - MSE:  2.13197626554381 - Train Accuracy:  0.8192771\n",
      "epoch :  899  -  cost:  0.4094779  - MSE:  2.1314279190234755 - Train Accuracy:  0.8192771\n",
      "epoch :  900  -  cost:  0.40941858  - MSE:  2.13097387114328 - Train Accuracy:  0.8192771\n",
      "epoch :  901  -  cost:  0.40936032  - MSE:  2.1305866871676447 - Train Accuracy:  0.8192771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  902  -  cost:  0.40930277  - MSE:  2.130253140477412 - Train Accuracy:  0.8192771\n",
      "epoch :  903  -  cost:  0.40924588  - MSE:  2.1299546641548868 - Train Accuracy:  0.8192771\n",
      "epoch :  904  -  cost:  0.40918946  - MSE:  2.129696637005385 - Train Accuracy:  0.8192771\n",
      "epoch :  905  -  cost:  0.40913355  - MSE:  2.1294703632956096 - Train Accuracy:  0.8192771\n",
      "epoch :  906  -  cost:  0.40907797  - MSE:  2.129262499834917 - Train Accuracy:  0.8192771\n",
      "epoch :  907  -  cost:  0.4090227  - MSE:  2.1290838218774093 - Train Accuracy:  0.8192771\n",
      "epoch :  908  -  cost:  0.40896782  - MSE:  2.128918943231543 - Train Accuracy:  0.8192771\n",
      "epoch :  909  -  cost:  0.40891317  - MSE:  2.1287657473158355 - Train Accuracy:  0.8192771\n",
      "epoch :  910  -  cost:  0.4088587  - MSE:  2.1286336583848016 - Train Accuracy:  0.8192771\n",
      "epoch :  911  -  cost:  0.40880466  - MSE:  2.128476872498806 - Train Accuracy:  0.8192771\n",
      "epoch :  912  -  cost:  0.40875074  - MSE:  2.128337816838879 - Train Accuracy:  0.8192771\n",
      "epoch :  913  -  cost:  0.408697  - MSE:  2.1282109139420813 - Train Accuracy:  0.8192771\n",
      "epoch :  914  -  cost:  0.40864348  - MSE:  2.1280930312343327 - Train Accuracy:  0.8192771\n",
      "epoch :  915  -  cost:  0.40859008  - MSE:  2.1279806128604015 - Train Accuracy:  0.8192771\n",
      "epoch :  916  -  cost:  0.4085368  - MSE:  2.127877696382485 - Train Accuracy:  0.8192771\n",
      "epoch :  917  -  cost:  0.40848374  - MSE:  2.127777602409256 - Train Accuracy:  0.8192771\n",
      "epoch :  918  -  cost:  0.4084308  - MSE:  2.127687655796335 - Train Accuracy:  0.8192771\n",
      "epoch :  919  -  cost:  0.40837803  - MSE:  2.1275949018548013 - Train Accuracy:  0.8192771\n",
      "epoch :  920  -  cost:  0.40832534  - MSE:  2.1275129718839465 - Train Accuracy:  0.8192771\n",
      "epoch :  921  -  cost:  0.40827274  - MSE:  2.1274334472705645 - Train Accuracy:  0.8192771\n",
      "epoch :  922  -  cost:  0.40822032  - MSE:  2.127355288100359 - Train Accuracy:  0.8192771\n",
      "epoch :  923  -  cost:  0.40816796  - MSE:  2.1272704722991085 - Train Accuracy:  0.8192771\n",
      "epoch :  924  -  cost:  0.40811574  - MSE:  2.127194542635911 - Train Accuracy:  0.8192771\n",
      "epoch :  925  -  cost:  0.4080636  - MSE:  2.127115190187481 - Train Accuracy:  0.8192771\n",
      "epoch :  926  -  cost:  0.40801156  - MSE:  2.127045540162805 - Train Accuracy:  0.8192771\n",
      "epoch :  927  -  cost:  0.40795964  - MSE:  2.126977166112728 - Train Accuracy:  0.8192771\n",
      "epoch :  928  -  cost:  0.40790763  - MSE:  2.1269128041999723 - Train Accuracy:  0.8192771\n",
      "epoch :  929  -  cost:  0.4078559  - MSE:  2.126870008436828 - Train Accuracy:  0.8192771\n",
      "epoch :  930  -  cost:  0.40780413  - MSE:  2.1268266170481875 - Train Accuracy:  0.8192771\n",
      "epoch :  931  -  cost:  0.4077524  - MSE:  2.126792961485707 - Train Accuracy:  0.82530123\n",
      "epoch :  932  -  cost:  0.40770084  - MSE:  2.1267539373438127 - Train Accuracy:  0.82530123\n",
      "epoch :  933  -  cost:  0.40764916  - MSE:  2.1267189495243364 - Train Accuracy:  0.82530123\n",
      "epoch :  934  -  cost:  0.4075976  - MSE:  2.126688968897449 - Train Accuracy:  0.82530123\n",
      "epoch :  935  -  cost:  0.40754613  - MSE:  2.1266652455284962 - Train Accuracy:  0.82530123\n",
      "epoch :  936  -  cost:  0.40749454  - MSE:  2.1266386234799195 - Train Accuracy:  0.82530123\n",
      "epoch :  937  -  cost:  0.40744308  - MSE:  2.1266633897200684 - Train Accuracy:  0.82530123\n",
      "epoch :  938  -  cost:  0.40739155  - MSE:  2.126717656866916 - Train Accuracy:  0.82530123\n",
      "epoch :  939  -  cost:  0.4073399  - MSE:  2.126784788667319 - Train Accuracy:  0.82530123\n",
      "epoch :  940  -  cost:  0.40728825  - MSE:  2.126860766130252 - Train Accuracy:  0.82530123\n",
      "epoch :  941  -  cost:  0.40723646  - MSE:  2.1269507616784984 - Train Accuracy:  0.82530123\n",
      "epoch :  942  -  cost:  0.40718445  - MSE:  2.1270523680279165 - Train Accuracy:  0.82530123\n",
      "epoch :  943  -  cost:  0.40713212  - MSE:  2.1271710085221076 - Train Accuracy:  0.82530123\n",
      "epoch :  944  -  cost:  0.4070794  - MSE:  2.127315975907391 - Train Accuracy:  0.82530123\n",
      "epoch :  945  -  cost:  0.40702608  - MSE:  2.127490158343301 - Train Accuracy:  0.82530123\n",
      "epoch :  946  -  cost:  0.40697184  - MSE:  2.1277033135044645 - Train Accuracy:  0.82530123\n",
      "epoch :  947  -  cost:  0.4069161  - MSE:  2.12796498307068 - Train Accuracy:  0.82530123\n",
      "epoch :  948  -  cost:  0.40685797  - MSE:  2.128309739401167 - Train Accuracy:  0.82530123\n",
      "epoch :  949  -  cost:  0.40679532  - MSE:  2.128768926615105 - Train Accuracy:  0.82530123\n",
      "epoch :  950  -  cost:  0.40672377  - MSE:  2.1294153707165924 - Train Accuracy:  0.82530123\n",
      "epoch :  951  -  cost:  0.40663028  - MSE:  2.1304181535239035 - Train Accuracy:  0.82530123\n",
      "epoch :  952  -  cost:  0.40646398  - MSE:  2.132172330094131 - Train Accuracy:  0.82530123\n",
      "epoch :  953  -  cost:  0.40586597  - MSE:  2.1360111463972706 - Train Accuracy:  0.82530123\n",
      "epoch :  954  -  cost:  0.40190533  - MSE:  2.1464868006285 - Train Accuracy:  0.8313253\n",
      "epoch :  955  -  cost:  0.39757174  - MSE:  2.1445980157452893 - Train Accuracy:  0.8373494\n",
      "epoch :  956  -  cost:  0.4011896  - MSE:  2.1577716997580265 - Train Accuracy:  0.8313253\n",
      "epoch :  957  -  cost:  0.39651293  - MSE:  2.1526407021948533 - Train Accuracy:  0.8373494\n",
      "epoch :  958  -  cost:  0.3998292  - MSE:  2.161428481747883 - Train Accuracy:  0.8313253\n",
      "epoch :  959  -  cost:  0.3983539  - MSE:  2.15271403361562 - Train Accuracy:  0.8373494\n",
      "epoch :  960  -  cost:  0.40613613  - MSE:  2.152810299020706 - Train Accuracy:  0.82530123\n",
      "epoch :  961  -  cost:  0.4039433  - MSE:  2.1503655098462455 - Train Accuracy:  0.82530123\n",
      "epoch :  962  -  cost:  0.3958091  - MSE:  2.17274641267764 - Train Accuracy:  0.8373494\n",
      "epoch :  963  -  cost:  0.3958704  - MSE:  2.162423097390406 - Train Accuracy:  0.8373494\n",
      "epoch :  964  -  cost:  0.39690232  - MSE:  2.164175174849759 - Train Accuracy:  0.8373494\n",
      "epoch :  965  -  cost:  0.39510888  - MSE:  2.1640333385367123 - Train Accuracy:  0.8373494\n",
      "epoch :  966  -  cost:  0.39505115  - MSE:  2.159954980298126 - Train Accuracy:  0.8373494\n",
      "epoch :  967  -  cost:  0.3951048  - MSE:  2.1596028780694976 - Train Accuracy:  0.8373494\n",
      "epoch :  968  -  cost:  0.39495212  - MSE:  2.1574960072665115 - Train Accuracy:  0.8373494\n",
      "epoch :  969  -  cost:  0.39496782  - MSE:  2.1562495301579268 - Train Accuracy:  0.8373494\n",
      "epoch :  970  -  cost:  0.39469537  - MSE:  2.156180825843773 - Train Accuracy:  0.8373494\n",
      "epoch :  971  -  cost:  0.39455312  - MSE:  2.1546324969776154 - Train Accuracy:  0.8373494\n",
      "epoch :  972  -  cost:  0.39439598  - MSE:  2.1541414568361112 - Train Accuracy:  0.8373494\n",
      "epoch :  973  -  cost:  0.39432287  - MSE:  2.1526312242795083 - Train Accuracy:  0.8373494\n",
      "epoch :  974  -  cost:  0.39426124  - MSE:  2.1514251591710005 - Train Accuracy:  0.8313253\n",
      "epoch :  975  -  cost:  0.39420024  - MSE:  2.1503109802538924 - Train Accuracy:  0.8313253\n",
      "epoch :  976  -  cost:  0.394138  - MSE:  2.1493370068246955 - Train Accuracy:  0.8313253\n",
      "epoch :  977  -  cost:  0.39407334  - MSE:  2.148515641031974 - Train Accuracy:  0.8313253\n",
      "epoch :  978  -  cost:  0.3940034  - MSE:  2.147859176602872 - Train Accuracy:  0.8313253\n",
      "epoch :  979  -  cost:  0.39392215  - MSE:  2.147408665021279 - Train Accuracy:  0.8313253\n",
      "epoch :  980  -  cost:  0.3938118  - MSE:  2.14728722397303 - Train Accuracy:  0.8313253\n",
      "epoch :  981  -  cost:  0.3936009  - MSE:  2.1478094637215492 - Train Accuracy:  0.8313253\n",
      "epoch :  982  -  cost:  0.39295283  - MSE:  2.149764425193328 - Train Accuracy:  0.8313253\n",
      "epoch :  983  -  cost:  0.39228398  - MSE:  2.153530368667166 - Train Accuracy:  0.8313253\n",
      "epoch :  984  -  cost:  0.3941275  - MSE:  2.1461632443465906 - Train Accuracy:  0.8313253\n",
      "epoch :  985  -  cost:  0.3923334  - MSE:  2.156132953070553 - Train Accuracy:  0.8313253\n",
      "epoch :  986  -  cost:  0.39592448  - MSE:  2.1445282752623274 - Train Accuracy:  0.82530123\n",
      "epoch :  987  -  cost:  0.3913805  - MSE:  2.1596947951234093 - Train Accuracy:  0.8313253\n",
      "epoch :  988  -  cost:  0.39142725  - MSE:  2.162115036644102 - Train Accuracy:  0.8313253\n",
      "epoch :  989  -  cost:  0.39184317  - MSE:  2.1546861655390446 - Train Accuracy:  0.8313253\n",
      "epoch :  990  -  cost:  0.3924091  - MSE:  2.1642114451080157 - Train Accuracy:  0.8313253\n",
      "epoch :  991  -  cost:  0.39718756  - MSE:  2.147641337023666 - Train Accuracy:  0.8192771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  992  -  cost:  0.39168432  - MSE:  2.1825684832324814 - Train Accuracy:  0.8313253\n",
      "epoch :  993  -  cost:  0.39285415  - MSE:  2.1659784145113665 - Train Accuracy:  0.8313253\n",
      "epoch :  994  -  cost:  0.39275667  - MSE:  2.1851378147600187 - Train Accuracy:  0.8313253\n",
      "epoch :  995  -  cost:  0.39698222  - MSE:  2.1604987120325343 - Train Accuracy:  0.8192771\n",
      "epoch :  996  -  cost:  0.3907958  - MSE:  2.20374597357594 - Train Accuracy:  0.8313253\n",
      "epoch :  997  -  cost:  0.3903928  - MSE:  2.1986817110880743 - Train Accuracy:  0.8313253\n",
      "epoch :  998  -  cost:  0.39031976  - MSE:  2.195691239787434 - Train Accuracy:  0.8313253\n",
      "epoch :  999  -  cost:  0.39024198  - MSE:  2.1932795177816495 - Train Accuracy:  0.8313253\n",
      "Model saved in file: C:UsersSaurabhPycharmProjectsNeural Network TutorialBankNotes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.64285713\n",
      "MSE: 2.1933\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# Reading the dataset\n",
    "def read_dataset():\n",
    "    df = pd.read_csv(\"sonar.csv\")\n",
    "    # print(len(df.columns))\n",
    "    X = df[df.columns[0:60]].values\n",
    "    y = df[df.columns[60]]\n",
    "    encoder=LabelEncoder()\n",
    "    encoder.fit(y)  #convert r and m into 0 and 1\n",
    "    y=encoder.transform(y)\n",
    "    \n",
    "    #c=tf.one_hot(indices=y,depth=2,on_value=1)\n",
    "    sess=tf.Session()\n",
    "    #Y=sess.run(c)\n",
    "    \n",
    "    \n",
    "    # Encode the dependent variable\n",
    "    Y = one_hot_encode(y)\n",
    "    print(X.shape)\n",
    "    return (X, Y)\n",
    " \n",
    " \n",
    "# Define the encoder function.\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels, n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode\n",
    " \n",
    " \n",
    "# Read the dataset\n",
    "X, Y = read_dataset()\n",
    " \n",
    "# Shuffle the dataset to mix up the rows.\n",
    "X, Y = shuffle(X, Y, random_state=5)\n",
    " \n",
    "# Convert the dataset into train and test part\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.20, random_state=5)\n",
    " \n",
    "# Inpect the shape of the training and testing.\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    " \n",
    "# Define the important parameters and variable to work with the tensors\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "n_dim = X.shape[1]\n",
    "print(\"n_dim\", n_dim)\n",
    "n_class = 2\n",
    "model_path = \"C:UsersSaurabhPycharmProjectsNeural Network TutorialBankNotes\"\n",
    " \n",
    "# Define the number of hidden layers and number of neurons for each layer\n",
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 60\n",
    "n_hidden_4 = 60\n",
    " \n",
    "x = tf.placeholder(tf.float32, [None, n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim, n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_ = tf.placeholder(tf.float32, [None, n_class])\n",
    " \n",
    " \n",
    "# Define the model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    " \n",
    "    # Hidden layer with RELU activationsd\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    " \n",
    "    # Hidden layer with sigmoid activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    " \n",
    "    # Hidden layer with sigmoid activation\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.relu(layer_3)\n",
    " \n",
    "    # Hidden layer with RELU activation\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.sigmoid(layer_4)\n",
    " \n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    " \n",
    " \n",
    "# Define the weights and the biases for each layer\n",
    " \n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
    "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_4, n_class]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4': tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_class]))\n",
    "}\n",
    " \n",
    "# Initialize all the variables\n",
    " \n",
    "init = tf.global_variables_initializer()\n",
    " \n",
    "saver = tf.train.Saver()\n",
    " \n",
    "# Call your model defined\n",
    "y = multilayer_perceptron(x, weights, biases)\n",
    " \n",
    "# Define the cost function and optimizer\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    " \n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    " \n",
    "# Calculate the cost and the accuracy for each epoch\n",
    " \n",
    "mse_history = []\n",
    "accuracy_history = []\n",
    " \n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict={x: train_x, y_: train_y})\n",
    "    cost = sess.run(cost_function, feed_dict={x: train_x, y_: train_y})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    # print(\"Accuracy: \", (sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))\n",
    "    pred_y = sess.run(y, feed_dict={x: test_x})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "    mse_ = sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy = (sess.run(accuracy, feed_dict={x: train_x, y_: train_y}))\n",
    "    accuracy_history.append(accuracy)\n",
    " \n",
    "    print('epoch : ', epoch, ' - ', 'cost: ', cost, \" - MSE: \", mse_, \"- Train Accuracy: \", accuracy)\n",
    " \n",
    "save_path = saver.save(sess, model_path)\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    " \n",
    "#Plot Accuracy Graph\n",
    "plt.plot(accuracy_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    " \n",
    "# Print the final accuracy\n",
    " \n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Test Accuracy: \", (sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))\n",
    " \n",
    "# Print the final mean square error\n",
    " \n",
    "pred_y = sess.run(y, feed_dict={x: test_x})\n",
    "mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "print(\"MSE: %.4f\" % sess.run(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "(142, 13)\n",
      "(142, 3)\n",
      "(36, 13)\n",
      "n_dim 13\n",
      "epoch :  0  -  cost:  2.2977965  - MSE:  9.851163174101409 - Train Accuracy:  0.3943662\n",
      "epoch :  1  -  cost:  2.0527506  - MSE:  9.03860286417777 - Train Accuracy:  0.3943662\n",
      "epoch :  2  -  cost:  1.8643603  - MSE:  8.378979296123124 - Train Accuracy:  0.3943662\n",
      "epoch :  3  -  cost:  1.7258757  - MSE:  7.8403744000113775 - Train Accuracy:  0.3943662\n",
      "epoch :  4  -  cost:  1.6225618  - MSE:  7.390669030463837 - Train Accuracy:  0.3943662\n",
      "epoch :  5  -  cost:  1.5405041  - MSE:  7.005921505501243 - Train Accuracy:  0.3943662\n",
      "epoch :  6  -  cost:  1.4708143  - MSE:  6.671793113647012 - Train Accuracy:  0.3943662\n",
      "epoch :  7  -  cost:  1.4090667  - MSE:  6.380635139290223 - Train Accuracy:  0.3943662\n",
      "epoch :  8  -  cost:  1.3534979  - MSE:  6.12828491064305 - Train Accuracy:  0.3943662\n",
      "epoch :  9  -  cost:  1.3036497  - MSE:  5.912019291673054 - Train Accuracy:  0.3943662\n",
      "epoch :  10  -  cost:  1.2595874  - MSE:  5.729445671261154 - Train Accuracy:  0.3943662\n",
      "epoch :  11  -  cost:  1.2214838  - MSE:  5.577988877912817 - Train Accuracy:  0.3943662\n",
      "epoch :  12  -  cost:  1.1893938  - MSE:  5.4546962000855315 - Train Accuracy:  0.3943662\n",
      "epoch :  13  -  cost:  1.1631463  - MSE:  5.3562503756892665 - Train Accuracy:  0.3943662\n",
      "epoch :  14  -  cost:  1.1423218  - MSE:  5.279100925679858 - Train Accuracy:  0.3943662\n",
      "epoch :  15  -  cost:  1.1262937  - MSE:  5.219667914861257 - Train Accuracy:  0.3943662\n",
      "epoch :  16  -  cost:  1.1143101  - MSE:  5.174553206768686 - Train Accuracy:  0.3943662\n",
      "epoch :  17  -  cost:  1.1055876  - MSE:  5.1407013847815675 - Train Accuracy:  0.3943662\n",
      "epoch :  18  -  cost:  1.0993894  - MSE:  5.115511714541838 - Train Accuracy:  0.3943662\n",
      "epoch :  19  -  cost:  1.0950761  - MSE:  5.096856853868964 - Train Accuracy:  0.3943662\n",
      "epoch :  20  -  cost:  1.0921273  - MSE:  5.083063719043654 - Train Accuracy:  0.3943662\n",
      "epoch :  21  -  cost:  1.0901417  - MSE:  5.0728545839833865 - Train Accuracy:  0.3943662\n",
      "epoch :  22  -  cost:  1.0888203  - MSE:  5.06527322676953 - Train Accuracy:  0.3943662\n",
      "epoch :  23  -  cost:  1.0879502  - MSE:  5.059613547460901 - Train Accuracy:  0.3943662\n",
      "epoch :  24  -  cost:  1.0873818  - MSE:  5.0553657401695435 - Train Accuracy:  0.3943662\n",
      "epoch :  25  -  cost:  1.0870129  - MSE:  5.05215609431283 - Train Accuracy:  0.3943662\n",
      "epoch :  26  -  cost:  1.086775  - MSE:  5.049715221536913 - Train Accuracy:  0.3943662\n",
      "epoch :  27  -  cost:  1.0866216  - MSE:  5.047847896241643 - Train Accuracy:  0.3943662\n",
      "epoch :  28  -  cost:  1.0865234  - MSE:  5.046410475262484 - Train Accuracy:  0.3943662\n",
      "epoch :  29  -  cost:  1.0864611  - MSE:  5.045298595341624 - Train Accuracy:  0.3943662\n",
      "epoch :  30  -  cost:  1.0864209  - MSE:  5.044433989623939 - Train Accuracy:  0.3943662\n",
      "epoch :  31  -  cost:  1.0863954  - MSE:  5.043760035900756 - Train Accuracy:  0.3943662\n",
      "epoch :  32  -  cost:  1.0863792  - MSE:  5.0432324764556045 - Train Accuracy:  0.3943662\n",
      "epoch :  33  -  cost:  1.0863689  - MSE:  5.042818741842763 - Train Accuracy:  0.3943662\n",
      "epoch :  34  -  cost:  1.0863622  - MSE:  5.042492251492498 - Train Accuracy:  0.3943662\n",
      "epoch :  35  -  cost:  1.0863581  - MSE:  5.042235110770712 - Train Accuracy:  0.3943662\n",
      "epoch :  36  -  cost:  1.0863553  - MSE:  5.042032215560133 - Train Accuracy:  0.3943662\n",
      "epoch :  37  -  cost:  1.0863538  - MSE:  5.041871908550059 - Train Accuracy:  0.3943662\n",
      "epoch :  38  -  cost:  1.0863525  - MSE:  5.041745956137716 - Train Accuracy:  0.3943662\n",
      "epoch :  39  -  cost:  1.0863522  - MSE:  5.041644659232022 - Train Accuracy:  0.3943662\n",
      "epoch :  40  -  cost:  1.0863514  - MSE:  5.041564712250888 - Train Accuracy:  0.3943662\n",
      "epoch :  41  -  cost:  1.0863514  - MSE:  5.041501394305897 - Train Accuracy:  0.3943662\n",
      "epoch :  42  -  cost:  1.0863512  - MSE:  5.041451359465648 - Train Accuracy:  0.3943662\n",
      "epoch :  43  -  cost:  1.0863512  - MSE:  5.0414111085438655 - Train Accuracy:  0.3943662\n",
      "epoch :  44  -  cost:  1.086351  - MSE:  5.041379621673122 - Train Accuracy:  0.3943662\n",
      "epoch :  45  -  cost:  1.0863512  - MSE:  5.041354098782175 - Train Accuracy:  0.3943662\n",
      "epoch :  46  -  cost:  1.0863509  - MSE:  5.0413341016249955 - Train Accuracy:  0.3943662\n",
      "epoch :  47  -  cost:  1.0863509  - MSE:  5.041318327841894 - Train Accuracy:  0.3943662\n",
      "epoch :  48  -  cost:  1.0863508  - MSE:  5.041305554961717 - Train Accuracy:  0.3943662\n",
      "epoch :  49  -  cost:  1.0863509  - MSE:  5.041295373779149 - Train Accuracy:  0.3943662\n",
      "epoch :  50  -  cost:  1.0863508  - MSE:  5.041287533865893 - Train Accuracy:  0.3943662\n",
      "epoch :  51  -  cost:  1.0863509  - MSE:  5.041281518023908 - Train Accuracy:  0.3943662\n",
      "epoch :  52  -  cost:  1.086351  - MSE:  5.041276128901537 - Train Accuracy:  0.3943662\n",
      "epoch :  53  -  cost:  1.0863509  - MSE:  5.041272105505603 - Train Accuracy:  0.3943662\n",
      "epoch :  54  -  cost:  1.0863508  - MSE:  5.041268368987392 - Train Accuracy:  0.3943662\n",
      "epoch :  55  -  cost:  1.0863509  - MSE:  5.04126616285796 - Train Accuracy:  0.3943662\n",
      "epoch :  56  -  cost:  1.086351  - MSE:  5.041264000775034 - Train Accuracy:  0.3943662\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# Reading the dataset\n",
    "def read_dataset():   \n",
    "       df=pd.read_csv(\"wine.csv\")\n",
    "       print(len(df.columns)) #total no. of columns\n",
    "       x=df[df.columns[1:14]].values  #convert data into array \n",
    "       y=df[df.columns[0]]\n",
    "       #encode the dependent variable,single it has more than one class\n",
    "       encoder=LabelEncoder()\n",
    "       encoder.fit(y)  #convert r and m into 0 and 1\n",
    "       y=encoder.transform(y)\n",
    "       c=tf.one_hot(indices=y,depth=3,on_value=1)\n",
    "       sess=tf.Session()\n",
    "       Y=sess.run(c)\n",
    "       return(x,Y,y)\n",
    "\n",
    " \n",
    "# Define the encoder function.\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels, n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode\n",
    " \n",
    " \n",
    "# Read the dataset\n",
    "X, Y,y = read_dataset()\n",
    " \n",
    "# Shuffle the dataset to mix up the rows.\n",
    "X, Y = shuffle(X, Y, random_state=5)\n",
    " \n",
    "# Convert the dataset into train and test part\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.20, random_state=5)\n",
    " \n",
    "# Inpect the shape of the training and testing.\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    " \n",
    "# Define the important parameters and variable to work with the tensors\n",
    "learning_rate = 0.1\n",
    "training_epochs = 100\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "n_dim = X.shape[1]\n",
    "print(\"n_dim\", n_dim)\n",
    "n_class = 3\n",
    "model_path = \"C:UsersSaurabhPycharmProjectsNeural Network TutorialBankNotes\"\n",
    " \n",
    "# Define the number of hidden layers and number of neurons for each layer\n",
    "n_hidden_1 = 13\n",
    "n_hidden_2 = 13\n",
    "n_hidden_3 = 13\n",
    "n_hidden_4 = 13\n",
    " \n",
    "x = tf.placeholder(tf.float32, [None, n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim, n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_ = tf.placeholder(tf.float32, [None, n_class])\n",
    " \n",
    " \n",
    "# Define the model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    " \n",
    "    # Hidden layer with RELU activationsd\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    " \n",
    "    # Hidden layer with sigmoid activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    " \n",
    "    # Hidden layer with sigmoid activation\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.relu(layer_3)\n",
    " \n",
    "    # Hidden layer with RELU activation\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.sigmoid(layer_4)\n",
    " \n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    " \n",
    " \n",
    "# Define the weights and the biases for each layer\n",
    " \n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
    "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_4, n_class]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4': tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_class]))\n",
    "}\n",
    " \n",
    "# Initialize all the variables\n",
    " \n",
    "init = tf.global_variables_initializer()\n",
    " \n",
    "saver = tf.train.Saver()\n",
    " \n",
    "# Call your model defined\n",
    "y = multilayer_perceptron(x, weights, biases)\n",
    " \n",
    "# Define the cost function and optimizer\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    " \n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    " \n",
    "# Calculate the cost and the accuracy for each epoch\n",
    " \n",
    "mse_history = []\n",
    "accuracy_history = []\n",
    " \n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict={x: train_x, y_: train_y})\n",
    "    cost = sess.run(cost_function, feed_dict={x: train_x, y_: train_y})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    # print(\"Accuracy: \", (sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))\n",
    "    pred_y = sess.run(y, feed_dict={x: test_x})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "    mse_ = sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy = (sess.run(accuracy, feed_dict={x: train_x, y_: train_y}))\n",
    "    accuracy_history.append(accuracy)\n",
    " \n",
    "    print('epoch : ', epoch, ' - ', 'cost: ', cost, \" - MSE: \", mse_, \"- Train Accuracy: \", accuracy)\n",
    " \n",
    "save_path = saver.save(sess, model_path)\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    " \n",
    "#Plot Accuracy Graph\n",
    "plt.plot(accuracy_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    " \n",
    "# Print the final accuracy\n",
    " \n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Test Accuracy: \", (sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))\n",
    " \n",
    "# Print the final mean square error\n",
    " \n",
    "pred_y = sess.run(y, feed_dict={x: test_x})\n",
    "mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "print(\"MSE: %.4f\" % sess.run(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
